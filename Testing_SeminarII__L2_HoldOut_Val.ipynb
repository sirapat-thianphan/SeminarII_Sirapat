{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/sirapat-thianphan/SeminarII_Sirapat/master/events_bs2_2.csv'\n",
    "loaded_data = pd.read_csv(url, sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tactic0_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>NEAR_CCTV_</th>\n",
       "      <th>NEAR_MOOBA</th>\n",
       "      <th>MOOBAN_EST</th>\n",
       "      <th>MOOBAN_LEV</th>\n",
       "      <th>NEAR_UNITS</th>\n",
       "      <th>UNIT_TYPE</th>\n",
       "      <th>NEAR_VEHIC</th>\n",
       "      <th>VEHICLES_T</th>\n",
       "      <th>NEAR_NAIS_</th>\n",
       "      <th>NAIS_TYPE</th>\n",
       "      <th>NEAR_DIST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>101.19182</td>\n",
       "      <td>6.13009</td>\n",
       "      <td>3467.485002</td>\n",
       "      <td>85.604275</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>927.963005</td>\n",
       "      <td>5</td>\n",
       "      <td>1308.145156</td>\n",
       "      <td>0.7</td>\n",
       "      <td>284.929088</td>\n",
       "      <td>3</td>\n",
       "      <td>27.677967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>101.26577</td>\n",
       "      <td>6.41964</td>\n",
       "      <td>972.895329</td>\n",
       "      <td>1515.131446</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1855.001821</td>\n",
       "      <td>4</td>\n",
       "      <td>2805.680397</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1321.192664</td>\n",
       "      <td>1</td>\n",
       "      <td>1077.837387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>101.14605</td>\n",
       "      <td>6.68195</td>\n",
       "      <td>4535.321847</td>\n",
       "      <td>372.279866</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>294.153727</td>\n",
       "      <td>7</td>\n",
       "      <td>212.795421</td>\n",
       "      <td>0.7</td>\n",
       "      <td>323.187802</td>\n",
       "      <td>10</td>\n",
       "      <td>97.315259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>101.22266</td>\n",
       "      <td>6.85446</td>\n",
       "      <td>240.146910</td>\n",
       "      <td>333.135614</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1591.508482</td>\n",
       "      <td>3</td>\n",
       "      <td>407.629181</td>\n",
       "      <td>0.3</td>\n",
       "      <td>155.356802</td>\n",
       "      <td>3</td>\n",
       "      <td>6.634046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>101.34695</td>\n",
       "      <td>6.45786</td>\n",
       "      <td>242.448908</td>\n",
       "      <td>1172.773291</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>558.423389</td>\n",
       "      <td>5</td>\n",
       "      <td>701.641769</td>\n",
       "      <td>0.7</td>\n",
       "      <td>620.660475</td>\n",
       "      <td>5</td>\n",
       "      <td>31.915022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>100.97757</td>\n",
       "      <td>6.65426</td>\n",
       "      <td>4096.016638</td>\n",
       "      <td>1315.821482</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1716.603590</td>\n",
       "      <td>5</td>\n",
       "      <td>6956.354136</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14218.082300</td>\n",
       "      <td>5</td>\n",
       "      <td>1124.033888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>101.74995</td>\n",
       "      <td>6.27591</td>\n",
       "      <td>2686.242719</td>\n",
       "      <td>932.762119</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1707.460629</td>\n",
       "      <td>4</td>\n",
       "      <td>3448.168296</td>\n",
       "      <td>0.7</td>\n",
       "      <td>69.781556</td>\n",
       "      <td>6</td>\n",
       "      <td>71.977883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>101.62470</td>\n",
       "      <td>6.71488</td>\n",
       "      <td>580.185597</td>\n",
       "      <td>403.194092</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>567.060214</td>\n",
       "      <td>4</td>\n",
       "      <td>1545.663021</td>\n",
       "      <td>0.7</td>\n",
       "      <td>80.889155</td>\n",
       "      <td>4</td>\n",
       "      <td>35.425075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>101.28660</td>\n",
       "      <td>6.72085</td>\n",
       "      <td>302.995168</td>\n",
       "      <td>143.336508</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1104.123671</td>\n",
       "      <td>4</td>\n",
       "      <td>363.863675</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1144.968962</td>\n",
       "      <td>3</td>\n",
       "      <td>25.827262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>101.45094</td>\n",
       "      <td>6.49835</td>\n",
       "      <td>2562.292453</td>\n",
       "      <td>250.031476</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3504.811321</td>\n",
       "      <td>4</td>\n",
       "      <td>7015.471466</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2175.258547</td>\n",
       "      <td>6</td>\n",
       "      <td>14.428984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tactic0_id  longitude  latitude   NEAR_CCTV_   NEAR_MOOBA  MOOBAN_EST  \\\n",
       "0           1  101.19182   6.13009  3467.485002    85.604275         0.3   \n",
       "1           0  101.26577   6.41964   972.895329  1515.131446         0.3   \n",
       "2           1  101.14605   6.68195  4535.321847   372.279866         0.7   \n",
       "3           1  101.22266   6.85446   240.146910   333.135614         0.3   \n",
       "4           0  101.34695   6.45786   242.448908  1172.773291         0.3   \n",
       "5           0  100.97757   6.65426  4096.016638  1315.821482         0.3   \n",
       "6           0  101.74995   6.27591  2686.242719   932.762119         0.7   \n",
       "7           0  101.62470   6.71488   580.185597   403.194092         0.3   \n",
       "8           1  101.28660   6.72085   302.995168   143.336508         0.7   \n",
       "9           0  101.45094   6.49835  2562.292453   250.031476         0.3   \n",
       "\n",
       "   MOOBAN_LEV   NEAR_UNITS  UNIT_TYPE   NEAR_VEHIC  VEHICLES_T    NEAR_NAIS_  \\\n",
       "0        0.25   927.963005          5  1308.145156         0.7    284.929088   \n",
       "1        0.25  1855.001821          4  2805.680397         0.7   1321.192664   \n",
       "2        1.00   294.153727          7   212.795421         0.7    323.187802   \n",
       "3        0.25  1591.508482          3   407.629181         0.3    155.356802   \n",
       "4        0.25   558.423389          5   701.641769         0.7    620.660475   \n",
       "5        0.25  1716.603590          5  6956.354136         0.3  14218.082300   \n",
       "6        1.00  1707.460629          4  3448.168296         0.7     69.781556   \n",
       "7        0.25   567.060214          4  1545.663021         0.7     80.889155   \n",
       "8        1.00  1104.123671          4   363.863675         0.7   1144.968962   \n",
       "9        0.25  3504.811321          4  7015.471466         0.7   2175.258547   \n",
       "\n",
       "   NAIS_TYPE    NEAR_DIST  \n",
       "0          3    27.677967  \n",
       "1          1  1077.837387  \n",
       "2         10    97.315259  \n",
       "3          3     6.634046  \n",
       "4          5    31.915022  \n",
       "5          5  1124.033888  \n",
       "6          6    71.977883  \n",
       "7          4    35.425075  \n",
       "8          3    25.827262  \n",
       "9          6    14.428984  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pre = loaded_data.iloc[:,1:]\n",
    "y_pre = loaded_data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>NEAR_CCTV_</th>\n",
       "      <th>NEAR_MOOBA</th>\n",
       "      <th>MOOBAN_EST</th>\n",
       "      <th>MOOBAN_LEV</th>\n",
       "      <th>NEAR_UNITS</th>\n",
       "      <th>UNIT_TYPE</th>\n",
       "      <th>NEAR_VEHIC</th>\n",
       "      <th>VEHICLES_T</th>\n",
       "      <th>NEAR_NAIS_</th>\n",
       "      <th>NAIS_TYPE</th>\n",
       "      <th>NEAR_DIST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.19182</td>\n",
       "      <td>6.13009</td>\n",
       "      <td>3467.485002</td>\n",
       "      <td>85.604275</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>927.963005</td>\n",
       "      <td>5</td>\n",
       "      <td>1308.145156</td>\n",
       "      <td>0.7</td>\n",
       "      <td>284.929088</td>\n",
       "      <td>3</td>\n",
       "      <td>27.677967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.26577</td>\n",
       "      <td>6.41964</td>\n",
       "      <td>972.895329</td>\n",
       "      <td>1515.131446</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1855.001821</td>\n",
       "      <td>4</td>\n",
       "      <td>2805.680397</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1321.192664</td>\n",
       "      <td>1</td>\n",
       "      <td>1077.837387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101.14605</td>\n",
       "      <td>6.68195</td>\n",
       "      <td>4535.321847</td>\n",
       "      <td>372.279866</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>294.153727</td>\n",
       "      <td>7</td>\n",
       "      <td>212.795421</td>\n",
       "      <td>0.7</td>\n",
       "      <td>323.187802</td>\n",
       "      <td>10</td>\n",
       "      <td>97.315259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.22266</td>\n",
       "      <td>6.85446</td>\n",
       "      <td>240.146910</td>\n",
       "      <td>333.135614</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1591.508482</td>\n",
       "      <td>3</td>\n",
       "      <td>407.629181</td>\n",
       "      <td>0.3</td>\n",
       "      <td>155.356802</td>\n",
       "      <td>3</td>\n",
       "      <td>6.634046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101.34695</td>\n",
       "      <td>6.45786</td>\n",
       "      <td>242.448908</td>\n",
       "      <td>1172.773291</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>558.423389</td>\n",
       "      <td>5</td>\n",
       "      <td>701.641769</td>\n",
       "      <td>0.7</td>\n",
       "      <td>620.660475</td>\n",
       "      <td>5</td>\n",
       "      <td>31.915022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude   NEAR_CCTV_   NEAR_MOOBA  MOOBAN_EST  MOOBAN_LEV  \\\n",
       "0  101.19182   6.13009  3467.485002    85.604275         0.3        0.25   \n",
       "1  101.26577   6.41964   972.895329  1515.131446         0.3        0.25   \n",
       "2  101.14605   6.68195  4535.321847   372.279866         0.7        1.00   \n",
       "3  101.22266   6.85446   240.146910   333.135614         0.3        0.25   \n",
       "4  101.34695   6.45786   242.448908  1172.773291         0.3        0.25   \n",
       "\n",
       "    NEAR_UNITS  UNIT_TYPE   NEAR_VEHIC  VEHICLES_T   NEAR_NAIS_  NAIS_TYPE  \\\n",
       "0   927.963005          5  1308.145156         0.7   284.929088          3   \n",
       "1  1855.001821          4  2805.680397         0.7  1321.192664          1   \n",
       "2   294.153727          7   212.795421         0.7   323.187802         10   \n",
       "3  1591.508482          3   407.629181         0.3   155.356802          3   \n",
       "4   558.423389          5   701.641769         0.7   620.660475          5   \n",
       "\n",
       "     NEAR_DIST  \n",
       "0    27.677967  \n",
       "1  1077.837387  \n",
       "2    97.315259  \n",
       "3     6.634046  \n",
       "4    31.915022  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pre.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: tactic0_id, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kratung/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "#standardizing the input feature\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "X = sc.fit_transform(X_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.491497</td>\n",
       "      <td>0.254955</td>\n",
       "      <td>0.107703</td>\n",
       "      <td>0.005184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028806</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.037864</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006080</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.001228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.533348</td>\n",
       "      <td>0.455602</td>\n",
       "      <td>0.030219</td>\n",
       "      <td>0.091754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057583</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.081210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.465594</td>\n",
       "      <td>0.637373</td>\n",
       "      <td>0.140871</td>\n",
       "      <td>0.022545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009131</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.006159</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.508950</td>\n",
       "      <td>0.756916</td>\n",
       "      <td>0.007459</td>\n",
       "      <td>0.020174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049404</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.011799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.579290</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>0.007531</td>\n",
       "      <td>0.071022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017335</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.020309</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013266</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.001416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3    4    5         6         7   \\\n",
       "0  0.491497  0.254955  0.107703  0.005184  0.0  0.0  0.028806  0.363636   \n",
       "1  0.533348  0.455602  0.030219  0.091754  0.0  0.0  0.057583  0.272727   \n",
       "2  0.465594  0.637373  0.140871  0.022545  1.0  1.0  0.009131  0.545455   \n",
       "3  0.508950  0.756916  0.007459  0.020174  0.0  0.0  0.049404  0.181818   \n",
       "4  0.579290  0.482087  0.007531  0.071022  0.0  0.0  0.017335  0.363636   \n",
       "\n",
       "         8    9         10        11        12  \n",
       "0  0.037864  1.0  0.006080  0.222222  0.001228  \n",
       "1  0.081210  1.0  0.028261  0.000000  0.047830  \n",
       "2  0.006159  1.0  0.006899  1.000000  0.004318  \n",
       "3  0.011799  0.0  0.003306  0.222222  0.000294  \n",
       "4  0.020309  1.0  0.013266  0.444444  0.001416  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=X)   \n",
    "df.head(5)                          # We still the zero problem in the column 4, 5 and 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.01191820e+02, 6.13009000e+00, 3.46748500e+03, ...,\n",
       "        2.84929088e+02, 3.00000000e+00, 2.76779675e+01],\n",
       "       [1.01265770e+02, 6.41964000e+00, 9.72895329e+02, ...,\n",
       "        1.32119266e+03, 1.00000000e+00, 1.07783739e+03],\n",
       "       [1.01146050e+02, 6.68195000e+00, 4.53532185e+03, ...,\n",
       "        3.23187802e+02, 1.00000000e+01, 9.73152590e+01],\n",
       "       ...,\n",
       "       [1.00829740e+02, 6.66129000e+00, 6.35483105e+03, ...,\n",
       "        2.24800867e+04, 5.00000000e+00, 3.82198525e+03],\n",
       "       [1.01305360e+02, 6.55308000e+00, 1.66363464e+02, ...,\n",
       "        3.23205756e+02, 6.00000000e+00, 7.04019195e+01],\n",
       "       [1.01554750e+02, 6.42124000e+00, 3.85837311e+03, ...,\n",
       "        1.95051624e+02, 5.00000000e+00, 1.68364332e+02]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pre_numpy = X_pre.values  # convert panda dataframe to numpy array\n",
    "X_pre_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:, 4] = X_pre_numpy[:, 4]\n",
    "X[:, 5] = X_pre_numpy[:, 5]\n",
    "X[:, 9] = X_pre_numpy[:, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.491497</td>\n",
       "      <td>0.254955</td>\n",
       "      <td>0.107703</td>\n",
       "      <td>0.005184</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.028806</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.037864</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.006080</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.001228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.533348</td>\n",
       "      <td>0.455602</td>\n",
       "      <td>0.030219</td>\n",
       "      <td>0.091754</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.057583</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.081210</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.028261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.465594</td>\n",
       "      <td>0.637373</td>\n",
       "      <td>0.140871</td>\n",
       "      <td>0.022545</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.009131</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.006159</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.006899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.508950</td>\n",
       "      <td>0.756916</td>\n",
       "      <td>0.007459</td>\n",
       "      <td>0.020174</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.049404</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.011799</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.579290</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>0.007531</td>\n",
       "      <td>0.071022</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.017335</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.020309</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.013266</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.001416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3    4     5         6         7   \\\n",
       "0  0.491497  0.254955  0.107703  0.005184  0.3  0.25  0.028806  0.363636   \n",
       "1  0.533348  0.455602  0.030219  0.091754  0.3  0.25  0.057583  0.272727   \n",
       "2  0.465594  0.637373  0.140871  0.022545  0.7  1.00  0.009131  0.545455   \n",
       "3  0.508950  0.756916  0.007459  0.020174  0.3  0.25  0.049404  0.181818   \n",
       "4  0.579290  0.482087  0.007531  0.071022  0.3  0.25  0.017335  0.363636   \n",
       "\n",
       "         8    9         10        11        12  \n",
       "0  0.037864  0.7  0.006080  0.222222  0.001228  \n",
       "1  0.081210  0.7  0.028261  0.000000  0.047830  \n",
       "2  0.006159  0.7  0.006899  1.000000  0.004318  \n",
       "3  0.011799  0.3  0.003306  0.222222  0.000294  \n",
       "4  0.020309  0.7  0.013266  0.444444  0.001416  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=X)   \n",
    "df.head(5)                          # Now, the zero problems are already solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_pre, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96363873, 0.35831693, 0.08574365, 0.0319393 , 0.7       ,\n",
       "       1.        , 0.05352891, 0.18181818, 0.10715836, 0.7       ,\n",
       "       0.05303056, 0.        , 0.01554384])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NN Model 1 ( 8, 16 , 16, 1 )\n",
    "# output = activation(dot(input, kernel) + bias)\n",
    "classifier1 = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier1.add(layers.Dense(8, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_dim=13))  \n",
    "#classifier1.add(layers.Dropout(0.3))\n",
    "#Second  Hidden Layer\n",
    "classifier1.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "#classifier1.add(layers.Dropout(0.3))\n",
    "#Third Hidden Layer\n",
    "classifier1.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "#classifier1.add(layers.Dropout(0.3))\n",
    "#Output Layer\n",
    "classifier1.add(layers.Dense(1, activation='sigmoid'))\n",
    "#Compiling the neural network\n",
    "classifier1.compile(optimizer ='rmsprop',loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NN Model 2 ( 16, 32 , 32, 1 )\n",
    "# output = activation(dot(input, kernel) + bias)\n",
    "classifier2 = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier2.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_dim=13))  \n",
    "#classifier2.add(layers.Dropout(0.3))\n",
    "#Second  Hidden Layer\n",
    "classifier2.add(layers.Dense(32, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "#classifier2.add(layers.Dropout(0.3))\n",
    "#Third Hidden Layer\n",
    "classifier2.add(layers.Dense(32, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "#classifier2.add(layers.Dropout(0.3))\n",
    "#Output Layer\n",
    "classifier2.add(layers.Dense(1, activation='sigmoid'))\n",
    "#Compiling the neural network\n",
    "classifier2.compile(optimizer ='rmsprop',loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NN Model 3 ( 32, 64 , 64, 1 )\n",
    "# output = activation(dot(input, kernel) + bias)\n",
    "classifier3 = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier3.add(layers.Dense(32, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_dim=13))  \n",
    "#classifier3.add(layers.Dropout(0.3))\n",
    "#Second  Hidden Layer\n",
    "classifier3.add(layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "#classifier3.add(layers.Dropout(0.3))\n",
    "#Third Hidden Layer\n",
    "classifier3.add(layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "#classifier3.add(layers.Dropout(0.3))\n",
    "#Output Layer\n",
    "classifier3.add(layers.Dense(1, activation='sigmoid'))\n",
    "#Compiling the neural network\n",
    "classifier3.compile(optimizer ='rmsprop',loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Approach\n",
    "x_val = X_train[:1000]\n",
    "partial_x_train = X_train[1000:]\n",
    "\n",
    "y_val = y_train[:1000]\n",
    "partial_y_train = y_train[1000:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5400 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "5400/5400 [==============================] - 2s 351us/step - loss: 0.7208 - acc: 0.5409 - val_loss: 0.7145 - val_acc: 0.5550\n",
      "Epoch 2/100\n",
      "5400/5400 [==============================] - 0s 52us/step - loss: 0.7109 - acc: 0.5546 - val_loss: 0.7040 - val_acc: 0.5770\n",
      "Epoch 3/100\n",
      "5400/5400 [==============================] - 0s 49us/step - loss: 0.7023 - acc: 0.5694 - val_loss: 0.6965 - val_acc: 0.5850\n",
      "Epoch 4/100\n",
      "5400/5400 [==============================] - 0s 42us/step - loss: 0.6955 - acc: 0.5820 - val_loss: 0.6899 - val_acc: 0.5900\n",
      "Epoch 5/100\n",
      "5400/5400 [==============================] - 0s 57us/step - loss: 0.6899 - acc: 0.5894 - val_loss: 0.6848 - val_acc: 0.6060\n",
      "Epoch 6/100\n",
      "5400/5400 [==============================] - 0s 51us/step - loss: 0.6858 - acc: 0.5891 - val_loss: 0.6806 - val_acc: 0.6070\n",
      "Epoch 7/100\n",
      "5400/5400 [==============================] - 0s 63us/step - loss: 0.6829 - acc: 0.5913 - val_loss: 0.6782 - val_acc: 0.6050\n",
      "Epoch 8/100\n",
      "5400/5400 [==============================] - 0s 54us/step - loss: 0.6802 - acc: 0.5989 - val_loss: 0.6785 - val_acc: 0.6120\n",
      "Epoch 9/100\n",
      "5400/5400 [==============================] - 0s 59us/step - loss: 0.6784 - acc: 0.6000 - val_loss: 0.6766 - val_acc: 0.6110\n",
      "Epoch 10/100\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.6774 - acc: 0.6000 - val_loss: 0.6755 - val_acc: 0.6080\n",
      "Epoch 11/100\n",
      "5400/5400 [==============================] - 0s 62us/step - loss: 0.6756 - acc: 0.6007 - val_loss: 0.6724 - val_acc: 0.6080\n",
      "Epoch 12/100\n",
      "5400/5400 [==============================] - 0s 43us/step - loss: 0.6749 - acc: 0.5987 - val_loss: 0.6712 - val_acc: 0.6200\n",
      "Epoch 13/100\n",
      "5400/5400 [==============================] - 0s 47us/step - loss: 0.6735 - acc: 0.6048 - val_loss: 0.6704 - val_acc: 0.6160\n",
      "Epoch 14/100\n",
      "5400/5400 [==============================] - 0s 34us/step - loss: 0.6728 - acc: 0.6050 - val_loss: 0.6702 - val_acc: 0.6180\n",
      "Epoch 15/100\n",
      "5400/5400 [==============================] - 0s 34us/step - loss: 0.6717 - acc: 0.6046 - val_loss: 0.6699 - val_acc: 0.6130\n",
      "Epoch 16/100\n",
      "5400/5400 [==============================] - 0s 36us/step - loss: 0.6709 - acc: 0.6041 - val_loss: 0.6682 - val_acc: 0.6210\n",
      "Epoch 17/100\n",
      "5400/5400 [==============================] - 0s 35us/step - loss: 0.6705 - acc: 0.6059 - val_loss: 0.6679 - val_acc: 0.6240\n",
      "Epoch 18/100\n",
      "5400/5400 [==============================] - 0s 35us/step - loss: 0.6692 - acc: 0.6061 - val_loss: 0.6668 - val_acc: 0.6170\n",
      "Epoch 19/100\n",
      "5400/5400 [==============================] - 0s 52us/step - loss: 0.6689 - acc: 0.6098 - val_loss: 0.6662 - val_acc: 0.6200\n",
      "Epoch 20/100\n",
      "5400/5400 [==============================] - 0s 36us/step - loss: 0.6680 - acc: 0.6130 - val_loss: 0.6665 - val_acc: 0.6160\n",
      "Epoch 21/100\n",
      "5400/5400 [==============================] - 0s 44us/step - loss: 0.6673 - acc: 0.6109 - val_loss: 0.6693 - val_acc: 0.6190\n",
      "Epoch 22/100\n",
      "5400/5400 [==============================] - 0s 56us/step - loss: 0.6668 - acc: 0.6096 - val_loss: 0.6657 - val_acc: 0.6240\n",
      "Epoch 23/100\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.6662 - acc: 0.6106 - val_loss: 0.6644 - val_acc: 0.6180\n",
      "Epoch 24/100\n",
      "5400/5400 [==============================] - 0s 53us/step - loss: 0.6656 - acc: 0.6120 - val_loss: 0.6668 - val_acc: 0.6170\n",
      "Epoch 25/100\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.6652 - acc: 0.6128 - val_loss: 0.6667 - val_acc: 0.6160\n",
      "Epoch 26/100\n",
      "5400/5400 [==============================] - 0s 34us/step - loss: 0.6647 - acc: 0.6143 - val_loss: 0.6655 - val_acc: 0.6210\n",
      "Epoch 27/100\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.6641 - acc: 0.6130 - val_loss: 0.6630 - val_acc: 0.6180\n",
      "Epoch 28/100\n",
      "5400/5400 [==============================] - 0s 61us/step - loss: 0.6640 - acc: 0.6152 - val_loss: 0.6626 - val_acc: 0.6260\n",
      "Epoch 29/100\n",
      "5400/5400 [==============================] - 0s 35us/step - loss: 0.6635 - acc: 0.6152 - val_loss: 0.6615 - val_acc: 0.6170\n",
      "Epoch 30/100\n",
      "5400/5400 [==============================] - 0s 35us/step - loss: 0.6622 - acc: 0.6191 - val_loss: 0.6634 - val_acc: 0.6210\n",
      "Epoch 31/100\n",
      "5400/5400 [==============================] - 0s 42us/step - loss: 0.6621 - acc: 0.6176 - val_loss: 0.6671 - val_acc: 0.6020\n",
      "Epoch 32/100\n",
      "5400/5400 [==============================] - 0s 57us/step - loss: 0.6606 - acc: 0.6198 - val_loss: 0.6607 - val_acc: 0.6220\n",
      "Epoch 33/100\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.6613 - acc: 0.6152 - val_loss: 0.6601 - val_acc: 0.6220\n",
      "Epoch 34/100\n",
      "5400/5400 [==============================] - 0s 63us/step - loss: 0.6607 - acc: 0.6150 - val_loss: 0.6604 - val_acc: 0.6220\n",
      "Epoch 35/100\n",
      "5400/5400 [==============================] - 0s 53us/step - loss: 0.6605 - acc: 0.6193 - val_loss: 0.6591 - val_acc: 0.6210\n",
      "Epoch 36/100\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.6599 - acc: 0.6163 - val_loss: 0.6587 - val_acc: 0.6250\n",
      "Epoch 37/100\n",
      "5400/5400 [==============================] - 0s 36us/step - loss: 0.6596 - acc: 0.6133 - val_loss: 0.6589 - val_acc: 0.6200\n",
      "Epoch 38/100\n",
      "5400/5400 [==============================] - 0s 44us/step - loss: 0.6593 - acc: 0.6194 - val_loss: 0.6587 - val_acc: 0.6200\n",
      "Epoch 39/100\n",
      "5400/5400 [==============================] - 0s 48us/step - loss: 0.6592 - acc: 0.6159 - val_loss: 0.6581 - val_acc: 0.6220\n",
      "Epoch 40/100\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.6590 - acc: 0.6167 - val_loss: 0.6578 - val_acc: 0.6210\n",
      "Epoch 41/100\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.6584 - acc: 0.6167 - val_loss: 0.6577 - val_acc: 0.6220\n",
      "Epoch 42/100\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.6585 - acc: 0.6152 - val_loss: 0.6573 - val_acc: 0.6220\n",
      "Epoch 43/100\n",
      "5400/5400 [==============================] - 0s 42us/step - loss: 0.6574 - acc: 0.6194 - val_loss: 0.6587 - val_acc: 0.6120\n",
      "Epoch 44/100\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.6577 - acc: 0.6178 - val_loss: 0.6576 - val_acc: 0.6230\n",
      "Epoch 45/100\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.6570 - acc: 0.6213 - val_loss: 0.6574 - val_acc: 0.6250\n",
      "Epoch 46/100\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.6576 - acc: 0.6176 - val_loss: 0.6602 - val_acc: 0.6100\n",
      "Epoch 47/100\n",
      "5400/5400 [==============================] - 0s 34us/step - loss: 0.6568 - acc: 0.6200 - val_loss: 0.6576 - val_acc: 0.6220\n",
      "Epoch 48/100\n",
      "5400/5400 [==============================] - 0s 36us/step - loss: 0.6569 - acc: 0.6180 - val_loss: 0.6582 - val_acc: 0.6200\n",
      "Epoch 49/100\n",
      "5400/5400 [==============================] - 0s 65us/step - loss: 0.6564 - acc: 0.6170 - val_loss: 0.6566 - val_acc: 0.6290\n",
      "Epoch 50/100\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.6556 - acc: 0.6178 - val_loss: 0.6560 - val_acc: 0.6200\n",
      "Epoch 51/100\n",
      "5400/5400 [==============================] - 0s 59us/step - loss: 0.6562 - acc: 0.6178 - val_loss: 0.6572 - val_acc: 0.6270\n",
      "Epoch 52/100\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.6562 - acc: 0.6163 - val_loss: 0.6593 - val_acc: 0.6150\n",
      "Epoch 53/100\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.6560 - acc: 0.6161 - val_loss: 0.6553 - val_acc: 0.6210\n",
      "Epoch 54/100\n",
      "5400/5400 [==============================] - 0s 65us/step - loss: 0.6558 - acc: 0.6180 - val_loss: 0.6557 - val_acc: 0.6200\n",
      "Epoch 55/100\n",
      "5400/5400 [==============================] - 0s 59us/step - loss: 0.6555 - acc: 0.6219 - val_loss: 0.6570 - val_acc: 0.6240\n",
      "Epoch 56/100\n",
      "5400/5400 [==============================] - 1s 100us/step - loss: 0.6554 - acc: 0.6174 - val_loss: 0.6585 - val_acc: 0.6170\n",
      "Epoch 57/100\n",
      "5400/5400 [==============================] - 0s 85us/step - loss: 0.6558 - acc: 0.6176 - val_loss: 0.6555 - val_acc: 0.6270\n",
      "Epoch 58/100\n",
      "5400/5400 [==============================] - 0s 69us/step - loss: 0.6547 - acc: 0.6215 - val_loss: 0.6554 - val_acc: 0.6300\n",
      "Epoch 59/100\n",
      "5400/5400 [==============================] - 0s 57us/step - loss: 0.6546 - acc: 0.6211 - val_loss: 0.6658 - val_acc: 0.6030\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400/5400 [==============================] - 0s 44us/step - loss: 0.6557 - acc: 0.6174 - val_loss: 0.6549 - val_acc: 0.6260\n",
      "Epoch 61/100\n",
      "5400/5400 [==============================] - 0s 43us/step - loss: 0.6546 - acc: 0.6181 - val_loss: 0.6662 - val_acc: 0.6040\n",
      "Epoch 62/100\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.6546 - acc: 0.6235 - val_loss: 0.6540 - val_acc: 0.6220\n",
      "Epoch 63/100\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.6540 - acc: 0.6202 - val_loss: 0.6535 - val_acc: 0.6230\n",
      "Epoch 64/100\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.6540 - acc: 0.6176 - val_loss: 0.6587 - val_acc: 0.6140\n",
      "Epoch 65/100\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.6542 - acc: 0.6233 - val_loss: 0.6598 - val_acc: 0.6130\n",
      "Epoch 66/100\n",
      "5400/5400 [==============================] - 0s 59us/step - loss: 0.6536 - acc: 0.6183 - val_loss: 0.6528 - val_acc: 0.6290\n",
      "Epoch 67/100\n",
      "5400/5400 [==============================] - 0s 44us/step - loss: 0.6538 - acc: 0.6189 - val_loss: 0.6538 - val_acc: 0.6210\n",
      "Epoch 68/100\n",
      "5400/5400 [==============================] - 0s 45us/step - loss: 0.6529 - acc: 0.6250 - val_loss: 0.6522 - val_acc: 0.6260\n",
      "Epoch 69/100\n",
      "5400/5400 [==============================] - 0s 46us/step - loss: 0.6535 - acc: 0.6196 - val_loss: 0.6521 - val_acc: 0.6240\n",
      "Epoch 70/100\n",
      "5400/5400 [==============================] - 0s 51us/step - loss: 0.6531 - acc: 0.6220 - val_loss: 0.6540 - val_acc: 0.6290\n",
      "Epoch 71/100\n",
      "5400/5400 [==============================] - 0s 48us/step - loss: 0.6528 - acc: 0.6248 - val_loss: 0.6522 - val_acc: 0.6310\n",
      "Epoch 72/100\n",
      "5400/5400 [==============================] - 0s 45us/step - loss: 0.6529 - acc: 0.6194 - val_loss: 0.6553 - val_acc: 0.6210\n",
      "Epoch 73/100\n",
      "5400/5400 [==============================] - 0s 63us/step - loss: 0.6523 - acc: 0.6274 - val_loss: 0.6525 - val_acc: 0.6310\n",
      "Epoch 74/100\n",
      "5400/5400 [==============================] - 0s 44us/step - loss: 0.6521 - acc: 0.6222 - val_loss: 0.6541 - val_acc: 0.6280\n",
      "Epoch 75/100\n",
      "5400/5400 [==============================] - 0s 44us/step - loss: 0.6525 - acc: 0.6224 - val_loss: 0.6512 - val_acc: 0.6280\n",
      "Epoch 76/100\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.6523 - acc: 0.6220 - val_loss: 0.6511 - val_acc: 0.6210\n",
      "Epoch 77/100\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.6514 - acc: 0.6226 - val_loss: 0.6516 - val_acc: 0.6290\n",
      "Epoch 78/100\n",
      "5400/5400 [==============================] - 0s 56us/step - loss: 0.6519 - acc: 0.6215 - val_loss: 0.6510 - val_acc: 0.6310\n",
      "Epoch 79/100\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.6514 - acc: 0.6254 - val_loss: 0.6519 - val_acc: 0.6250\n",
      "Epoch 80/100\n",
      "5400/5400 [==============================] - 0s 35us/step - loss: 0.6507 - acc: 0.6252 - val_loss: 0.6528 - val_acc: 0.6270\n",
      "Epoch 81/100\n",
      "5400/5400 [==============================] - 1s 112us/step - loss: 0.6505 - acc: 0.6237 - val_loss: 0.6497 - val_acc: 0.6280\n",
      "Epoch 82/100\n",
      "5400/5400 [==============================] - 0s 65us/step - loss: 0.6511 - acc: 0.6244 - val_loss: 0.6505 - val_acc: 0.6310\n",
      "Epoch 83/100\n",
      "5400/5400 [==============================] - 0s 53us/step - loss: 0.6510 - acc: 0.6269 - val_loss: 0.6510 - val_acc: 0.6250\n",
      "Epoch 84/100\n",
      "5400/5400 [==============================] - 0s 52us/step - loss: 0.6505 - acc: 0.6265 - val_loss: 0.6506 - val_acc: 0.6260\n",
      "Epoch 85/100\n",
      "5400/5400 [==============================] - 0s 46us/step - loss: 0.6497 - acc: 0.6293 - val_loss: 0.6489 - val_acc: 0.6250\n",
      "Epoch 86/100\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.6504 - acc: 0.6265 - val_loss: 0.6505 - val_acc: 0.6300\n",
      "Epoch 87/100\n",
      "5400/5400 [==============================] - 0s 36us/step - loss: 0.6505 - acc: 0.6257 - val_loss: 0.6489 - val_acc: 0.6240\n",
      "Epoch 88/100\n",
      "5400/5400 [==============================] - 0s 47us/step - loss: 0.6492 - acc: 0.6257 - val_loss: 0.6490 - val_acc: 0.6330\n",
      "Epoch 89/100\n",
      "5400/5400 [==============================] - 0s 49us/step - loss: 0.6499 - acc: 0.6281 - val_loss: 0.6482 - val_acc: 0.6230\n",
      "Epoch 90/100\n",
      "5400/5400 [==============================] - 0s 53us/step - loss: 0.6494 - acc: 0.6267 - val_loss: 0.6484 - val_acc: 0.6250\n",
      "Epoch 91/100\n",
      "5400/5400 [==============================] - 0s 49us/step - loss: 0.6487 - acc: 0.6267 - val_loss: 0.6474 - val_acc: 0.6270\n",
      "Epoch 92/100\n",
      "5400/5400 [==============================] - 0s 91us/step - loss: 0.6489 - acc: 0.6294 - val_loss: 0.6510 - val_acc: 0.6230\n",
      "Epoch 93/100\n",
      "5400/5400 [==============================] - 0s 69us/step - loss: 0.6489 - acc: 0.6259 - val_loss: 0.6553 - val_acc: 0.6070\n",
      "Epoch 94/100\n",
      "5400/5400 [==============================] - 0s 53us/step - loss: 0.6491 - acc: 0.6296 - val_loss: 0.6474 - val_acc: 0.6230\n",
      "Epoch 95/100\n",
      "5400/5400 [==============================] - 0s 47us/step - loss: 0.6487 - acc: 0.6276 - val_loss: 0.6465 - val_acc: 0.6290\n",
      "Epoch 96/100\n",
      "5400/5400 [==============================] - 0s 44us/step - loss: 0.6486 - acc: 0.6261 - val_loss: 0.6509 - val_acc: 0.6260\n",
      "Epoch 97/100\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.6484 - acc: 0.6291 - val_loss: 0.6491 - val_acc: 0.6280\n",
      "Epoch 98/100\n",
      "5400/5400 [==============================] - 0s 58us/step - loss: 0.6475 - acc: 0.6320 - val_loss: 0.6456 - val_acc: 0.6280\n",
      "Epoch 99/100\n",
      "5400/5400 [==============================] - 0s 45us/step - loss: 0.6478 - acc: 0.6291 - val_loss: 0.6514 - val_acc: 0.6240\n",
      "Epoch 100/100\n",
      "5400/5400 [==============================] - 0s 36us/step - loss: 0.6470 - acc: 0.6324 - val_loss: 0.6453 - val_acc: 0.6340\n"
     ]
    }
   ],
   "source": [
    "classifier1.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history1 = classifier1.fit(partial_x_train, partial_y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5400 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "5400/5400 [==============================] - 1s 275us/step - loss: 0.7472 - acc: 0.5494 - val_loss: 0.7319 - val_acc: 0.6070\n",
      "Epoch 2/100\n",
      "5400/5400 [==============================] - 0s 66us/step - loss: 0.7267 - acc: 0.5907 - val_loss: 0.7146 - val_acc: 0.6090\n",
      "Epoch 3/100\n",
      "5400/5400 [==============================] - 0s 50us/step - loss: 0.7109 - acc: 0.5943 - val_loss: 0.7024 - val_acc: 0.6230\n",
      "Epoch 4/100\n",
      "5400/5400 [==============================] - 0s 51us/step - loss: 0.6999 - acc: 0.6057 - val_loss: 0.6965 - val_acc: 0.6090\n",
      "Epoch 5/100\n",
      "5400/5400 [==============================] - 0s 49us/step - loss: 0.6920 - acc: 0.6063 - val_loss: 0.6881 - val_acc: 0.6180\n",
      "Epoch 6/100\n",
      "5400/5400 [==============================] - 1s 139us/step - loss: 0.6862 - acc: 0.6126 - val_loss: 0.6905 - val_acc: 0.5950\n",
      "Epoch 7/100\n",
      "5400/5400 [==============================] - 0s 74us/step - loss: 0.6822 - acc: 0.6178 - val_loss: 0.6888 - val_acc: 0.5860\n",
      "Epoch 8/100\n",
      "5400/5400 [==============================] - 0s 91us/step - loss: 0.6795 - acc: 0.6087 - val_loss: 0.6842 - val_acc: 0.6220\n",
      "Epoch 9/100\n",
      "5400/5400 [==============================] - 0s 89us/step - loss: 0.6775 - acc: 0.6159 - val_loss: 0.6764 - val_acc: 0.6430\n",
      "Epoch 10/100\n",
      "5400/5400 [==============================] - 0s 80us/step - loss: 0.6754 - acc: 0.6191 - val_loss: 0.6765 - val_acc: 0.6380\n",
      "Epoch 11/100\n",
      "5400/5400 [==============================] - 0s 70us/step - loss: 0.6735 - acc: 0.6133 - val_loss: 0.6924 - val_acc: 0.6040\n",
      "Epoch 12/100\n",
      "5400/5400 [==============================] - 0s 71us/step - loss: 0.6728 - acc: 0.6191 - val_loss: 0.6732 - val_acc: 0.6400\n",
      "Epoch 13/100\n",
      "5400/5400 [==============================] - 0s 81us/step - loss: 0.6706 - acc: 0.6176 - val_loss: 0.6751 - val_acc: 0.6150\n",
      "Epoch 14/100\n",
      "5400/5400 [==============================] - 0s 86us/step - loss: 0.6701 - acc: 0.6193 - val_loss: 0.6791 - val_acc: 0.6000\n",
      "Epoch 15/100\n",
      "5400/5400 [==============================] - 0s 72us/step - loss: 0.6690 - acc: 0.6200 - val_loss: 0.6660 - val_acc: 0.6430\n",
      "Epoch 16/100\n",
      "5400/5400 [==============================] - 0s 69us/step - loss: 0.6668 - acc: 0.6243 - val_loss: 0.6697 - val_acc: 0.6460\n",
      "Epoch 17/100\n",
      "5400/5400 [==============================] - 0s 73us/step - loss: 0.6673 - acc: 0.6220 - val_loss: 0.6693 - val_acc: 0.6430\n",
      "Epoch 18/100\n",
      "5400/5400 [==============================] - 0s 71us/step - loss: 0.6657 - acc: 0.6298 - val_loss: 0.6704 - val_acc: 0.6410\n",
      "Epoch 19/100\n",
      "5400/5400 [==============================] - 0s 91us/step - loss: 0.6649 - acc: 0.6261 - val_loss: 0.6699 - val_acc: 0.6330\n",
      "Epoch 20/100\n",
      "5400/5400 [==============================] - 0s 74us/step - loss: 0.6662 - acc: 0.6220 - val_loss: 0.6690 - val_acc: 0.6210\n",
      "Epoch 21/100\n",
      "5400/5400 [==============================] - 0s 73us/step - loss: 0.6643 - acc: 0.6278 - val_loss: 0.6715 - val_acc: 0.6190\n",
      "Epoch 22/100\n",
      "5400/5400 [==============================] - 0s 77us/step - loss: 0.6628 - acc: 0.6250 - val_loss: 0.6639 - val_acc: 0.6240\n",
      "Epoch 23/100\n",
      "5400/5400 [==============================] - 0s 86us/step - loss: 0.6640 - acc: 0.6311 - val_loss: 0.6630 - val_acc: 0.6360\n",
      "Epoch 24/100\n",
      "5400/5400 [==============================] - 0s 75us/step - loss: 0.6617 - acc: 0.6307 - val_loss: 0.6782 - val_acc: 0.5920\n",
      "Epoch 25/100\n",
      "5400/5400 [==============================] - 0s 73us/step - loss: 0.6621 - acc: 0.6344 - val_loss: 0.6708 - val_acc: 0.6210\n",
      "Epoch 26/100\n",
      "5400/5400 [==============================] - 0s 70us/step - loss: 0.6612 - acc: 0.6346 - val_loss: 0.6653 - val_acc: 0.6450\n",
      "Epoch 27/100\n",
      "5400/5400 [==============================] - 0s 77us/step - loss: 0.6615 - acc: 0.6302 - val_loss: 0.6691 - val_acc: 0.6160\n",
      "Epoch 28/100\n",
      "5400/5400 [==============================] - 0s 70us/step - loss: 0.6607 - acc: 0.6276 - val_loss: 0.6596 - val_acc: 0.6410\n",
      "Epoch 29/100\n",
      "5400/5400 [==============================] - 0s 83us/step - loss: 0.6593 - acc: 0.6343 - val_loss: 0.6607 - val_acc: 0.6430\n",
      "Epoch 30/100\n",
      "5400/5400 [==============================] - 0s 74us/step - loss: 0.6595 - acc: 0.6330 - val_loss: 0.6742 - val_acc: 0.5990\n",
      "Epoch 31/100\n",
      "5400/5400 [==============================] - 1s 96us/step - loss: 0.6592 - acc: 0.6343 - val_loss: 0.6603 - val_acc: 0.6360\n",
      "Epoch 32/100\n",
      "5400/5400 [==============================] - 0s 74us/step - loss: 0.6580 - acc: 0.6344 - val_loss: 0.6693 - val_acc: 0.6280\n",
      "Epoch 33/100\n",
      "5400/5400 [==============================] - 1s 96us/step - loss: 0.6578 - acc: 0.6352 - val_loss: 0.6554 - val_acc: 0.6380\n",
      "Epoch 34/100\n",
      "5400/5400 [==============================] - 0s 69us/step - loss: 0.6580 - acc: 0.6326 - val_loss: 0.6589 - val_acc: 0.6420\n",
      "Epoch 35/100\n",
      "5400/5400 [==============================] - 0s 79us/step - loss: 0.6571 - acc: 0.6344 - val_loss: 0.6556 - val_acc: 0.6440\n",
      "Epoch 36/100\n",
      "5400/5400 [==============================] - 0s 68us/step - loss: 0.6570 - acc: 0.6417 - val_loss: 0.6615 - val_acc: 0.6360\n",
      "Epoch 37/100\n",
      "5400/5400 [==============================] - 0s 70us/step - loss: 0.6558 - acc: 0.6376 - val_loss: 0.6650 - val_acc: 0.6310\n",
      "Epoch 38/100\n",
      "5400/5400 [==============================] - 0s 55us/step - loss: 0.6573 - acc: 0.6367 - val_loss: 0.6704 - val_acc: 0.6120\n",
      "Epoch 39/100\n",
      "5400/5400 [==============================] - 0s 51us/step - loss: 0.6558 - acc: 0.6376 - val_loss: 0.6580 - val_acc: 0.6360\n",
      "Epoch 40/100\n",
      "5400/5400 [==============================] - 0s 68us/step - loss: 0.6556 - acc: 0.6367 - val_loss: 0.6588 - val_acc: 0.6370\n",
      "Epoch 41/100\n",
      "5400/5400 [==============================] - 0s 89us/step - loss: 0.6545 - acc: 0.6400 - val_loss: 0.6648 - val_acc: 0.6210\n",
      "Epoch 42/100\n",
      "5400/5400 [==============================] - 0s 70us/step - loss: 0.6541 - acc: 0.6367 - val_loss: 0.6849 - val_acc: 0.6100\n",
      "Epoch 43/100\n",
      "5400/5400 [==============================] - 0s 67us/step - loss: 0.6556 - acc: 0.6374 - val_loss: 0.6576 - val_acc: 0.6410\n",
      "Epoch 44/100\n",
      "5400/5400 [==============================] - 0s 79us/step - loss: 0.6545 - acc: 0.6407 - val_loss: 0.6668 - val_acc: 0.6190\n",
      "Epoch 45/100\n",
      "5400/5400 [==============================] - 0s 52us/step - loss: 0.6534 - acc: 0.6320 - val_loss: 0.6525 - val_acc: 0.6380\n",
      "Epoch 46/100\n",
      "5400/5400 [==============================] - 0s 53us/step - loss: 0.6522 - acc: 0.6378 - val_loss: 0.6686 - val_acc: 0.6130\n",
      "Epoch 47/100\n",
      "5400/5400 [==============================] - 0s 70us/step - loss: 0.6519 - acc: 0.6454 - val_loss: 0.6567 - val_acc: 0.6330\n",
      "Epoch 48/100\n",
      "5400/5400 [==============================] - 0s 64us/step - loss: 0.6529 - acc: 0.6394 - val_loss: 0.6556 - val_acc: 0.6400\n",
      "Epoch 49/100\n",
      "5400/5400 [==============================] - 0s 67us/step - loss: 0.6525 - acc: 0.6431 - val_loss: 0.6556 - val_acc: 0.6340\n",
      "Epoch 50/100\n",
      "5400/5400 [==============================] - 0s 51us/step - loss: 0.6514 - acc: 0.6394 - val_loss: 0.6517 - val_acc: 0.6480\n",
      "Epoch 51/100\n",
      "5400/5400 [==============================] - 0s 70us/step - loss: 0.6524 - acc: 0.6361 - val_loss: 0.6494 - val_acc: 0.6480\n",
      "Epoch 52/100\n",
      "5400/5400 [==============================] - 0s 57us/step - loss: 0.6514 - acc: 0.6417 - val_loss: 0.6719 - val_acc: 0.6110\n",
      "Epoch 53/100\n",
      "5400/5400 [==============================] - 0s 52us/step - loss: 0.6514 - acc: 0.6419 - val_loss: 0.6528 - val_acc: 0.6340\n",
      "Epoch 54/100\n",
      "5400/5400 [==============================] - 0s 52us/step - loss: 0.6499 - acc: 0.6415 - val_loss: 0.6609 - val_acc: 0.6310\n",
      "Epoch 55/100\n",
      "5400/5400 [==============================] - 0s 51us/step - loss: 0.6510 - acc: 0.6422 - val_loss: 0.6492 - val_acc: 0.6450\n",
      "Epoch 56/100\n",
      "5400/5400 [==============================] - 0s 53us/step - loss: 0.6502 - acc: 0.6437 - val_loss: 0.6810 - val_acc: 0.6020\n",
      "Epoch 57/100\n",
      "5400/5400 [==============================] - 0s 53us/step - loss: 0.6505 - acc: 0.6406 - val_loss: 0.6637 - val_acc: 0.6190\n",
      "Epoch 58/100\n",
      "5400/5400 [==============================] - 0s 52us/step - loss: 0.6497 - acc: 0.6361 - val_loss: 0.6498 - val_acc: 0.6400\n",
      "Epoch 59/100\n",
      "5400/5400 [==============================] - 0s 52us/step - loss: 0.6482 - acc: 0.6411 - val_loss: 0.6456 - val_acc: 0.6420\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400/5400 [==============================] - 0s 69us/step - loss: 0.6492 - acc: 0.6389 - val_loss: 0.6467 - val_acc: 0.6400\n",
      "Epoch 61/100\n",
      "5400/5400 [==============================] - 0s 77us/step - loss: 0.6485 - acc: 0.6417 - val_loss: 0.6613 - val_acc: 0.6310\n",
      "Epoch 62/100\n",
      "5400/5400 [==============================] - 0s 72us/step - loss: 0.6487 - acc: 0.6470 - val_loss: 0.6495 - val_acc: 0.6370\n",
      "Epoch 63/100\n",
      "5400/5400 [==============================] - 0s 71us/step - loss: 0.6494 - acc: 0.6454 - val_loss: 0.6514 - val_acc: 0.6310\n",
      "Epoch 64/100\n",
      "5400/5400 [==============================] - 0s 53us/step - loss: 0.6494 - acc: 0.6396 - val_loss: 0.6480 - val_acc: 0.6450\n",
      "Epoch 65/100\n",
      "5400/5400 [==============================] - 0s 52us/step - loss: 0.6487 - acc: 0.6420 - val_loss: 0.6496 - val_acc: 0.6370\n",
      "Epoch 66/100\n",
      "5400/5400 [==============================] - 0s 67us/step - loss: 0.6491 - acc: 0.6430 - val_loss: 0.6468 - val_acc: 0.6380\n",
      "Epoch 67/100\n",
      "5400/5400 [==============================] - 0s 51us/step - loss: 0.6480 - acc: 0.6413 - val_loss: 0.6456 - val_acc: 0.6420\n",
      "Epoch 68/100\n",
      "5400/5400 [==============================] - 0s 58us/step - loss: 0.6478 - acc: 0.6394 - val_loss: 0.6469 - val_acc: 0.6420\n",
      "Epoch 69/100\n",
      "5400/5400 [==============================] - 0s 52us/step - loss: 0.6480 - acc: 0.6454 - val_loss: 0.6464 - val_acc: 0.6580\n",
      "Epoch 70/100\n",
      "5400/5400 [==============================] - 0s 53us/step - loss: 0.6474 - acc: 0.6452 - val_loss: 0.6464 - val_acc: 0.6370\n",
      "Epoch 71/100\n",
      "5400/5400 [==============================] - 0s 52us/step - loss: 0.6469 - acc: 0.6393 - val_loss: 0.6487 - val_acc: 0.6350\n",
      "Epoch 72/100\n",
      "5400/5400 [==============================] - 0s 72us/step - loss: 0.6479 - acc: 0.6465 - val_loss: 0.6449 - val_acc: 0.6410\n",
      "Epoch 73/100\n",
      "5400/5400 [==============================] - 0s 72us/step - loss: 0.6456 - acc: 0.6426 - val_loss: 0.6492 - val_acc: 0.6590\n",
      "Epoch 74/100\n",
      "5400/5400 [==============================] - 0s 60us/step - loss: 0.6472 - acc: 0.6428 - val_loss: 0.6484 - val_acc: 0.6420\n",
      "Epoch 75/100\n",
      "5400/5400 [==============================] - 0s 59us/step - loss: 0.6449 - acc: 0.6476 - val_loss: 0.6498 - val_acc: 0.6330\n",
      "Epoch 76/100\n",
      "5400/5400 [==============================] - 0s 56us/step - loss: 0.6470 - acc: 0.6402 - val_loss: 0.6463 - val_acc: 0.6390\n",
      "Epoch 77/100\n",
      "5400/5400 [==============================] - 0s 48us/step - loss: 0.6460 - acc: 0.6411 - val_loss: 0.6584 - val_acc: 0.6260\n",
      "Epoch 78/100\n",
      "5400/5400 [==============================] - 0s 51us/step - loss: 0.6456 - acc: 0.6385 - val_loss: 0.6528 - val_acc: 0.6310\n",
      "Epoch 79/100\n",
      "5400/5400 [==============================] - 0s 50us/step - loss: 0.6458 - acc: 0.6439 - val_loss: 0.6663 - val_acc: 0.6160\n",
      "Epoch 80/100\n",
      "5400/5400 [==============================] - 0s 49us/step - loss: 0.6465 - acc: 0.6422 - val_loss: 0.6514 - val_acc: 0.6440\n",
      "Epoch 81/100\n",
      "5400/5400 [==============================] - 0s 58us/step - loss: 0.6456 - acc: 0.6457 - val_loss: 0.6540 - val_acc: 0.6290\n",
      "Epoch 82/100\n",
      "5400/5400 [==============================] - 0s 88us/step - loss: 0.6456 - acc: 0.6461 - val_loss: 0.6417 - val_acc: 0.6440\n",
      "Epoch 83/100\n",
      "5400/5400 [==============================] - 0s 85us/step - loss: 0.6454 - acc: 0.6441 - val_loss: 0.6653 - val_acc: 0.6240\n",
      "Epoch 84/100\n",
      "5400/5400 [==============================] - 0s 88us/step - loss: 0.6452 - acc: 0.6457 - val_loss: 0.6417 - val_acc: 0.6460\n",
      "Epoch 85/100\n",
      "5400/5400 [==============================] - 0s 90us/step - loss: 0.6443 - acc: 0.6430 - val_loss: 0.6443 - val_acc: 0.6420\n",
      "Epoch 86/100\n",
      "5400/5400 [==============================] - 0s 71us/step - loss: 0.6454 - acc: 0.6409 - val_loss: 0.6668 - val_acc: 0.6160\n",
      "Epoch 87/100\n",
      "5400/5400 [==============================] - 0s 88us/step - loss: 0.6450 - acc: 0.6420 - val_loss: 0.6444 - val_acc: 0.6560\n",
      "Epoch 88/100\n",
      "5400/5400 [==============================] - 0s 77us/step - loss: 0.6448 - acc: 0.6454 - val_loss: 0.6440 - val_acc: 0.6490\n",
      "Epoch 89/100\n",
      "5400/5400 [==============================] - 0s 62us/step - loss: 0.6449 - acc: 0.6457 - val_loss: 0.6428 - val_acc: 0.6410\n",
      "Epoch 90/100\n",
      "5400/5400 [==============================] - 0s 60us/step - loss: 0.6443 - acc: 0.6452 - val_loss: 0.6432 - val_acc: 0.6580\n",
      "Epoch 91/100\n",
      "5400/5400 [==============================] - 0s 56us/step - loss: 0.6445 - acc: 0.6444 - val_loss: 0.6445 - val_acc: 0.6570\n",
      "Epoch 92/100\n",
      "5400/5400 [==============================] - 0s 54us/step - loss: 0.6436 - acc: 0.6478 - val_loss: 0.6512 - val_acc: 0.6310\n",
      "Epoch 93/100\n",
      "5400/5400 [==============================] - 0s 53us/step - loss: 0.6442 - acc: 0.6420 - val_loss: 0.6404 - val_acc: 0.6490\n",
      "Epoch 94/100\n",
      "5400/5400 [==============================] - 1s 113us/step - loss: 0.6438 - acc: 0.6415 - val_loss: 0.6459 - val_acc: 0.6320\n",
      "Epoch 95/100\n",
      "5400/5400 [==============================] - 0s 72us/step - loss: 0.6439 - acc: 0.6422 - val_loss: 0.6418 - val_acc: 0.6460\n",
      "Epoch 96/100\n",
      "5400/5400 [==============================] - 0s 69us/step - loss: 0.6439 - acc: 0.6433 - val_loss: 0.6496 - val_acc: 0.6300\n",
      "Epoch 97/100\n",
      "5400/5400 [==============================] - 0s 80us/step - loss: 0.6447 - acc: 0.6463 - val_loss: 0.6642 - val_acc: 0.6270\n",
      "Epoch 98/100\n",
      "5400/5400 [==============================] - 0s 84us/step - loss: 0.6437 - acc: 0.6435 - val_loss: 0.6549 - val_acc: 0.6300\n",
      "Epoch 99/100\n",
      "5400/5400 [==============================] - 0s 83us/step - loss: 0.6440 - acc: 0.6457 - val_loss: 0.6467 - val_acc: 0.6350\n",
      "Epoch 100/100\n",
      "5400/5400 [==============================] - 0s 77us/step - loss: 0.6429 - acc: 0.6487 - val_loss: 0.6441 - val_acc: 0.6340\n"
     ]
    }
   ],
   "source": [
    "classifier2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history2 = classifier2.fit(partial_x_train, partial_y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5400 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "5400/5400 [==============================] - 2s 305us/step - loss: 0.7835 - acc: 0.5519 - val_loss: 0.7586 - val_acc: 0.5690\n",
      "Epoch 2/100\n",
      "5400/5400 [==============================] - 1s 102us/step - loss: 0.7412 - acc: 0.5780 - val_loss: 0.7296 - val_acc: 0.5890\n",
      "Epoch 3/100\n",
      "5400/5400 [==============================] - 1s 115us/step - loss: 0.7147 - acc: 0.5941 - val_loss: 0.7048 - val_acc: 0.6160\n",
      "Epoch 4/100\n",
      "5400/5400 [==============================] - 1s 108us/step - loss: 0.7001 - acc: 0.5939 - val_loss: 0.6945 - val_acc: 0.6190\n",
      "Epoch 5/100\n",
      "5400/5400 [==============================] - 1s 175us/step - loss: 0.6905 - acc: 0.6085 - val_loss: 0.6901 - val_acc: 0.6040\n",
      "Epoch 6/100\n",
      "5400/5400 [==============================] - 1s 141us/step - loss: 0.6866 - acc: 0.6067 - val_loss: 0.6884 - val_acc: 0.6040\n",
      "Epoch 7/100\n",
      "5400/5400 [==============================] - 1s 149us/step - loss: 0.6831 - acc: 0.6148 - val_loss: 0.6831 - val_acc: 0.6280\n",
      "Epoch 8/100\n",
      "5400/5400 [==============================] - 1s 132us/step - loss: 0.6807 - acc: 0.6172 - val_loss: 0.6863 - val_acc: 0.6120\n",
      "Epoch 9/100\n",
      "5400/5400 [==============================] - 1s 116us/step - loss: 0.6776 - acc: 0.6170 - val_loss: 0.6770 - val_acc: 0.6270\n",
      "Epoch 10/100\n",
      "5400/5400 [==============================] - 1s 128us/step - loss: 0.6752 - acc: 0.6213 - val_loss: 0.6732 - val_acc: 0.6360\n",
      "Epoch 11/100\n",
      "5400/5400 [==============================] - 1s 126us/step - loss: 0.6737 - acc: 0.6185 - val_loss: 0.6705 - val_acc: 0.6260\n",
      "Epoch 12/100\n",
      "5400/5400 [==============================] - 1s 121us/step - loss: 0.6719 - acc: 0.6211 - val_loss: 0.6835 - val_acc: 0.6190\n",
      "Epoch 13/100\n",
      "5400/5400 [==============================] - 1s 120us/step - loss: 0.6713 - acc: 0.6230 - val_loss: 0.6663 - val_acc: 0.6370\n",
      "Epoch 14/100\n",
      "5400/5400 [==============================] - 1s 101us/step - loss: 0.6690 - acc: 0.6209 - val_loss: 0.6809 - val_acc: 0.5980\n",
      "Epoch 15/100\n",
      "5400/5400 [==============================] - 1s 111us/step - loss: 0.6677 - acc: 0.6226 - val_loss: 0.6677 - val_acc: 0.6250\n",
      "Epoch 16/100\n",
      "5400/5400 [==============================] - 1s 102us/step - loss: 0.6680 - acc: 0.6174 - val_loss: 0.6673 - val_acc: 0.6240\n",
      "Epoch 17/100\n",
      "5400/5400 [==============================] - 1s 154us/step - loss: 0.6653 - acc: 0.6285 - val_loss: 0.6652 - val_acc: 0.6260\n",
      "Epoch 18/100\n",
      "5400/5400 [==============================] - 1s 171us/step - loss: 0.6652 - acc: 0.6250 - val_loss: 0.6717 - val_acc: 0.6290\n",
      "Epoch 19/100\n",
      "5400/5400 [==============================] - 1s 213us/step - loss: 0.6638 - acc: 0.6287 - val_loss: 0.6654 - val_acc: 0.6410\n",
      "Epoch 20/100\n",
      "5400/5400 [==============================] - 1s 133us/step - loss: 0.6630 - acc: 0.6287 - val_loss: 0.6635 - val_acc: 0.6320\n",
      "Epoch 21/100\n",
      "5400/5400 [==============================] - 1s 142us/step - loss: 0.6641 - acc: 0.6256 - val_loss: 0.6648 - val_acc: 0.6280\n",
      "Epoch 22/100\n",
      "5400/5400 [==============================] - 1s 167us/step - loss: 0.6618 - acc: 0.6270 - val_loss: 0.6663 - val_acc: 0.6250\n",
      "Epoch 23/100\n",
      "5400/5400 [==============================] - 1s 178us/step - loss: 0.6619 - acc: 0.6263 - val_loss: 0.6789 - val_acc: 0.6010\n",
      "Epoch 24/100\n",
      "5400/5400 [==============================] - 1s 188us/step - loss: 0.6618 - acc: 0.6261 - val_loss: 0.6876 - val_acc: 0.5930\n",
      "Epoch 25/100\n",
      "5400/5400 [==============================] - 1s 199us/step - loss: 0.6629 - acc: 0.6259 - val_loss: 0.6685 - val_acc: 0.6190\n",
      "Epoch 26/100\n",
      "5400/5400 [==============================] - 1s 140us/step - loss: 0.6594 - acc: 0.6274 - val_loss: 0.7003 - val_acc: 0.5680\n",
      "Epoch 27/100\n",
      "5400/5400 [==============================] - 1s 148us/step - loss: 0.6601 - acc: 0.6276 - val_loss: 0.6992 - val_acc: 0.5660\n",
      "Epoch 28/100\n",
      "5400/5400 [==============================] - 1s 174us/step - loss: 0.6595 - acc: 0.6320 - val_loss: 0.6582 - val_acc: 0.6380\n",
      "Epoch 29/100\n",
      "5400/5400 [==============================] - 1s 172us/step - loss: 0.6598 - acc: 0.6291 - val_loss: 0.6698 - val_acc: 0.6130\n",
      "Epoch 30/100\n",
      "5400/5400 [==============================] - 1s 155us/step - loss: 0.6586 - acc: 0.6309 - val_loss: 0.6653 - val_acc: 0.6310\n",
      "Epoch 31/100\n",
      "5400/5400 [==============================] - 1s 167us/step - loss: 0.6573 - acc: 0.6326 - val_loss: 0.6683 - val_acc: 0.6240\n",
      "Epoch 32/100\n",
      "5400/5400 [==============================] - 1s 145us/step - loss: 0.6578 - acc: 0.6304 - val_loss: 0.6675 - val_acc: 0.6110\n",
      "Epoch 33/100\n",
      "5400/5400 [==============================] - 1s 124us/step - loss: 0.6563 - acc: 0.6346 - val_loss: 0.6549 - val_acc: 0.6400\n",
      "Epoch 34/100\n",
      "5400/5400 [==============================] - 1s 174us/step - loss: 0.6571 - acc: 0.6315 - val_loss: 0.6671 - val_acc: 0.6290\n",
      "Epoch 35/100\n",
      "5400/5400 [==============================] - 1s 163us/step - loss: 0.6567 - acc: 0.6289 - val_loss: 0.6532 - val_acc: 0.6340\n",
      "Epoch 36/100\n",
      "5400/5400 [==============================] - 1s 147us/step - loss: 0.6550 - acc: 0.6359 - val_loss: 0.6696 - val_acc: 0.6090\n",
      "Epoch 37/100\n",
      "5400/5400 [==============================] - 1s 179us/step - loss: 0.6559 - acc: 0.6311 - val_loss: 0.6536 - val_acc: 0.6340\n",
      "Epoch 38/100\n",
      "5400/5400 [==============================] - 1s 198us/step - loss: 0.6566 - acc: 0.6300 - val_loss: 0.6533 - val_acc: 0.6320\n",
      "Epoch 39/100\n",
      "5400/5400 [==============================] - 1s 138us/step - loss: 0.6542 - acc: 0.6348 - val_loss: 0.6610 - val_acc: 0.6280\n",
      "Epoch 40/100\n",
      "5400/5400 [==============================] - 1s 135us/step - loss: 0.6554 - acc: 0.6322 - val_loss: 0.6540 - val_acc: 0.6330\n",
      "Epoch 41/100\n",
      "5400/5400 [==============================] - 1s 174us/step - loss: 0.6535 - acc: 0.6369 - val_loss: 0.6504 - val_acc: 0.6370\n",
      "Epoch 42/100\n",
      "5400/5400 [==============================] - 1s 174us/step - loss: 0.6522 - acc: 0.6422 - val_loss: 0.6556 - val_acc: 0.6240\n",
      "Epoch 43/100\n",
      "5400/5400 [==============================] - 1s 129us/step - loss: 0.6541 - acc: 0.6306 - val_loss: 0.6487 - val_acc: 0.6370\n",
      "Epoch 44/100\n",
      "5400/5400 [==============================] - 1s 126us/step - loss: 0.6527 - acc: 0.6356 - val_loss: 0.6607 - val_acc: 0.6390\n",
      "Epoch 45/100\n",
      "5400/5400 [==============================] - 1s 211us/step - loss: 0.6514 - acc: 0.6370 - val_loss: 0.6586 - val_acc: 0.6390\n",
      "Epoch 46/100\n",
      "5400/5400 [==============================] - 1s 182us/step - loss: 0.6532 - acc: 0.6330 - val_loss: 0.6555 - val_acc: 0.6320\n",
      "Epoch 47/100\n",
      "5400/5400 [==============================] - 1s 182us/step - loss: 0.6526 - acc: 0.6343 - val_loss: 0.6655 - val_acc: 0.6250\n",
      "Epoch 48/100\n",
      "5400/5400 [==============================] - 1s 157us/step - loss: 0.6517 - acc: 0.6406 - val_loss: 0.6498 - val_acc: 0.6380\n",
      "Epoch 49/100\n",
      "5400/5400 [==============================] - 1s 169us/step - loss: 0.6518 - acc: 0.6331 - val_loss: 0.6481 - val_acc: 0.6400\n",
      "Epoch 50/100\n",
      "5400/5400 [==============================] - 1s 159us/step - loss: 0.6511 - acc: 0.6396 - val_loss: 0.6628 - val_acc: 0.6180\n",
      "Epoch 51/100\n",
      "5400/5400 [==============================] - 1s 152us/step - loss: 0.6506 - acc: 0.6391 - val_loss: 0.6616 - val_acc: 0.6290\n",
      "Epoch 52/100\n",
      "5400/5400 [==============================] - 1s 135us/step - loss: 0.6516 - acc: 0.6343 - val_loss: 0.6709 - val_acc: 0.6160\n",
      "Epoch 53/100\n",
      "5400/5400 [==============================] - 1s 202us/step - loss: 0.6495 - acc: 0.6393 - val_loss: 0.6817 - val_acc: 0.6100\n",
      "Epoch 54/100\n",
      "5400/5400 [==============================] - 1s 166us/step - loss: 0.6516 - acc: 0.6322 - val_loss: 0.6535 - val_acc: 0.6400\n",
      "Epoch 55/100\n",
      "5400/5400 [==============================] - 1s 173us/step - loss: 0.6509 - acc: 0.6339 - val_loss: 0.6482 - val_acc: 0.6400\n",
      "Epoch 56/100\n",
      "5400/5400 [==============================] - 1s 186us/step - loss: 0.6507 - acc: 0.6378 - val_loss: 0.6625 - val_acc: 0.6170\n",
      "Epoch 57/100\n",
      "5400/5400 [==============================] - 1s 145us/step - loss: 0.6498 - acc: 0.6378 - val_loss: 0.6680 - val_acc: 0.6140\n",
      "Epoch 58/100\n",
      "5400/5400 [==============================] - 1s 164us/step - loss: 0.6488 - acc: 0.6402 - val_loss: 0.6711 - val_acc: 0.6150\n",
      "Epoch 59/100\n",
      "5400/5400 [==============================] - 1s 179us/step - loss: 0.6501 - acc: 0.6354 - val_loss: 0.6566 - val_acc: 0.6360\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400/5400 [==============================] - 1s 151us/step - loss: 0.6493 - acc: 0.6380 - val_loss: 0.6474 - val_acc: 0.6400\n",
      "Epoch 61/100\n",
      "5400/5400 [==============================] - 1s 171us/step - loss: 0.6483 - acc: 0.6400 - val_loss: 0.6535 - val_acc: 0.6350\n",
      "Epoch 62/100\n",
      "5400/5400 [==============================] - 1s 154us/step - loss: 0.6488 - acc: 0.6420 - val_loss: 0.6605 - val_acc: 0.6220\n",
      "Epoch 63/100\n",
      "5400/5400 [==============================] - 1s 147us/step - loss: 0.6483 - acc: 0.6422 - val_loss: 0.6563 - val_acc: 0.6240\n",
      "Epoch 64/100\n",
      "5400/5400 [==============================] - 1s 183us/step - loss: 0.6472 - acc: 0.6398 - val_loss: 0.7700 - val_acc: 0.5430\n",
      "Epoch 65/100\n",
      "5400/5400 [==============================] - 1s 176us/step - loss: 0.6496 - acc: 0.6396 - val_loss: 0.6491 - val_acc: 0.6300\n",
      "Epoch 66/100\n",
      "5400/5400 [==============================] - 1s 127us/step - loss: 0.6492 - acc: 0.6393 - val_loss: 0.6454 - val_acc: 0.6410\n",
      "Epoch 67/100\n",
      "5400/5400 [==============================] - 1s 129us/step - loss: 0.6460 - acc: 0.6413 - val_loss: 0.6423 - val_acc: 0.6440\n",
      "Epoch 68/100\n",
      "5400/5400 [==============================] - 1s 118us/step - loss: 0.6463 - acc: 0.6391 - val_loss: 0.6778 - val_acc: 0.6090\n",
      "Epoch 69/100\n",
      "5400/5400 [==============================] - 1s 168us/step - loss: 0.6480 - acc: 0.6426 - val_loss: 0.7036 - val_acc: 0.5810\n",
      "Epoch 70/100\n",
      "5400/5400 [==============================] - 1s 117us/step - loss: 0.6489 - acc: 0.6380 - val_loss: 0.6510 - val_acc: 0.6290\n",
      "Epoch 71/100\n",
      "5400/5400 [==============================] - 1s 145us/step - loss: 0.6465 - acc: 0.6420 - val_loss: 0.6447 - val_acc: 0.6360\n",
      "Epoch 72/100\n",
      "5400/5400 [==============================] - 1s 129us/step - loss: 0.6465 - acc: 0.6450 - val_loss: 0.6455 - val_acc: 0.6340\n",
      "Epoch 73/100\n",
      "5400/5400 [==============================] - 1s 169us/step - loss: 0.6458 - acc: 0.6372 - val_loss: 0.6509 - val_acc: 0.6340\n",
      "Epoch 74/100\n",
      "5400/5400 [==============================] - 1s 171us/step - loss: 0.6461 - acc: 0.6415 - val_loss: 0.6421 - val_acc: 0.6440\n",
      "Epoch 75/100\n",
      "5400/5400 [==============================] - 1s 163us/step - loss: 0.6466 - acc: 0.6378 - val_loss: 0.6414 - val_acc: 0.6540\n",
      "Epoch 76/100\n",
      "5400/5400 [==============================] - 1s 126us/step - loss: 0.6455 - acc: 0.6448 - val_loss: 0.6469 - val_acc: 0.6440\n",
      "Epoch 77/100\n",
      "5400/5400 [==============================] - 1s 158us/step - loss: 0.6459 - acc: 0.6400 - val_loss: 0.6473 - val_acc: 0.6390\n",
      "Epoch 78/100\n",
      "5400/5400 [==============================] - 1s 123us/step - loss: 0.6456 - acc: 0.6437 - val_loss: 0.6688 - val_acc: 0.6230\n",
      "Epoch 79/100\n",
      "5400/5400 [==============================] - 1s 118us/step - loss: 0.6453 - acc: 0.6441 - val_loss: 0.6414 - val_acc: 0.6430\n",
      "Epoch 80/100\n",
      "5400/5400 [==============================] - 1s 148us/step - loss: 0.6457 - acc: 0.6372 - val_loss: 0.6397 - val_acc: 0.6520\n",
      "Epoch 81/100\n",
      "5400/5400 [==============================] - 1s 185us/step - loss: 0.6465 - acc: 0.6393 - val_loss: 0.6477 - val_acc: 0.6300\n",
      "Epoch 82/100\n",
      "5400/5400 [==============================] - 1s 164us/step - loss: 0.6445 - acc: 0.6415 - val_loss: 0.6417 - val_acc: 0.6440\n",
      "Epoch 83/100\n",
      "5400/5400 [==============================] - 1s 162us/step - loss: 0.6454 - acc: 0.6420 - val_loss: 0.6389 - val_acc: 0.6580\n",
      "Epoch 84/100\n",
      "5400/5400 [==============================] - 1s 152us/step - loss: 0.6443 - acc: 0.6424 - val_loss: 0.6461 - val_acc: 0.6320\n",
      "Epoch 85/100\n",
      "5400/5400 [==============================] - 1s 166us/step - loss: 0.6431 - acc: 0.6456 - val_loss: 0.6452 - val_acc: 0.6400\n",
      "Epoch 86/100\n",
      "5400/5400 [==============================] - 1s 166us/step - loss: 0.6439 - acc: 0.6406 - val_loss: 0.6405 - val_acc: 0.6540\n",
      "Epoch 87/100\n",
      "5400/5400 [==============================] - 1s 152us/step - loss: 0.6443 - acc: 0.6457 - val_loss: 0.6418 - val_acc: 0.6460\n",
      "Epoch 88/100\n",
      "5400/5400 [==============================] - 1s 154us/step - loss: 0.6448 - acc: 0.6419 - val_loss: 0.6412 - val_acc: 0.6470\n",
      "Epoch 89/100\n",
      "5400/5400 [==============================] - 1s 157us/step - loss: 0.6459 - acc: 0.6444 - val_loss: 0.6476 - val_acc: 0.6320\n",
      "Epoch 90/100\n",
      "5400/5400 [==============================] - 1s 150us/step - loss: 0.6441 - acc: 0.6435 - val_loss: 0.6455 - val_acc: 0.6350\n",
      "Epoch 91/100\n",
      "5400/5400 [==============================] - 1s 154us/step - loss: 0.6430 - acc: 0.6478 - val_loss: 0.6510 - val_acc: 0.6340\n",
      "Epoch 92/100\n",
      "5400/5400 [==============================] - 1s 163us/step - loss: 0.6420 - acc: 0.6420 - val_loss: 0.6366 - val_acc: 0.6660\n",
      "Epoch 93/100\n",
      "5400/5400 [==============================] - 1s 146us/step - loss: 0.6425 - acc: 0.6465 - val_loss: 0.6417 - val_acc: 0.6390\n",
      "Epoch 94/100\n",
      "5400/5400 [==============================] - 1s 150us/step - loss: 0.6435 - acc: 0.6404 - val_loss: 0.6419 - val_acc: 0.6460\n",
      "Epoch 95/100\n",
      "5400/5400 [==============================] - 1s 175us/step - loss: 0.6425 - acc: 0.6454 - val_loss: 0.6378 - val_acc: 0.6580\n",
      "Epoch 96/100\n",
      "5400/5400 [==============================] - 1s 148us/step - loss: 0.6420 - acc: 0.6489 - val_loss: 0.6499 - val_acc: 0.6320\n",
      "Epoch 97/100\n",
      "5400/5400 [==============================] - 1s 127us/step - loss: 0.6439 - acc: 0.6402 - val_loss: 0.6369 - val_acc: 0.6640\n",
      "Epoch 98/100\n",
      "5400/5400 [==============================] - 1s 165us/step - loss: 0.6416 - acc: 0.6443 - val_loss: 0.6516 - val_acc: 0.6300\n",
      "Epoch 99/100\n",
      "5400/5400 [==============================] - 1s 210us/step - loss: 0.6417 - acc: 0.6470 - val_loss: 0.6459 - val_acc: 0.6350\n",
      "Epoch 100/100\n",
      "5400/5400 [==============================] - 1s 222us/step - loss: 0.6408 - acc: 0.6443 - val_loss: 0.6380 - val_acc: 0.6640\n"
     ]
    }
   ],
   "source": [
    "classifier3.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history3 = classifier3.fit(partial_x_train, partial_y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['acc', 'loss', 'val_acc', 'val_loss'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict1 = history1.history\n",
    "history_dict2 = history2.history\n",
    "history_dict3 = history3.history\n",
    "\n",
    "history_dict1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAFNCAYAAABfUShSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzs3Xl8lfWZ///XRYjaBAlUxaJIApZWloQAkVI3QFpGVnGrMNFB+GoUl6LWaRmpgp3mZ8etlNaZ+VKnlkqEUmdcwa91UnCrrQISQJQqkgBiMUYISwIk5Pr9cZ+ELOckJyQnG+/n43EeJ/fn3Pfnvs4xnlx8VnN3RERERKRt6tTaAYiIiIhIZErWRERERNowJWsiIiIibZiSNREREZE2TMmaiIiISBumZE1ERESkDVOyJiLtjpmlmJmbWefQ8ctmNj2ac4/jXvea2RNNiTdCvTeY2ZvNXa+IdDxK1kSkxZnZK2b2kzDll5vZ3xubWLn7OHdf3AxxjTKznbXq/v/c/cam1i0icryUrIlIa/gtcL2ZWa3y64Ecdy9v+ZBERNomJWsi0hqeA74KXFxZYGbdgYnA70LHE8zsPTPbZ2Y7zGx+pMrMbLWZ3Rj6Oc7MHjGzL8zsE2BCrXNnmNkHZrbfzD4xs5tD5YnAy8BZZnYg9DjLzOab2ZJq1082s/fNbG/ovv2rvZZvZveY2QYzKzaz35vZKdF8IGZ2gZm9G7ruXTO7oNprN4Ri3W9m28wsM1T+dTN7LXTNF2b2+2juJSLti5I1EWlx7l4KLAf+qVrx94AP3T0vdHww9Ho3goRrlplNiaL6mwiSviFABnB1rdc/D73eFZgB/NzMhrr7QWAcsMvdu4Qeu6pfaGbfAJYCdwJnACuBF83spFrv4zKgD5AG3NBQwGb2VWAFsBA4DXgMWGFmp4WSyIXAOHc/FbgAWB+69F+BPwLdgV7ALxu6l4i0P0rWRKS1LAauMbOvhI7/KVQGgLuvdveN7l7h7hsIkqSRUdT7PWCBu+9w9y+BB6u/6O4r3H2rB14jSHYuDldRGNcCK9z9VXcvAx4BvkKQQFVa6O67Qvd+EUiPot4JwEfu/pS7l7v7UuBDYFLo9QpgkJl9xd0/c/f3Q+VlQDJwlrsfcndNWBDpgJSsiUirCCUWhcDlZtYXOB94uvJ1M/uWma0ys0IzKwZuAU6PouqzgB3Vjguqv2hm48zsL2b2pZntBcZHWW9l3VX1uXtF6F5nVzvn79V+LgG6NLbeanGfHWrxu5bg/X9mZivM7LzQOT8EDHgn1DU7M8r3ISLtiJI1EWlNvyNoUbse+KO776722tPAC8A57p4E/CdBYtKQz4Bzqh33rvzBzE4G/pugRexMd+9G0JVZWa83UPcugpasyvosdK9Po4gr6npDelfW6+6vuPt3gZ4ELW6/DpX/3d1vcvezgJuBfzezrzcxFhFpY5SsiUhr+h3wHYJxZrWX3jgV+NLdD5nZcOAfo6xzOfB9M+sVmrQwp9prJwEnE7TolZvZOGBstdd3A6eZWVI9dU8wszFmFg/8ADgM/DnK2CJZCXzDzP7RzDqb2bXAAOAlMzszNKkhMXSvA8BRADO7xsx6herYQ5BsHm1iLCLSxihZE5FW4+75BIlOIkErWnW3Aj8xs/3A/QSJUjR+DbwC5AHrgP+pdr/9wPdDde0hSABfqPb6hwRj4z4JzfY8q1a8W4DrCAbyf0EwpmySux+JMraw3L2IYNLDD4Aigu7Nie7+BcH39A8IWt++JBi3d2vo0vOBv5rZgdD7mO3u25oSi4i0PebeUKu/iIiIiLQWtayJiIiItGFK1kRERETaMCVrIiIiIm2YkjURERGRNkzJmoiIiEgb1rm1A2gup59+uqekpLR2GCIiIiINWrt27RfufkY053aYZC0lJYU1a9a0dhgiIiIiDTKz2lvMRaRuUBEREZE2TMmaiIiISBumZE1ERESkDeswY9ZERESaoqysjJ07d3Lo0KHWDkU6kFNOOYVevXoRHx9/3HUoWRMREQF27tzJqaeeSkpKCmbW2uFIB+DuFBUVsXPnTvr06XPc9agbVEREBDh06BCnnXaaEjVpNmbGaaed1uTWWiVrIiIiIUrUpLk1x++UkjUREYlazsYcUhak0OmBTqQsSCFnY05rh9RhjBo1ildeeaVG2YIFC7j11lvrva5Lly4A7Nq1i6uvvjpi3Q2tRbpgwQJKSkqqjsePH8/evXujCb1e8+fP55FHHmlyPeGYGddff33VcXl5OWeccQYTJ05sVD0pKSl88cUXx3XO3LlzOeecc6r+O8SCkjUREYlKzsYcsl7MoqC4AMcpKC4g68UsJWzNZNq0aSxbtqxG2bJly5g2bVpU15911lk888wzx33/2snaypUr6dat23HX1xISExPZtGkTpaWlALz66qucffbZLRrDpEmTeOedd2J6DyVrIiISlbm5cykpK6lRVlJWwtzcua0UUevKyYGUFOjUKXjOaWLOevXVV/PSSy9x+PBhAPLz89m1axcXXXQRBw4cYMyYMQwdOpTU1FSef/75Otfn5+czaNAgAEpLS5k6dSppaWlce+21VckMwKxZs8jIyGDgwIHMmzcPgIULF7Jr1y5Gjx7N6NGjgZotSY899hiDBg1i0KBBLFiwoOp+/fv356abbmLgwIGMHTu2xn3CWb9+PSNGjCAtLY0rrriCPXv2VN1/wIABpKWlMXXqVABee+010tPTSU9PZ8iQIezfvz9snePGjWPFihUALF26tEZy++WXXzJlyhTS0tIYMWIEGzZsAKCoqIixY8cyZMgQbr75Zty96polS5YwfPhw0tPTufnmmzl69Gi972nEiBH07Nmz3nOazN07xGPYsGEuIiKxY/PNmU+dh8231g6tWWzevDnqc5cscU9IcIdjj4SEoLwpxo8f788995y7uz/44IN+zz33uLt7WVmZFxcXu7t7YWGhn3vuuV5RUeHu7omJie7uvm3bNh84cKC7uz/66KM+Y8YMd3fPy8vzuLg4f/fdd93dvaioyN3dy8vLfeTIkZ6Xl+fu7snJyV5YWFgVS+XxmjVrfNCgQX7gwAHfv3+/DxgwwNetW+fbtm3zuLg4f++999zd/ZprrvGnnnqqznuaN2+eP/zww+7unpqa6qtXr3Z39/vuu89nz57t7u49e/b0Q4cOubv7nj173N194sSJ/uabb7q7+/79+72srKxO3YmJiZ6Xl+dXXXWVl5aW+uDBg33VqlU+YcIEd3e//fbbff78+e7unpub64MHD3Z39zvuuMMfeOABd3d/6aWXHPDCwkLfvHmzT5w40Y8cOeLu7rNmzfLFixeH/XzCxRJJuN8tYI1HmeOoZU1ERKLSO6l3o8o7srlzoaRmIyMlJUF5U1TvCq3eBeru3HvvvaSlpfGd73yHTz/9lN27d0es5/XXX+e6664DIC0tjbS0tKrXli9fztChQxkyZAjvv/8+mzdvrjemN998kyuuuILExES6dOnClVdeyRtvvAFAnz59SE9PB2DYsGHk5+dHrKe4uJi9e/cycuRIAKZPn87rr79eFWNmZiZLliyhc+dgVbELL7yQu+++m4ULF7J3796q8trS0tLIz89n6dKljB8/vk7slWPaLr30UoqKiiguLq7x+UyYMIHu3bsDkJuby9q1azn//PNJT08nNzeXTz75pN7PpyUoWRMRkahkj8kmIT6hRllCfALZY7JbKaLWs31748qjNWXKFHJzc1m3bh2lpaUMHToUgJycHAoLC1m7di3r16/nzDPPbHA5iHCzELdt28YjjzxCbm4uGzZsYMKECQ3W49W6CGs7+eSTq36Oi4ujvLy83roiWbFiBbfddhtr165l2LBhlJeXM2fOHJ544glKS0sZMWIEH374YcTrJ0+ezD333FNnfF+42Cs/l3Cfj7szffp01q9fz/r169myZQvz588/rvfUnJSsiYhIVDJTM1k0aRHJSckYRnJSMosmLSIzNbO1Q2txvSM0JkYqj1aXLl0YNWoUM2fOrJF4FBcX06NHD+Lj41m1ahUFBQX11nPJJZeQExpEt2nTpqqxWvv27SMxMZGkpCR2797Nyy+/XHXNqaeeGnZc2CWXXMJzzz1HSUkJBw8e5Nlnn+Xiiy9u9HtLSkqie/fuVa1yTz31FCNHjqSiooIdO3YwevRoHnroIfbu3cuBAwfYunUrqamp/OhHPyIjI6PeZG3mzJncf//9pKamRvwcVq9ezemnn07Xrl1rlL/88stVY+fGjBnDM888w+effw4EY94a+qxbgnYwEBGRqGWmZp6QyVlt2dmQlVWzKzQhIShvqmnTpnHllVfWmBmamZnJpEmTyMjIID09nfPOO6/eOmbNmsWMGTNIS0sjPT2d4cOHAzB48GCGDBnCwIED6du3LxdeeGHVNVlZWYwbN46ePXuyatWqqvKhQ4dyww03VNVx4403MmTIkHq7PCNZvHgxt9xyCyUlJfTt25cnn3ySo0ePct1111FcXIy7c9ddd9GtWzfuu+8+Vq1aRVxcHAMGDGDcuHER6+3VqxezZ8+uUz5//vyqzyEhIYHFixcDMG/ePKZNm8bQoUMZOXIkvUNZ9oABA/jpT3/K2LFjqaioID4+nscff5zk5OSI9/7hD3/I008/TUlJCb169eLGG29s9tY4q695sz3JyMjwhtaQERERieSDDz6gf//+UZ+fkxOMUdu+PWhRy86GTOWxEka43y0zW+vuGdFcr5Y1ERGR45CZqeRMWobGrImIiIi0YUrWRERERNowJWsiIiIibZiSNREREZE2TMmaiIiISBumZE1ERKQNGDVqFK+88kqNsgULFnDrrbfWe12XLl0A2LVrF1dffXXEuhta3mrBggWUVFs4bvz48ezduzea0Os1f/58HnnkkSbXE46ZVW0nBVBeXs4ZZ5zBxIkTG1VP9U3rG3NOSUkJEyZM4LzzzmPgwIHMmTOnUfeNlpI1ERGRNqD6vqCVqu8P2pCzzjqLZ5555rjvXztZW7lyJd26dTvu+lpCYmIimzZtorS0FIBXX32Vs88+u0VjuOeee/jwww957733eOutt2rsCtFclKyJiIi0AVdffTUvvfQShw8fBiA/P59du3Zx0UUXceDAAcaMGcPQoUNJTU3l+eefr3N9fn4+gwYNAqC0tJSpU6eSlpbGtddeW5XMQLC7QUZGBgMHDmTevHkALFy4kF27djF69GhGjx4N1GxJeuyxxxg0aBCDBg1iwYIFVffr378/N910EwMHDmTs2LE17hPO+vXrGTFiBGlpaVxxxRVV2zwtXLiQAQMGkJaWxtSpUwF47bXXSE9PJz09nSFDhoTdCgtg3LhxrFixAoClS5fWSG6//PJLpkyZQlpaGiNGjKjadquoqIixY8cyZMgQbr755hp7iC5ZsoThw4eTnp7OzTffzNGjRyO+n4SEhKrP66STTmLo0KHs3Lmz3s/guLh7zB7AZcAW4GNgTpjXfw6sDz3+Buyt9lpv4I/AB8BmIKW+ew0bNsxFRESO1+bNm1s7BB8/frw/99xz7u7+4IMP+j333OPu7mVlZV5cXOzu7oWFhX7uued6RUWFu7snJia6u/u2bdt84MCB7u7+6KOP+owZM9zdPS8vz+Pi4vzdd991d/eioiJ3dy8vL/eRI0d6Xl6eu7snJyd7YWFhVSyVx2vWrPFBgwb5gQMHfP/+/T5gwABft26db9u2zePi4vy9995zd/drrrnGn3rqqTrvad68ef7www+7u3tqaqqvXr3a3d3vu+8+nz17tru79+zZ0w8dOuTu7nv27HF394kTJ/qbb77p7u779+/3srKyOnUnJiZ6Xl6eX3XVVV5aWuqDBw/2VatW+YQJE9zd/fbbb/f58+e7u3tubq4PHjzY3d3vuOMOf+CBB9zd/aWXXnLACwsLffPmzT5x4kQ/cuSIu7vPmjXLFy9eHPbzqW3Pnj3ep08f37p1a53Xwv1uAWs8ynwqZjsYmFkc8DjwXWAn8K6ZveDum6slindVO/8OYEi1Kn4HZLv7q2bWBaiIVawiIiLV3XknrF/fvHWmp0OoUSqiyq7Qyy+/nGXLlvGb3/wGCBpW7r33Xl5//XU6derEp59+yu7du/na174Wtp7XX3+d73//+wCkpaWRlpZW9dry5ctZtGgR5eXlfPbZZ2zevLnG67W9+eabXHHFFSQmJgJw5ZVX8sYbbzB58mT69OlDeno6AMOGDat3v9Di4mL27t3LyJEjAZg+fTrXXHNNVYyZmZlMmTKFKVOmAHDhhRdy9913k5mZyZVXXkmvXr3C1puWlkZ+fj5Lly5l/PjxdWL/7//+bwAuvfRSioqKKC4u5vXXX+d//ud/AJgwYQLdu3cHIDc3l7Vr13L++ecDQQtljx49Ir6nSuXl5UybNo3vf//79O3bt8HzGyuW3aDDgY/d/RN3PwIsAy6v5/xpwFIAMxsAdHb3VwHc/YC7l9RzrYiISLs3ZcoUcnNzWbduHaWlpQwdOhSAnJwcCgsLWbt2LevXr+fMM8/k0KFD9dZlZnXKtm3bxiOPPEJubi4bNmxgwoQJDdbj9ewhfvLJJ1f9HBcXR3l5eb11RbJixQpuu+021q5dy7BhwygvL2fOnDk88cQTlJaWMmLECD788MOI10+ePJl77rmnzvi+cLFXfi7hPh93Z/r06axfv57169ezZcuWqDZlz8rKol+/ftx5550Nnns8Yrk36NnAjmrHO4FvhTvRzJKBPsCfQkXfAPaa2f+Eyv+XoBs1csexiIhIM2moBSxWunTpwqhRo5g5c2aNxKO4uJgePXoQHx/PqlWrKCgoqLeeSy65hJycHEaPHs2mTZuqxmrt27ePxMREkpKS2L17Ny+//DKjRo0C4NRTT2X//v2cfvrpdeq64YYbmDNnDu7Os88+y1NPPdXo95aUlET37t154403uPjii3nqqacYOXIkFRUV7Nixg9GjR3PRRRfx9NNPc+DAAYqKikhNTSU1NZW3336bDz/8kPPOOy9s3TNnziQpKYnU1FRWr15d53O47777WL16Naeffjpdu3atKv/xj3/Myy+/XDV2bsyYMVx++eXcdddd9OjRgy+//JL9+/eTnJwc8X39+Mc/pri4mCeeeKLRn0m0Ypms1U1ZIVJ6PhV4ploy1hm4mKBbdDvwe+AG4L9q3MAsC8gC6N27d9MjrkfOxhzm5s5le/F2eif1JntMNpmp2sFXRESa17Rp07jyyitrzAzNzMxk0qRJZGRkkJ6eHjFpqTRr1ixmzJhBWloa6enpDB8+HIDBgwczZMgQBg4cSN++fbnwwgurrsnKymLcuHH07NmTVatWVZUPHTqUG264oaqOG2+8kSFDhtTb5RnJ4sWLueWWWygpKaFv3748+eSTHD16lOuuu47i4mLcnbvuuotu3bpx3333sWrVKuLi4hgwYADjxo2LWG+vXr2YPXt2nfL58+dXfQ4JCQksXrwYgHnz5jFt2jSGDh3KyJEjq3KIAQMG8NOf/pSxY8dSUVFBfHw8jz/+eMRkbefOnWRnZ3PeeedVtYLefvvt3HjjjY3+bOpj9TVvNqlis28D8939H0LH/wLg7g+GOfc94DZ3/3PoeATwM3cfFTq+Hhjh7rdFul9GRoY3tIbM8crZmEPWi1mUlB3riU2IT2DRpEVK2EREOogPPviA/v37t3YY0gGF+90ys7XunhHN9bEcs/Yu0M/M+pjZSQStZy/UPsnMvgl0B96udW13MzsjdHwpwYzQVjE3d26NRA2gpKyEublzWykiEREROVHELFlz93LgduAVguU3lrv7+2b2EzObXO3UacAyr9bEF+oOvQfINbONBF2qv45VrA3ZXry9UeUiIiIizSWWY9Zw95XAylpl99c6nh/h2leByHOJW1DvpN4UFNcdzNk7Kbbj5ERERES0g0EUssdkkxCfUKMsIT6B7DHZrRSRiIiInCiUrEUhMzWTRZMWkZyUjGEkJyVrcoGIiIi0iJh2g3YkmamZSs5ERESkxallTUREpA0YNWoUr7zySo2yBQsWcOutt9Z7XZcuXQDYtWsXV199dcS6G1reasGCBZSUHFv5YPz48ezduzea0Os1f/58HnnkkSbXE46Zcf3111cdl5eXc8YZZzBx4sRG1VN90/rGnnPZZZcxePBgBg4cyC233FLvxu/HS8maiIhIG1C5L2h1y5Ytq7OFUiRnnXUWzzzzzHHfv3aytnLlSrp163bc9bWExMRENm3aRGlpKQCvvvoqZ599dovGsHz5cvLy8ti0aROFhYX84Q9/aPZ7KFkTERE5Djkbc0hZkEKnBzqRsiCFnI05Tarv6quv5qWXXuLw4cMA5Ofns2vXLi666CIOHDjAmDFjGDp0KKmpqTz//PN1rs/Pz2fQoEFAsAH51KlTSUtL49prr61KZiDY3SAjI4OBAwcyb948ABYuXMiuXbsYPXo0o0ePBmq2JD322GMMGjSIQYMGsSC0F1d+fj79+/fnpptuYuDAgYwdO7bGfcJZv349I0aMIC0tjSuuuKJqm6eFCxcyYMAA0tLSmDp1KgCvvfYa6enppKenM2TIEPbv3x+2znHjxrFixQoAli5dWiO5/fLLL5kyZQppaWmMGDGiatutoqIixo4dy5AhQ7j55ptr7CG6ZMkShg8fTnp6OjfffHODLWVdu3YFgla9I0eOhN1ztMncvUM8hg0b5iIiIsdr8+bNUZ+7ZMMST8hOcOZT9UjITvAlG5Y0KYbx48f7c8895+7uDz74oN9zzz3u7l5WVubFxcXu7l5YWOjnnnuuV1RUuLt7YmKiu7tv27bNBw4c6O7ujz76qM+YMcPd3fPy8jwuLs7fffddd3cvKipyd/fy8nIfOXKk5+Xlubt7cnKyFxYWVsVSebxmzRofNGiQHzhwwPfv3+8DBgzwdevW+bZt2zwuLs7fe+89d3e/5ppr/KmnnqrznubNm+cPP/ywu7unpqb66tWr3d39vvvu89mzZ7u7e8+ePf3QoUPu7r5nzx53d584caK/+eab7u6+f/9+Lysrq1N3YmKi5+Xl+VVXXeWlpaU+ePBgX7VqlU+YMMHd3W+//XafP3++u7vn5ub64MGD3d39jjvu8AceeMDd3V966SUHvLCw0Ddv3uwTJ070I0eOuLv7rFmzfPHixWE/n+rGjh3r3bp182nTpnl5eXmd18P9bgFrPMocRy1rIiIijRSrnW2qd4VW7wJ1d+69917S0tL4zne+w6effsru3bsj1vP6669z3XXXAZCWlkZa2rFlS5cvX87QoUMZMmQI77//Pps3179B0JtvvskVV1xBYmIiXbp04corr+SNN94AoE+fPqSnpwMwbNiwevcLLS4uZu/evYwcORKA6dOn8/rrr1fFmJmZyZIlS+jcOZj7eOGFF3L33XezcOFC9u7dW1VeW1paGvn5+SxdupTx48fXib1yTNull15KUVERxcXFNT6fCRMm0L17dwByc3NZu3Yt559/Punp6eTm5vLJJ5/U+/kAvPLKK3z22WccPnyYP/3pTw2e31hK1kRERBopVjvbTJkyhdzcXNatW0dpaWnV5uA5OTkUFhaydu1a1q9fz5lnnsmhQ4fqrStcd9y2bdt45JFHyM3NZcOGDUyYMKHBeryePcRPPvnkqp/j4uIoLy+vt65IVqxYwW233cbatWsZNmwY5eXlzJkzhyeeeILS0lJGjBjBhx9+GPH6yZMnc88999QZ3xcu9srPJdzn4+5Mnz6d9evXs379erZs2cL8+fOjeg+nnHIKkydPDttF3VRK1kRERBop0g42Td3ZpkuXLowaNYqZM2fWSDyKi4vp0aMH8fHxrFq1ioKCurvqVHfJJZeQkxOModu0aVPVWK19+/aRmJhIUlISu3fv5uWXX6665tRTTw07LuySSy7hueeeo6SkhIMHD/Lss89y8cUXN/q9JSUl0b1796pWuaeeeoqRI0dSUVHBjh07GD16NA899BB79+7lwIEDbN26ldTUVH70ox+RkZFRb7I2c+ZM7r//flJTUyN+DqtXr+b000+na9euNcpffvnlqrFzY8aM4ZlnnuHzzz8HgjFv9X3WBw4c4LPPPgOCMWsrV67kvPPOa/Rn0xCtsyYiItJI2WOyyXoxq0ZXaHPtbDNt2jSuvPLKGjNDMzMzmTRpEhkZGaSnpzeYEMyaNYsZM2aQlpZGeno6w4cPB2Dw4MEMGTKEgQMH0rdvXy688MKqa7Kyshg3bhw9e/Zk1apVVeVDhw7lhhtuqKrjxhtvZMiQIfV2eUayePFibrnlFkpKSujbty9PPvkkR48e5brrrqO4uBh356677qJbt27cd999rFq1iri4OAYMGMC4ceMi1turVy9mz55dp3z+/PlVn0NCQgKLFy8GYN68eUybNo2hQ4cycuRIevcOkuwBAwbw05/+lLFjx1JRUUF8fDyPP/44ycnJYe978OBBJk+ezOHDhzl69CiXXnopt9xyS6M/l4ZYfc2b7UlGRoY3tIaMiIhIJB988AH9+/eP+vycjTnMzZ3L9uLt9E7qTfaYbC2eLmGF+90ys7XunhHN9WpZExEROQ7a2UZaisasiYiIiLRhStZERERE2jAlayIiIiEdZRy3tB3N8TulZE1ERIRgnayioiIlbNJs3J2ioiJOOeWUJtWjCQYiIiIEyz/s3LmTwsLC1g5FOpBTTjmFXr16NakOJWsiIiJAfHw8ffr0ae0wROpQN6iIiIhIG6ZkTURERKQNU7ImIiIi0oYpWRMRERFpw5SsiYiIiLRhStZERERE2jAlayIiIiJtmJI1ERERkTZMyZqIiIhIGxbTZM3MLjOzLWb2sZnNCfP6z81sfejxNzPbW+v1rmb2qZn9KpZxioiIiLRVMdtuyszigMeB7wI7gXfN7AV331x5jrvfVe38O4Ahtar5V+C1WMUoIiIi0tbFsmVtOPCxu3/i7keAZcDl9Zw/DVhaeWBmw4AzgT/GMEYRERGRNi2WydrZwI5qxztDZXWYWTLQB/hT6LgT8CjwzzGMT0RERKTNi2WyZmHKPMK5U4Fn3P1o6PhWYKW774hwfnADsywzW2NmawoLC5sQqoiIiEjbFLMxawQtaedUO+4F7IrUBIIrAAAgAElEQVRw7lTgtmrH3wYuNrNbgS7ASWZ2wN1rTFJw90XAIoCMjIxIiaCIiIhIuxXLZO1doJ+Z9QE+JUjI/rH2SWb2TaA78HZlmbtnVnv9BiCjdqImIiIiciKIWTeou5cDtwOvAB8Ay939fTP7iZlNrnbqNGCZu6tlTERERKQW6yg5UkZGhq9Zs6a1wxARERFpkJmtdfeMaM7VDgYiIiIibZiSNREREZE2TMmaiIiISBumZE1ERESkDVOyJiIiItKGKVkTERERacOUrImIiIi0YUrWRERERNowJWsiIiIibZiStShVVMCYMbBgQWtHIiIiIicSJWtR6tQJ8vPhL39p7UhERETkRKJkrRH694cPPjh2nLMxh5QFKXR6oBMpC1LI2ZjTesGJiIhIh9S5tQNoT/r3h//9Xzh6FJZtziHrxSxKykoAKCguIOvFLAAyUzNbM0wRERHpQNSy1gj9+8Phw7BtG8zNnVuVqFUqKSthbu7cVopOREREOiIla43Qv3/w/MEHsL14e9hzIpWLiIiIHA8la41QPVnrndQ77DmRykVERESOh5K1RujWDb72tSBZyx6TTUJ8Qo3XE+ITyB6T3UrRiYiISEekZK2RKmeEZqZmsmjSIpKTkjGM5KRkFk1apMkFIiIi0qw0G7SR+veHJUvAPUjYlJyJiIhILKllrZH694d9++Czz1o7EhERETkRKFlrpOqTDERERERiTclaIylZExERkZakZK2RevaEpCTYvLm1IxEREZETgZK1RjKru0eoiIiISKwoWTsOStZERESkpShZOw79+8Pu3bBnT2tHIiIiIh2dkrXjoEkGIiIi0lIaTNbM7CEz62pm8WaWa2ZfmNl1LRFcW6VkTURERFpKNC1rY919HzAR2Al8A/jnaCo3s8vMbIuZfWxmc8K8/nMzWx96/M3M9obK083sbTN738w2mNm1jXhPMZeSAiefrGRNREREYi+a7abiQ8/jgaXu/qWZNXiRmcUBjwPfJUjy3jWzF9y9atELd7+r2vl3AENChyXAP7n7R2Z2FrDWzF5x973RvKlYi4uDb35TyZqIiIjEXjQtay+a2YdABpBrZmcAh6K4bjjwsbt/4u5HgGXA5fWcPw1YCuDuf3P3j0I/7wI+B86I4p4tRjNCRUREpCU0mKy5+xzg20CGu5cBB6k/6ap0NrCj2vHOUFkdZpYM9AH+FOa14cBJwNYo7tli+veH/HwoKWntSERERKQji2aCwTVAubsfNbMfA0uAs6KoO1xfqUc4dyrwjLsfrXXvnsBTwAx3rwgTW5aZrTGzNYWFhVGE1Hz69wd32LKlRW8rIiIiJ5houkHvc/f9ZnYR8A/AYuA/orhuJ3BOteNewK4I504l1AVaycy6AiuAH7v7X8Jd5O6L3D3D3TPOOKNle0k1I1RERERaQjTJWmVr1wTgP9z9eYJuyYa8C/Qzsz5mdhJBQvZC7ZPM7JtAd+DtamUnAc8Cv3P3P0Rxrxb3jW9Ap05K1kRERCS2oknWPjWz/wt8D1hpZidHc527lwO3A68AHwDL3f19M/uJmU2uduo0YJm7V+8i/R5wCXBDtaU90qN8Ty3i5JPh3HOVrImIiEhsWc0cKcwJZgnAZcDG0FIaPYFUd/9jSwQYrYyMDF+zZk2L3vPyy+Hjj+H991v0tiIiItLOmdlad8+I5txoWshKCGZi/oOZ3Q70aGuJWmvp3x8++gjKy1s7EhEREemoopkNOhvIAXqEHktCC9ie8Pr3h7Iy2NqmFhURERGRjiSaMWv/B/iWu9/v7vcDI4CbYhtW25OTE2wz1alT8JyToxmhIiIiEnvRJGvGsRmhhH5ueL+pDiQnB7KyoKAgWFutoCA4zssLXt+8uf7rRURERI5XNHuDPgn81cyeDR1PAX4Tu5Danrlz6+5UUFIC2dlw9tlK1kRERCR2GkzW3P0xM1sNXETQojbD3d+LdWBtyfbtkcsnTIAWnoQqIiIiJ5BoWtZw93XAuspjM9vu7r1jFlUb07t30PUZrvzCC+Gll+CLL+D001s+NhEREenYohmzFs4JNWYtOxsSEmqWJSQE5RdcEBz/JeyGWCIiIiJNc7zJWv0r6XYwmZmwaBEkJ4NZ8LxoUVCekQGdO8Of/9zaUYqIiEhHFLEb1MzujvQS0CU24bRdmZnBo7aEBBgyBN56q+VjEhERkY6vvpa1UyM8ugC/iH1o7ccFF8A77wQL5IqIiIg0p4gta+7+QEsG0p5deCH84hewfj2cf35rRyMiIiIdyfGOWZNqvv3t4Fnj1kRERKS5KVlrBr16Bct4KFkTERGR5qZkrZlccIGSNREREWl+DS6Ka2YnA1cBKdXPd/efxC6s9ueCC2DZMtixA845p7WjERERkY4impa154HLgXLgYLWHVFO5OK5a10RERKQ5RbPdVC93vyzmkbRzgwcHa679+c9w7bWtHY2IiIh0FNG0rP3ZzFJjHkk717kzfOtbWhxXREREmlc0ydpFwFoz22JmG8xso5ltiHVg7dEFFwRrrR1UJ7GIiIg0k2i6QcfFPIoO4oIL4OiAHM795Vw+P7yd3km9yR6TTWZqmH2qRERERKLQYLLm7gVmNhi4OFT0hrvnxTas9mln9xyYlMXuwyUAFBQXkPViFoASNhERETkuDXaDmtlsIAfoEXosMbM7Yh1Ye5CTAykp0KlT8Hzvn+bCSSU1zikpK2Fu7txWiU9EpD3K2ZhDyoIUOj3QiZQFKeRszGntkERaVTTdoP8H+Ja7HwQws38D3gZ+GcvA2rqcHMjKgpJQblZQAJRtB6t77vbi7S0am4hIe5WzMYesF7MoKVMPhUilaCYYGHC02vFRwqYkJ5a5c48lalWKe4c9t3dS+HIREalpbu7cqkStknoo5EQXTbL2JPBXM5tvZvOBvwD/FdOo2oHt4RrLcrPhSEKNooT4BLLHZLdMUCIi7Vykngj1UMiJrMFkzd0fA2YAXwJ7gBnuviDWgbV1vcM1lm3M5Kt/XkSnfcngRnJSMosmLVLTvYhIlCL1RKiHQk5kEZM1M+saev4qkA8sAZ4CCkJlJ7Ts7GDHguoSEmDhjZlM2prPWb+u4G+35itRExFphOwx2STEq4dCpLr6WtaeDj2vBdZUe1QeN8jMLgstpvuxmc0J8/rPzWx96PE3M9tb7bXpZvZR6DE96nfUQjIzYdEiSE4Gs+B50aKgfNYs2LUrmIQgHYNmp4m0jMzUTBZNWkRyUjKGeihEAMzdY1OxWRzwN+C7wE7gXWCau2+OcP4dwBB3nxlquVsDZABOkCAOc/c9ke6XkZHha9ZElUPGnDsMHQqlpbB5c7C0h7RftWenQfAvff0BERGR42Vma909I5pzo1lnLTeasjCGAx+7+yfufgRYBlxez/nTgKWhn/8BeNXdvwwlaK8C7WYzeTOYMwe2bIHnn2/taKSpNDtNRERaU31j1k4JtXCdbmbdzeyroUcKcFYUdZ8N7Kh2vDNUFu5eyUAf4E+NvbatuuoqOPdc+NnPgpY2ab8izUIrKC5Q16iIiMRcfS1rNxN0P54Xeq58PA88HkXd4dZii5S2TAWecffK9dyiutbMssxsjZmtKSwsjCKkltO5M/zzP8M778Dq1a0djTRFpFlohlFQXIDjVQt3KmETEZHmFjFZc/dfuHsf4B537+vufUKPwe7+qyjq3gmcU+24F7ArwrlTOdYFGvW17r7I3TPcPeOMM86IIqSWNX06fO1rQeuatF/hZqcZhtf694O6RkVEJBaiWWftl2Y2yMy+Z2b/VPmIou53gX5m1sfMTiJIyF6ofZKZfRPoTrCFVaVXgLGh7tfuwNhQWbtyyilw113wxz/CunWtHY0cr3Cz02onapW0cKeIiDS3aCYYzCPYB/SXwGjgIWByQ9e5ezlwO0GS9QGw3N3fN7OfmFn166cBy7zatFR3/xL4V4KE713gJ6GyNq/25u7du0NSEvzbv7V2ZNIUmamZ5N+ZT8W8CvLvzCc5KTnseVq4U0REmluDS3eY2UZgMPCeuw82szOBJ9x9UksEGK22sHRH7c3dIVgod8wYWLECPvwQ+vVrvfik+Wg5DxERaYpmXboDKHX3CqA8tKvB50DfpgTYUYXb3L2kBN57D+Lj4ZFHWicuaX5auFNERFpKNC1r/w7cSzDm7AfAAWC9u8+IfXjRawsta506hV+mwyxocfvtb6GwEE49tcVDExERkTakWVvW3P1Wd9/r7v9JsBvB9LaWqLUVYTd3B746Mofn+qRweE4n+i7UelwiIiISvc6RXjCzofW95u6a31hLdnbdMWvxw3LYPzqLI4dKwOCL8mA9LkBdZiIiItKgiMka8Gjo+RSCPTrzCBarTQP+ClwU29Dan8xQ7jV3LmzfHrS0HbhiLkXl4bcqUrImIiIiDalvUdzR7j4aKACGhhafHQYMAT5uqQDbm8xMyM+Hiorg+cvy8OtuaT0uERERiUY0s0HPc/eNlQfuvglIj11IHUukdbe0HpeIiIhEI5pk7QMze8LMRpnZSDP7NcEitxKFcFsVUZbA/IuzWycgERERaVeiSdZmAO8Ds4E7gc2hMolC7fW4epycDC8s4quftu54tVdegT/8oVVDEBERkSg0uM5ae9EW1lmLRllZsLn7hAnwu9+1XhwjRsDnn8Mnn7ReDCIiIieqZllnzcyWh543mtmG2o/mCvZEEx8Pl18Oz2zJIfnnKXR6oBMpC1p27bWKCnj/fSgogCNHWuy2IiIichzqW7pjduh5YksE0pHl5NRczmPgtBxKe2axfV+wpEdBcc211w4cgC5dYhdPQQEcOBD8/MkncN55sbuXiIiINE19S3d8FnouCPdouRDbt8rN3QsKgq2oCgrg5cNz4aS6a6/dmzuXO++Erl2Da774IjYxbdp07OePPorNPURERKR51NcNut/M9oV57DezfS0ZZHsWbnN37xph7bW9BfzCUvD7O/HrxBRSJuWwaBEcPdq8MW3ceOxnJWsiIiJtW30ta6e6e9cwj1PdvWtLBtmebQ+XlxVHWmPNoFsBmEO3Akq/m8XNv8rh29+Gd99tvpg2boTkZOjeXcmaiIhIWxfN0h0AmFkPM+td+YhlUB1J2M3dc7Oxslprr7kFSVo1FXElnH7tXHbsgG99C1aubJ6YNm2CQYOgXz/4+ATfiyJnYw4pC1pnooeIiEg0GkzWzGyymX0EbANeA/KBl2McV4eRnQ0JtfKyhK2Z3HL2IhLKksGNuP3JdRK1SkXl29myJZgEcPvtUFratHiOHIEPP4TUVPj610/slrWcjTlkvZhFQXEBjldN9FDCJiIibUk0LWv/CowA/ubufYAxwFsxjaoDycyERYuCbkez4HnRIvj3WZm8eVU+139Swfa780lOSg57fe+k3nTtCr/6FWzbBg89FJQfb4vQ3/4G5eXHWta2b4dDh5rr3bYvc3PnUlJWd6LH3Ny5rRSRiIhIXdEka2XuXgR0MrNO7r4K7Q3aKLU3d88MbV4wZEiwMO5ZZ4XfliohPoHsMcG2VJdeCt/7HvzsZ7Ag9/hbhConF6SmBsma+4m7MO724ggTPSKUi4iItIZokrW9ZtYFeB3IMbNfAOWxDevEU3tbquSkZBZNWkRm6rFtqR59FOLi4N4/HX+L0KZN0Llz0K3ar19QdqJ2hfZOCj/0MlK5iIhIa4gmWbscKAXuAv4fsBWYFMugTgQ5OZCSAp06Bc85OUHCln9nPhXzKsi/M79GogbQqxfcdx+Uxh9/i9DGjfCNb8BJJylZa6g1U0REpC2ob521X5nZBe5+0N2Punu5uy9294WhblE5TuEWys3KCsobctdd0Lnk+FuENm0KukAhWLrjtNNO3GQtmtZMERGR1lZfy9pHwKNmlm9m/2ZmGqfWTMItlFtSEpQ35KST4AeDs+FI41uE9u8PJikMGnSs7ESfEdpQa6Y0v1tvhf/4j9aOQkSk/ahvUdxfuPu3gZHAl8CTZvaBmd1vZt9osQg7oLAL5dZTXnvmZ2oaZPx9EVbcuBahzZuD58qWNTi21prWG5OW4B5MqnnxxdaORESk/WhwzFpoL9B/c/chwD8CVwAfxDyyDizsQrkRyiOtBXb9ddD5V/ncvT/6FqHqM0Er9esHO7rlcNMLWm9MYm/3bjh4EHbtau1IRETaj2gWxY03s0lmlkOwGO7fgKtiHlkHFnah3ISgvLZIa4E9ljeXceNg6dLo9w7duBESE4MJDZX69QPGzKW0XOuNSext3Ro8K1kTEYlefRMMvmtmvwF2AlnASuBcd7/W3Z9rqQA7okgL5WaGaRyrby2wzMzgj95rr0V3302bYODAYAZqpX79gCStNyYtozJZKywMdtPoaDScQERiob6WtXuBt4H+7j7J3XPc/WALxdXhRVoot7b61gKbNAlOPTW6WaQQtKxVn1wAoWQtwsby4e6tP0bSFJXJGsDf/956ccSCti8TkVipb4LBaHf/tbt/ebyVm9llZrbFzD42szkRzvmemW02s/fN7Olq5Q+Fyj4ws4VmZscbR3sRbu21+tYC+8pX4Mor4ZlnGt4y6vPPg9aM6uPVAJKS4NR3somraHh2qf4YSVNVT9Y6Wleoti8TkViJZlHc42JmccDjwDhgADDNzAbUOqcf8C/Ahe4+ELgzVH4BcCGQBgwCzieYldphRVp7jQ31rwWWmQn79sGKFfXXH25yQaVBnkm/Dxpeb0x/jKSpPv4YTj89+LmjJWvNsX2ZO/zyl1CklSxFpJrOMax7OPCxu38CYGbLCHZD2FztnJuAx919D4C7fx4qd+AU4CTAgHhgdwxjbXX1rb2Wn58ZcbbnpZfC174GS5bAVfVM+9i0KXiu3Q0KQVfo//5vJp8ur39GqfbSlKbauhUuugiee67jJWu9k3pTUFwQtjxaH30E3/8+lJcHC2CLiEAMW9aAs4Ed1Y53hsqq+wbwDTN7y8z+YmaXAbj728Aq4LPQ4xV379DLhTR27bVKcXEwdSqsXAl79kQ+b+NGOOMMOPPMuq/16xf84TzYwIjE9r6Xpsbbta59++CLL+Bb34L4+I6XrDXH9mW7Q/8k/aBDf9uJSGPFMlkLN8bMax13BvoBo4BpwBNm1s3Mvg70B3oRJHiXmtkldW5glmVma8xsTWFhYbMG39LqW3st3Fi26mXLlgUz6555JnL9mzaFb1WDY3uEVh9PFE573ktT4+1aX+Xv19e/Dj17drxkrTm2L1OyJiLhxDJZ2wmcU+24F1D763kn8Ly7l7n7NmALQfJ2BfAXdz/g7gcI1ncbUfsG7r7I3TPcPeOMM86IyZtoKZHWXhs/vu5YthkzYObMY2V//3uwBMhjj4Wvu6Ki5p6gtUW7oXvlH6Mz4pPBjbO7tJ+9NDXervVVJmvnngtnndXxkjVo+vZln4cGgpxIyZpavEUaFstk7V2gn5n1MbOTgKnAC7XOeQ4YDWBmpxN0i34CbAdGmllnM4snmFzQob++Iq29tnJl3bFsZWV116hyhw/jc+j1SN0vvfz8oIszUsva178ePEezR+jo0zI5+mg+PFDBQz3bz16a9Y23++tf4fDhFg7oBPTxx8Hzued2zJa15lCZrBUVBbO3Ozq1eItEJ2bJmruXA7cDrxAkWsvd/X0z+4mZTQ6d9gpQZGabCcao/bO7FwHPAFuBjUAekOfuHX43wXBrrzU0Zq1Kag5MyuLTg8e+9GY+G3zpVU4uiNSy1rUr9OjRcLJWURG06pWWwimnwDvvRBlbGxBpXN1Zib359rfhZz9r4YBOQFu3BuMmu3btuC1rTVWZrMGJ0bqmFm+R6MSyZQ13X+nu33D3c909O1R2v7u/EPrZ3f1udx/g7qnuvixUftTdb3b3/qHX7o5lnG1ZpLFsdYyZCyfV/NI74iXMfmFu1bIdAwdGvrxfv4aTtccfhz/+MehuzchoX8lapPF2156ejTv89rdBMiqxs3Vr0KoGQbK2Z0+Q+Msxu3cHySycGMmaZpiLRCemyZo0XbixbPHxcNJJtU6MsGVUUdn2qj1HU1Mj73bQULL2/vvwwx/ChAlw880wfDisWxd0ybYHkQZ/d98ZdOPm58Prr7dujB1d7WQN4LPPWi+etujzzyE9Pfh/fvPmhs9v79r7DHORlqJkrY0LN5btySfhN7+pWRZpyyiKe1e1XlQutBsuYevXL5iocOBA3dcOH4brrgu2tvqv/wruOXx4UF7ZatcehBv8nZcH55wTtGb89retHWHHdfgw7NhRN1lTV2hNn38erJt43nknRstae55hLtKSlKy1A+HGstUuO219Nhyp1QR3JAFya37pVS60W1vljNDKQeDV3X8/rF8fJGqV67QNHx48t6eu0HDy8uD88+Haa4OlT8Ilq9J027YFk2AqJ7OoZS283buD/8cGDDgxkrXmWO5E5ESgZK2D+MWNmcS/sgj2BstqsDcZXlwEG+t+6YWbtBBp+Y7ly+Hhh4Ouz0mTjpWnpATbBv31r833HlrawYNBcpqWBjfcEBzXt1adHL/qy3aAWtbCOXwYiouDyT79+8POnbB/f2tHFXtNXe5E5ESgZK2DyMyEJ+/KJPnZfOwnFSQ/m89pu8J/6YWbtFB7+Y6DB4Mu02uvDVqeHn205vlmwUr07bllbdOmoLVn8GD49reDhPXJJ1s7qo6pdrLWvTucfLKSteoql+qoTNYAPvyw9eIRkbZDyVoHUrtr9Be/gPhhOXBnCszrBHemED8sp2rCQXVdugRjZT76CNauhaFD4YknYM4ceOMNSEyse83w4UFXzb59MX5jMZKXFzwPHhwknzfcEEwyaGgnh+by9tvQq9exVes7sq1bg9+hHj2CYzMt31Fb5bIdZ555LFk7EbpCRaRhStY6srQcbHIWdCsAc+hWgE3O4q19OXW2r4KgZenFF4NWpoMHITcXHnwwzMzTkOHDg5aptWtb6g01r7y8YNJESkpwfP31QRLxu9+1zP1XroRPP4U332yZ+7WmypmgVm0TOiVrNVUm7T16BJ9V585K1kQkoGStA5ubO5cjXnfttf/8aG6N7asqZ4j27x+snH755bBhA4weXX/9558fPDe1K7S1tpvZsCEYr1aZQJxzDnznO7B4ccusufbuu8HzmjWxv1dr+/jjY13tlZSs1VTZstajR7A8T79+StZEJKBkrQOLtLCkd61ZXlICs2fDihXB8TvvwMsvN1z/aacFLQBNSdZaa7sZ9yBZGzy4ZvmMGUEC+9prMb097seStPbaMhmto0eD2aCV49UqKVmrqXqyBsE/npSsiQgoWevQIi4sGWZNtqKioEsOgtmikdZjq2348KYla6213Ux+fjDWrnayNmVKy6y5VlAQfOYJCUGy5h7b+7WmTz8N9rINl6zt29d+l0vJ2ZjD136WgjVTi/Dnn8NXvhKMH4UgWdu6te4+wJX31ubnIicOJWsdWLgFJ608AbaMrzHpgNS6X/SVrW21x7bl5NQsi4sLlhg43haSpm434x7s63nxxY3buqj65ILqvvIVmDo1WMIjlssmVHaB/uM/wpdfBslbR1V7Jmil9rzWWmWL8O7DBdBMLcK7dwetapXd8v37B62StZfT0ebnIiceJWsdWLgFJy/tPh2GLq4x6YBJWWETtqIiaoxtmzEDZs6sWfaHPwTnPvxw3cQuGk3ZbuboUbjjDviXfwkG6b/wQnT3hCBZM4NBg+q+dsMNQbK6fHn09dUnXCvImjXBxI3p04NzWrIrtKVbZSIlaz17Bs/tsSs0Fi3Cn39+rAsUIs8I1ebnIiceJWsdXO0FJz/utBLia37Rc1JJsBF8A8rK6nbJHD4cPP/qV4SdtNCQH2VkE0/N1r94EriqWzY7d0buHjx8OGgBe/zxYEYnBMlktEnihg3BgPdwS5KMGBHso/rww0FC2BSRWkFeKshh8GDIyAhm/bVUstbYVpkVK4KlJP7+9+O/58cfBwPmzzmnZnl7Xhg3FhuQ107WvvnN4Ln2HqHa/FzkxKNk7QQT8Qs9wkbw0Sovr3lcUhK0eE2dGrQePfQQvPRSMND86FFYvRqmTYPZl2ZS9t+LOLk02Hmh88Fkyv57EY/NyOScc6BPH/jBD+Avfzk2Q7O4GMaNC7oq4+OPdVeWlsJNN0WXsOXl1e0CrfT0phw+m5rClqmd+NrPmtbyFKkV5IOz55KRAaecAgMHtlyy1phWmaNH4Yc/DJKIpky42Lo1aG3t3LlmeXtO1mKxAXnlVlOVEhODfX9rt6xp8/O2S2MJJVaUrJ1gIn2hnxbfu8bG8Ked1vR77dgBv/99sG7Zj34UbFfVt2/wR3v06KCb8dJL4f1lmRz6WT4+v4Kyh/LZ/+dM3noLfvnLoIXrV78K1n5LToY774RRo4KFek87LWjtq660NPzep9Xt3x8kEOGStcqWpy/Kgm7iL8rrb3l69tn6u0sjzsg9dXvV0ifDhh2bZBDuy37//mC3iDfeqP99RaMxrTK///2xVp233z7+e1ausVZb167BBIv2mKxlj8nmlLjm24DcvW7LGgRdoW/tr/k7Mb7feG1+3gZpLKHEkpK1E0y4SQcJ8Qn8YnJ2nd0PEmrtCx8fX3eB3ISEUFdiak7dSQu1yiwth7i4Y9dWVAQJyHvv1ayzSxe44AK4/fZgkd7PP4enngp2VfjP/wwGXL/4YjAwP5xwe59Wt3Fj8BwuWWtMy9P69UHL4W23Re4urW9GbkZG8GNGRjA+cOGq8F/2V/3XrbxzQQqX5Db9X+vRtsqUl8MDDwTJ8kUXHX+y5h45WWuuXQy2b4dZs+DQoabV0xiZqZnc3vvYXrxfOdK0Dcj37g0+89rJGmk57Eiv+TuxOG8x0wdP1+bnbYzGEkosKVk7wYSbdBDuiz4zExYtokZr25NPwm9+U7Ns0SKYeG9OMEmh+qSFy2fA5TNrlPnELI4OqJloRJp1Wl1SElx3HTz/fJC47doFl10Wfo9TCLbNql+Q/DAAACAASURBVM+GDcFzWlrd16JteSopCbpxjx6FL76IvLBtuOS4sycQ/3p21QDyYcOC55/+JfyX/at7/7Pqc6zvX+vRdMFEStZrt8rk5MDf/hYkbBdeCOvWNW62baWiomB5jnDJGjRPsrZ8eZDEN0fLY2P0OZAJC/LJWFHBuS80bQPy6ltNVffOqXPrjDEtKSth5Ucrtfl5G6OxhBJLStZOQLUnHUT8ok+r1VqWllNn/9HMTHg7YW4wSaG6zmXQudZshAgTGWrPOo00OSEnJ0iwunULkrrx4+u2/gH0GFN/0pKXF9TRu3fdpUi+2jl8Bli7/O67YcsWePrp4NqVK8NeFjY57rtpEeefklk1histLega/uJIhC91qznLIty/1qPtgokmWS8rg5/8JGjJnDIl6IIuLz++cXWVM0Fr715QqTmStU2bgue33mpaPY1VUBC0NF98cTCJoim7XlTfaqq6PUebPwGo/Tsf7aQcqZ/GEkosKVmTsBoz/mJHY/5wRDGRIVxr2623Bklc9aRu8eJg8kL1lr7kSTnkJdeMe+azNePOywsSpKefrlvnnj9kw5FaGeCRBMr+X3bVJIrnnoP/+3/hnnvge98LZo9GStagZnK89Y58dr6cWTVeDY5NMmBf9F/qtf9YN6YLpqFkffFi+OSTIGEzC5I1OL6u0I8/Dp4balkLN+u3uDj4B0FDWitZy88PEv5vfjPogt258/jrqr17QaWzT40+AYgmCcvJqfs7H+3MbalftK3WbcGRI03fJlBalpI1Casxf/z///bOPL6JOv3jn6dtig1IkYKIQBMV8AJBqAqKioI/FRRWXQ+MJyrisYqKZ71A670iuqJWRV3Jisd6gIuCIK4gHqCggCir0hYUEMpNC72+vz+eDElmvpNOjiZp+7xfr77STOb4zkwm85nnjOrJsbJtvQV5AaB8fz9Kz/JC3ZuB0rO8eG6+HxUm411FBYukUEvfpt5Wt1GVqsCN03jcdXXBNlOFhbCss+57HzA9GIuELR5gejG2zfdhv/1YvJxzDt8MH3yQlxk6lN2gTspbrFjB29x9cLj1r83xfmC2Rigq0q7HfMwT5YLZvRt44AFOaBgyhKftuy8nhsQi1gzL2gEH6D/ff38+HroCxNdfz1arSN0damvDkyAMQZ2MrLzSUn5A6NaN35uL10aDnVh75JQioNqZ29qJCNN95ysq6k/KEeonktW6rg74+OP06VTy2mv8kNkYk3uaKyLWBC3R3PyLBhWhBZlqpWW4kIXwbIRMuJDl3h4e2zZMU5C3pyYGzqZwb2nr8Jvy9gx9K4Dyah73qlXAzp0s1mwTEZZyLBLG1fHrUrY8lZfzx3V1LMyMgsCGqPn4Y5v1hbBoEe/fq+Xh1r8F7UbxDGah+M1oRzfrRLlgXn6Zj4thVTPo35/FULQ3m19/BTp14s4QOuzKd1RXcxJJfd0xVq3iWLrBg/m8/vBD8rLySkpYtHfvzu/jFWtEQLt24dN9PX04ZGUxsisjx5g6FWF23/n6knIEZ9hZrf/zHy43NHduigcYYOXKYPKP0DgQsSZoiebm7+vpw7OnFaNlTfCG8spfXsGrZ08Oe8psk9MaNTDFsbkqQINNd5RBmhg4XbxbTz9oePhNGdBborA1H35/0KV3991A27Y2O++AXbuCN8JevbgafyRXqMGiRQANLsSu2vD9qwbvX/bPJqH40SSctJ2f1qEILSr1N+tEuGAqK4GiIs7+POWU8M/692eBGm1bLLtMUAM7sTZvHrtBAU5usMNwgY4eza/z5ycnK6+ykuPMPB7eh5yc+MTa+vVcisZciw4ABub54H6hBLX32seYOhVhdkk5dtOFxPDVV/yayHqKc+YAn38e27JGeIGTMAMhPRCxJmiJ9uZ/xdE+7Hgg/InS/JS5qVJfa0PlloXFndnGtZmm0+BCqCyTqCNldR1WudHyqyKMGgVs2MCT1q3jLEVzKRJdeRI7jBshEVvXZs2y1n0zs2gRoFrb799ppwVj8HJz+fXNu/k4XrexDtmTSjDicOvN2mmWbyQee4xF0wMPhFvVgNjj1n791T65ALAXa9OmAS1a8DiciLVTT+UOCV98kZysPOPcGzFiXbuytSJWdDXWDA49lEt7GEkIOpyKsKIia1KO283ThYbDyBY3ehIngptv5sLjsWA8dDXlnsRNDRFrgpZE3PzN2FnrPLn5YXFneS79fC1UW2SO9QL3ZSBzrBcq1+6XRoW5El0zi7HX/3wWN1F1Nbeqqq88iV2B4NAb4ZAhbAmKJGaqqrg2W2ul3z9XZT527w7G4Hm9XDajfXv+vG9fju2ys+A4zvLV8NFHXKbD5+Oiw2aOOIJv6tGItS++YFEcmkxhRtcfVCkWa4MGcfB+fWLtgAO4Nt+AAWxZ65KErDzjJufx8Gu3bvG7Qc1lOwzseoSG4lSE6UryFBfzdKFhUKphxFpZWezu6+ZgWXvuuaYlRkWsCbbEc/PX4dRaN3FYEbJNMXCZcEG5tqO2Fcex1bYqBdm4PPNcHuS+UgKMq4O7uASjj/XtiTczs2mTtRSJuTyJrkCw280CzbCsjBkDZGZGbmi/fDkH8B+zwxo0jmo3DlpVtKeTwapV/MM+fHhwFqMeW6JbU/36K3DhhSzIiov182RlAUcfHZ1Ye+wxFroXX2w/T6tWLJhDxdqPP/L+DxvG5UPMRZNDWbYM6NGD/z/uOF7PTUfE5xJ2kpxg3OS8Xn7t3p0zaM1t15xiWNZ02zbEmrlHaCjRiDBd+R2h4Vi1in9nOnZkwZ2I4s3btrG19Y8/6rfmm6moCHoYmpKYCWX1aq4g8MgjqR5J4hCxJiQNxwV5e/ow+axiS7xbVW14vJuCsgg2oxtDWRnHMbVsyW2rzG49AyexOrob4aWXckaVkX23ejXf/P7zH/uMPOPpevlUHzDNlEgwrRh/zvFh40Ze17RpPG+oWDvsMC7zkUixtmMH11LLyODWWbq6dQb9+7Nl0Elx3BUreB+uvz7Q4SIC5lpr06fz6xlnsFhbvTp4cwmlqopr3RlibcAAfm2/NnarsNPkhNJSFueGG7dbN75pxmrpWL8e2NxZv+3/bvIjNzfYecMOEWHpycKF/HrZZeHZy/GwejW/1tVFn9FpCDSXq+la1pYs4dcPP0yfDNx4IdVE9qSgoEAtsisjLzR6MsZlQEH/XfXkelC2tQz5ufkoGlQUdlOureVg9YceAmbPDr9w3e7YXUBer/On0rw8tiCVlrIoqq946rvvssBcv56tcaH068exXPE0VjdQittlvfMOZ7KakwrMTJ/O1q7PP+eSGpG48koWqWVlQTeuHSefzMJr/nx+f9xxbH349lvg00/ZHTpzJvB//xe+3LJl3A7L72fLYG0tJ41ceCG7QGLB+5Q3kKgSTl5OHlplt9rzPdv/pyKsnenDqlX8+bx5wAknsDv5tNOi2+bu3SzCc+/3Yius2/bkenDgtBJs3x688QuNh1tv5ev5u++4nuLkycDll8e3zo8+CmahO7keQ/n4Y85MPe44/j5VVvLvUlNi/Hjgvvv4f6OuZjpCRN8qpQqczNvETpHQVLGPd/NEdNVmZnIM1qxZbAnr1CkxsTrRWFCMDg0ACzU7K1+XLjze2bP5BzjUqmbQty+7BeOplm/w979zq6aHH65fqAEsFAHg2XmR3YR//MG9XEeOrF+oAeGWtT//ZFfrsGH8/sgj+VXnCjWSCwzLWmYmjzGe4rh2SQjlleVhFq+v9x2FvY4K7nc8tdYMq+FW2CdG9O3LZUmqqrSzCGnMokVA797AIYewldmw+sRD6O9PtNZc47foxBP5++SkPmRjY8mSYMLOhx+mdiyJokHFGhGdRkQ/E9EvRHSHzTznEdGPRLSciP4VMj2fiGYR0YrA596GHKuQ3iSiNMXFF3PdrkS4ieIpdaCUVbC53SyaDj+ca53V1gbFWmhl+jfftE8yiKaN0KefArffDpx7Lj/5O6F9e2DfwX68szuym/Dppzl26+abna03tIvBjBn8mnUkC8K8pzmZ5L1frDuzbBkLtIMPDk4bMICnb9nibNtmnCYh1GVWYHX3YCmQDh3YehqLWDOyPNvbJNbk5+ajTx++sSbChQbwNbBzZ/B9MooIN0fq6thCXFDA12XPnolJMigrC1rDohVrJSUcg2pkeDdFV+iSJfyQXlDAoSlNgQYTa0SUCeBZAKcDOAzACCI6zDRPNwB3AjhOKXU4gDEhH/8TwONKqUMBHA3gz4Yaq5D+NER2ajzosu9cLufuBKX0weB9+7JbrGNHzqI0V6Y3EiWuu67+dlx2bYSUAm66ieufTZ5sb+nTsfOYQtRm2Ncw27aNXZB//Wvk+mqh7L8/7/PmzexqbXOCHw8tCwrC2lal+GY/a9zYsmUskg4+OHgcKit5/2LptgDoHwrs2JkVvEsScZKBnVirrbW/SRvdC6492P6BJNHJJc88w1m0u3cnpoiw9BvVs3IlP1wVBBxdvXuzkIg3+qisjC3x7drFZlnLz+euJMb7psSWLZzU0bs3d5f58ktg48ZUjyp+GtKydjSAX5RSvymlqgBMBWB27FwF4Fml1GYAUEr9CQABUZellPokMH2HUspUeEFobiQ6OzWusWiSDl55Jdya5PHYF971ePTB4MZN+cwz+canq0wPcEHMUGH2/PPO2wh9/DG71AoL2RoUDTtdkWuYvfgiCzan1jogGKT/228cm1ZzgrWorcqqwJ2fhO/Ml1+yVSr0ODz1FB+3WF2huoeCvBx97ZZWtflhAiU7216svfAC3zx+/tn6mSHWLu5t/0DStStnzSZKrH32GbtfFy2Kv4iw9Bu1x4gxNMrX9OrFJX7i7RhRVsaCKz8/NsuaxxMsO9PULGvGQ9GRR3KSklLOusukOw0p1joBWB3yfk1gWijdAXQnoi+I6CsiOi1k+hYiepeIFhPR4wFLnSCkDbrsu3HjOFh8xAgOdNfFlkUqQnriiezaGzGC3zv9IbZ7Ui8ttVo8br6Zt3HZZcFpTi0jHXPsXXVVVcCECcBJJwUtCU4wYs+OOopdczsy9Tu9ZntwekUFi5za2vB5KivZxWMkK8SC+aFg4ukTrda2Kjcq/1MUJlAWLWLBqYsrM47nZ59ZPzPEWocO9g8kGRmcGRup5lw0GDGA8+dHX0TY/F258UbpN2rHokUcp3bIIfy+Vy9+jdcVGo9YM34TWrZky1xTs6wZMYG9e/M106FD04hba0ixpnOumG8pWQC6ARgIYASAl4ioTWD68QDGAjgKwIEALrNsgGgUES0iokUbdLn9gpBk3vvVD9zkxRvdM/BwpRfeYX6MGcM/qk4SG3r0YFenUZg23jZAROEWj0svBX76KShySks5M23kSKtl5NprrQLu0f+zbyz+xhvA778Dt93mfHx+P9emCxvzNv1O56Dtnriqg/7h1faKBVgsffONVTTF6qozW9vyMj3A9GLULg4/iTU1wRp5oZSWAgsW8P/z5lnXv349t6tq2TLyGPv04Zt8rLXcDDZvDt6g58+PrrWczopmV8NQ+o2yZa1PH344AjhmjSi+JIPaWo69jUWs7d7N8aGGVc3rbXqWtcWLWaDttx9fR0OHssU+2np06UZDirU1ALqEvO8MwFwRZg2AD5RS1UqpVQB+Bou3NQAWB1yoNQDeB9DHvAGlVLFSqkApVdDeSdqZIDQgRuzPrhbBBvQrDx6FgpF+lJY6T2zIzQ3+r4uNs8Mce0ZktbiZLVEA/4iZhU1FBbtWzQIuY7kP+y8qBrZyjbjMHR5c0qYYqz7w4coredmrr3ZurSsstBYJVbOLQDWmna5xYVfd9j1xVesqS4EzR2kFW7t2bGELzSCN11UXavG6tqoEWGp/Es2u0Dff5NejjtJb/IyCuP/6V+Qx9u3LxyreJANDKHi97C5+8CTnyTt2bnkdzb3faE0NfwdDrcytWnFrsngsa+vW8boNsbZtW7CPbn0Y9dkMsebxNE3LmpFFDrBY27Il+MDUWGlIsbYQQDciOoCIsgFcAGCaaZ73AZwEAETUDuz+/C2w7D5EZCiwkwEkKA9KEBqGhmggrouNO/dc63xud3ibqA4d4g9iNi9fUcEurz/n+IAJJcC4OtQ+UYLnr/PhnnuCFp+yMufWOu2NYqkP6oNiZO4ICsLM2taoyzApyuwK0ODwY+t2B+srnX564lx1ocLzyScjJ5KYxdrUqcAxxwAXXcT7u3p1+OdGqymdEAodoxHPGK8r1BCx117LVrYjs5wn7zi14jSXfqMzZ/J51T0ELV/O4trcbq137/jEmnEODLEWOq0+zJ03jGuwiZRb3ZMx3bt3cNopp3DyV2PPCm0wsRawiF0PYCaAFQDeUkotJ6LxRBSoooSZAMqJ6EcAcwHcqpQqV0rVgl2gc4hoKdil+mJDjVUQEkFDNRA3x8b5/fzjs/feQQF3++1sJTnpJM6OrKkJBu4nkvJyZ244p9Y6u0xUWuZD7RMlewRhbfYm7XyqdZklq3afffj95s31u+p0MX1mzFa5nTv5NTs7fD63m12ZoQ3df/6ZxdEFFwQ7LBiuUEMAzpzJ3QnsLBzGjbh7d7bM2CUZOC2/sWQJfzfOPpvfz5/vPHnHzlqWl9c8+42+/DKfx7fftn5m1Gg3x2/26sUt3rZti22b8Yg1c09bj4et0E0limj5cv7tCRVre+/NscCNPW4tqyFXrpSaAWCGadq9If8rADcH/szLfgIgTesOC4KV/Nx8bfX7RDYQB1io9enDiQyffcZukYICvgG//Tb3ITzmGJ43Jye8PVRGBgfghwopl4tvsqHTdC7URGBep1FzLnS6dttb84E21mObuTPfEnPj9TofuxHTBwStf198wfXejCDuHTusFi+l+CbQqlVwvqIirjEXall7803exrnncgzN3nuzOFKKt2Wst7LS/pgbN+SMDL4J6cSa4YI3LLtG+Q0AFuG1eDG7iQ48kMc0bx67rnXrLJxTGNYdpKjIFzZugEXqxInNQ5yFolQw6/iBB4Dzzgu3uC5cyCENXbuGL2ckGSxdyl0EoiVUrBm18qKxrGVkAJ0783vDwlZSEiwi25gxXPyhblCAs0LHjOEEIKNkSWNDOhgIQoJIROFep/Tty+6w3bu5ptmmTcD777OFo1s3bln15598owi1hjzxBNdWM5ccMU8bPVrfvD5PX8XCOT39wBgvcF8Gv/b0Q6ngGD0eG6E1pwiosmZk1i4fYrEmOb1x6cSRzvpnZ5XbtMmaDdytW1CsKQW88QZbOo87jkVxdTXXktO5PO2KJQ8ZErT+ff89izWzddOpC76ykvu29u7N2xowQB9HZ1d7DUf4HTeMb+qUlXGw/gknsOvt3XfDP1+0iB+izOfUsPrE6gotK2MR2Lo1u89drugsa5068TJA0MLWVOLWlixh67a5xuPQofzamF2hItYEIUEks3Bv1SF+bL/Ci70ezsAXR3kxcoJ/zxM7wPFrzz/PT++DBrEFaMQILoarKzlinjZpkjVWrriYLSi6YsBml6BuGnr6OSmgTTABA2eOQt5A/x5xZNSAsrDUB0wv5qb3ivh18aWgvq9ZBEXbE/XuvzZtwvfHzvrm1Cqncwnu2sU3TiK+Kf70E7u8jP3btYsz+exujuZiyZdeym3SjOW3b2cL6EUXmWL/bFztpVvLwuZ74gmOrzIsDwMG6OPoIom/xtAwPhlFeg2r2pNPsiB/4IFgqZ7du7mWoa6ETadOXH8x1oxQw5IL8P516RKdWDOsaUB61FpL5LlavJj7gGaaCn117crnSMSaIAgAklO417/Ujylbw0XPK+XWivNXXAHccgtbznbsiK6kBmAv6nTFgJ1Y61r9pRDINpmTsisAU5KAXXcIWuYDnioBxtXx6yEzoLKsggKDC7UZtFu28BP35ZcHBWystGhhDaD3+9lqZrB2Lb/qSgbYJSiYiyXPmKHPvnzzTVPs31a9q5225ofN9+CDPD1UrAHWIsINFX+ZDJJVpHfBAv4O9eoF3H03i7NpgRS6H37g825OLgD4eujVK3bL2urV4Q8K+fnOLWPmh6HcXH6ISZVYS+S5qqtjARwarxbK0KHA3Ln8W9gYEbEmCI2MwjmF2FXrLOv00UfZOnPFFfY/YtGitawcYXJvHuG3zLfTptjtpprw6XaCcMiQ4DxEAHLt12defuJELli8bh0waxb/GbF6odglPBgB9AYPPmi1KBUWOm+0XlendzObBaDjosiacidU44aaHb7CqireR8O60qsXC47Jk8OtG22znNdei4Z4rChOl60vqzZR4/niC44NzcriBJKuXYHx41l02CUXGPTuzVZvXRZpfYRa1gDntdZqargOYqhlDYiQlZ0EojlX9VFSwpZnc7yawRln8Pd/zpzo150OiFgThEZGNFaPzEzg1VeBl16KvE5dJqHT7EKnvSWjKb6qE4QXXcSftWsH9OsHeCKsz7z8DTcA997L2WKrV/Pfpk3A669zkD3AsS52sXoTJ/J6xo3jaddfb92u7Q1TE6fXogUL0nbteJaOHfWxX45rlQXKnYS64NUHxdp6cKqHHwc+zee16z+8aHO8H7Nnh1s3tr1XhKy68AORTfHFX8ZjRYlmWbvzYJ4ez3i2b2fr2bHH8vusLBYYixezq23hQqB9e/vz16sXxw/atSezY+dOjqE0i7Xff68/S3vNGhaH5jADw5qbCpyeKycYJWnsHkoHDOA4vw8+iH7d6YCINUFoZERVcd6B4NKJrcvfvxwjPxjpqLm30+D2eBMw+gTKYm/cyJ0eEpHQ4fOxu/Luu/lGePLJ+lg9Q0SVlrK422sv67q0N2abOL2qg/04++yg+Fu8WB/7FU1RZM+2cBe8Z5tmhT39wLDwc72mzyioHuHntfpbH2reC48RVNOKgR+cu/UT2ZYqGguMnUAyT4/HqvP11/wgEJrN6fMBBxzA1rWFC/XJBQZGfOnxx4db9WpruY/s77/rlzNiC81ira6Okx0iYVjP7Cxrqai15vRcOWHJEn447dFD/7nLBQwfzolYTi3g6YSINUFoZDgVKU4tXjqxVV1Xjara8F80O1erU0tfvAkYXbsG48x69EhsQse99/LN9eqruVadXQB9SYn1ZmegE1Y0WB+np04uxDffcKspIvssW51L+KSTrPPpXKhaoTeoEHCZxuOq4OlmlobHCFZ/64uqiHAi21LZzaOrk6fbb3NWbSTXn5PxLFjA56Nfv+A0lwu46y4WasuW6ePVDIx4tY0bg8fnqqvYUjd6NIcvRBqbWaw5GbdhPTNb1rxejuPapC9l2KDYnatYCiovWcI9WHNy7Oc57zyuv9gYXaEi1gShkeFUpDi1eEUTNK6bNyr3ZhwJGEadMSD49JyohA6XC5gyhV1Tl18ezOozU1pqk62KoLBq2ZLft2sHKJu4OuSWYd48Lq+Sl8duNDvMLt2JE3l6Xl7k8hlmodeuHWzj/Gynm3DqnoqmLVXbtlbBZbbKtW2rX9bc+3YUl5azCFxzVm2kgsxOrDoLFvB3MLQ1HABccklweSNeTRcXZ3TZCKWyknvatm0LfPmlfrvxiDVDnHbpEj49leU7dA8jsZaCWby4/rjcU07hc/bWW7GNN5WIWBOERogTkeLU4hVN0Lhu3mTWlzNcoYcfnvBV4+CDgb//nZMPnn3W+nldHd8Q7SxrAN9kJkxgV2lJiX1cnasif49Y69AhunEeeihbDy65pP7yGaFCb+RIcHFhHabp8QgZwLmoc7k4/itUROlalW3bZi0FY1cnr7DQKnB1WbVO6trpxKPHA3z+OcekmefLzgbuv58Fe79+9nFxkYTR6NFsJdKJ3bIy3l5odxJDfDmxrHXsaHXhG9/nVMWtJaIUzIYN7DqOJNb8S/04+Dkvto7JwGttvXjtO39SSrwkChFrgtBEcWrx0oktV4YL2Znhd0c7AZbM+nJ/+xsLqWgFjlNGj+ab9W23WRumr13L5RjsLGsGV13FwdwtW9oL2RNqirBgAccZRVs5PiuLY57s2k7ZsWQJ4PlFP54jNgbPa6SiyE7dU07bUrVubY0f0rUqq64GXH38yBzrBe7LQOZYryXOzkAnWsrKYFuQuT4LnFk8lpWxFey//9X3vh03juMfjzrKPk7PXAfMwOMB+vfnZAEjo9S8H/vvz6VbDJHRoweHB8yeHVl42FmFG8qypk1aagBx5PcHLe2PP27TMi4kJASkoFqX4sppo3D5BH9MCSYpQSnVJP769u2rBEEIMuWHKcpd5Fa4H3v+3EVuNeWHKdp5PRM8iu4n5ZngUVN+mKKdFu3241k+Vaxdq1S7dkp17KjU118Hp8+frxSg1IwZ0a1Pdxz8fl5XVpZS558f/RivvVapvfdWqrbW2fx1dUq1b6/UyJH68bz7Lo/niy9Cxj2FlwH4WEyJ4vRNmaKU283LGn9ut3UdROHz2P71nKJwV/h3me5283TTvB6PdTx5A63L4y63yhsYPiCPx+F4bP4c7w+UatFCf3w2bOD3Dz8cPJYeD6+7RQul9tvPemx12zYf7wMPVOqCC8LX5/Eo9frr/F264Qbn57fe86/57cke51auvlMijjHq7Tj8nnkmeMLPvfE3xuPo+9NQAFikHGqclIusRP2JWBMEK6kSTNEIxWQRzbFYulQpr5dvjn4/TzME1vLl8Y+lrCx4c/jb36Jf/uWXedmff3Y2/5o1PP/TT+s/X7+eP3/0UX6/ebNSl1wSHOOBBypVXh7dGM2iQHdTdiyOxuhvtnSTx9HNP+9B/fJ5D3rC5otGbMXz5/HwOTSEhnF8jGMGKJWTo9Q11+iFWTTbUYpFvcul1Bln6MVN585KDR8e3fmNRLLEkcejWLCP8SjcR/zac4plnXQ/6cdzH2lFb7KIRqyJG1QQmjDJ6Kigw2lyQ7Jwmhlr0KMHB3sfcwzH0BQWchNooH43qBO6dAmuJxaXbt++/OrUFWrX4Npg332Bjpv48gAAFyFJREFU7t25T+isWbz/fj9wzz0cn7VmDRd+tavlpXN5OYlFsutWYWlVZpMAoXLLHAWnmwsv202PpWREtBju5JEj2V2qVDBeLDSerbISeO4554kaOgyXsOHCX7BA75YtL9fHrMXqtrRNWtKcx1hqqhmUttaXxilt7XdU5FkXw5mM70AsiFgTBCHhRFO412nx3XiIRTy2bw988gnHoD30EPDww5xRaWR7xovR6inamDUAOOwwbnn11VfO5jcKhob2jzVz/PHARx8Bp57KsWRffsk1w44/nkXDJ58Ad9xhXc6/1I+rpjkXwqE4bV+W59LfQT25+Y6C0x3HbxZZA/B14jEjQ5/woMMcp2cnKKPJoHWKkWnbuTO/tyvPUVnJRX7NSRWxFg22TVpKsDjKPNWmhd2gQkuR52wyPRVUu0Gfhgdhxlo2JBmIWBMEIeE4vTlGa/GKFTvxWLq1NKJQzM7mIqVPP81N2A86KHFjyu7LAe9X/xG9SHW5gGHD+Ma/cmX98y9ezHXq9t7bfp4hQ7go6y23sMUutE7YyJHAdddxtmzozVop4Kbphaisid2KateDNqxcybD4Mo6LBhXBnWVaPit8+RUrgA8/5CbsBm3bhotHg3vusQrK+rpf1Ccoo7EwmYWhLmEhNNPWCYYj0BBldskRN95Yf6mVIS2s5ysbbmBOYsVRbStnFrzqb33Ye254EtTAbcVosdKHLl3iLxuSDESsCYKQcJyW80iWu9ROPBKoXqFIxFmo33xTf9sup/iX+jG1gt03sYrUiRO5hMfIkfY9Jg2r5bs9M/DHeZEF4dlnc7P7J57QFxadMAE48UTgyitZzP38M3D66cCGqoZv+h4p4/j77/kYrFkTefkzYerIML0Y04t8mDyZW5kdfjgwfTpbD9evZwvjjh0s0A3xeMstbNG8806roJw0Kb6aYfn50GasmoXZXnuxMAzdzj338Gf77hs50xZw1g/XcI3qKN/fj9KzvFD3ZqD0LC8uedxvKbXy2lgf+m8sRuYOPt6ZOzzou5bbn3XsyOvJyACef15/fJy6X+1K4+gseJv+Gx4SUjjMh127+DqKp2xIsiCOcWv8FBQUqEW6XGdBEFKCf6kfhXMKUba1DPm5+SgaVGSJmcsYlwEF628QgVB3n01l2hjHMmr6qDBhSCDttj25HpSMKUnYtnV4n/JyGYE4t/3661xvbcIEYMyY8M90++x2ueMqq7JhAxd73bmTa5/l5ACZY73YXGfdl04tPVgz1vm+xMJbb3FpjYoKdivPnasvMLxyJXDEEWw9fPVVdunOmMF/69axhef664GxY9n9DbDLsKCALW2FU/147NtClG4pQ4td+XjZxw8d9X2/o+Ha5/x47vdR4R0mqtwYVFmMX9717bGQvfBCsPivwR9/AJ06sbt69GielpHB4kmHxxNsCB9VyQ6jfVp2+Bgx3dqH1lwHjwjo1o1FvvG9XbLE6po33K+hVj23Wy98X1nkx8j3w48Z1bi1fXHNPVBrarju3ODBwBtvRHEMEggRfauUKnAyr1jWBEFoEJwkN0TT/SDesZgtMzqhBiTWImRHNDF9kbjoIuCMM7jNkbkpeENYLdu3596KmZm87ZUrgWf+YrWiotqN2llFWLcu5k1FpLaW9/n887kQ6lNPcXKErjNAXR1bA3NyuEZf69bAOecAL7/MhVR/+IEFy6OPBoUawC7Q994DNuznx98+Cdbo2p0TXe9cp8zYrWkFll2BlZ0LUVLC7sdWrTiG0sx++7HbM9SVahcLZogWw5pklzCTl2fTrswmRsyMWSgqFYyZM1qmffqpdbt2PVt17tecX3zAtGLs2yJ4XY/evxjuX8N/a3Tu1qws/h5Mn574WMGGQMSaIAgpI5ndD8zi0ZOrv0slWihGs41ot03ElpYWLdgVGNomK1GC0MyRR7I1avJkzmTVCeH7jizG9gU+DB7MXRrq47vvgKlTuadmdXXkebdu5YbcDz/MwuXTT/lGfsUVPG3WrPD5X3gBmDcPePJJ7HHBGWRkAD17BlpxaejVC8g9uxB1mbH3znWK3XlZs52nG5YwndsyIwPIPd6PiRnB+Msht/sdFTYuKrK6vY1YO7NbN952ZRs38mvnzhxDOXeudR672L3ycmuyw2OPAZ03+7D2tuB1Pekan2N3dNuBfuy8yotWjzdcclOiEDeoIAgpxYm7tKG2m2g3Yaq2/dprwGWX8Q32hht4WqfHvfijIn5Xa6wUTvXjoW8KgdZl2LsuH+NPLMKYQeH79vnnLBZCBVaLFhw/1rs3cOCBbEUzuhpUVbHr8rffOOlj9OigeKmoAI4+msXhfe/48fh3/J3C1nwctrYIS//ls83YjISdq15HPO57O9d4LjzYcl8JCgrY8vfRR9Zl/Uv9uOTtUWGi0u1yo/9el+KztTNQ27IMtD0fo7sWYdI11u+X38/uZKNDR1GRXty0K/KivEbjN63IA6pasWjbms+JBEutKwh1RV59NQv08vJw17XXG51r9tZbWbTVh9/PVjtD9A653Y/XNo1CRU34Mbt0n2LMeNS3Zz67Y5EIonGDilgTBKHZkiqhmOhtKwUMHcotkJ55htsRzVprjS9KpRhFlRsFa4vx5OU+VFTwTXDePBYgN98MnHYasHw5xzF9/z2/btjAixKxiHO52OX30kvACSdYj+G1Bxfh7ruB2qHhwiUn040Xh8e233YiSkc8QlgbV1njxuG/FWOp34d99wXOOosthU7HaI7LjHT+Tz+dj3ek26h/qR8j3xuFKhUcYyZcIBBqELQ0ZtW5Qf8pRvW3we3stRefN0P4TJ0KjBjBiTuhmce6mLVI6OLeLOPWrJNu8kLlao7ZVg/UhJI97+3i5RKBiDVBEIRmxpo1bJHato37R159NZA3MGhhSqYYtRMPGds8qHuyBAC7wm67jd2XltgosADdvZsFmq40hZ11MqM2BzvqrKmMsQop3XZcGS4QUZgrNBFC2Cw+u5YWYeFkH/74g+PVHnyQrUNmorH+2R2Ha64B3n476Kp0OsYdVTtQXmk93nlZHrQsLkFZGbtZX3wxXPCsW8du6Ucf5e9B2Db8/P3duRPYZx928+qyU10u/o7UZzHVWuvuy+BCumYUAePCraPm5IREIWJNEAShGfLVV3wTHDqUb2SpIlKW70td6pCVxR0RLJ0KoiAai5ex7VhdlDorKJDYbFAdRtbkv//NwfD//Cdw8cXW+aI5FnbH4ZFHuCTJ9u0sDJ0S6Vy/3rUOF13Ebu5TTrEue/jh7Go0u3Z/+ok/a9mSXd/jxwPjxlmtbeedx1bkeseoy4wd4+WOB2a2eICnSsL3hcLjQRNFNGJNk+QsCIIgNEb69Uv1CJj83HyteMjPzcfIkYnZRrSJEvEkjvh6+rRCrKGtlP378+vUqfxql+FZNKgIV7w/Crvr6i9NY3ccvF5+veIKLnPStSvXmOvaFWjTxn6Mduc6F/kYM4bLdQwapF/2pJO4lEp1dfjDxfjxbI1bsAAYOJBLtEyaxNm+ZWVAbi7XBHQSqwbYlCiZUwQaPgoqK0QBVlsL9xrLpxrJBhUEQRASSjKyfO1ER15OXtIyjBuagw7imL4PP+T3dqLB19OH8QVc9HdPCYuC0ZYWS5GOw4knsqiaNw+4+262fB51FLshTz2VEzt01iXduUa1G1v+XYQ+fdi1mmGjNE46iV2dCxcGp61YweL0+uu5R+0LL3AR5pIS/qutZffp8cc779Or60Hr/tWH0fuHZzFf06kYe/2v/rIfqUDEmiAIgpBQ7DoOAEhYH1g7QTjx9Im23Q7MJKMvbTwQAccey707ibjwrR3XDPABT5XgkRwuYdFrzSRUvVOMFpX1HweABdDs2Vxgd8cOrj/33nvcHWHZMnatH3IIJ7Bs28bC7bffgDZlPgxDMdzVwe4QR68rxrev+jBzZuTg/4ED+TW03tr48SyQxo7l9+ecw7FuDzzAyQ9LlrCgiybgX9eDtrgYmHRNeDmfSdf48NJLweOcTi2oJGZNEARBaHAaolRKPBm1ySrdEm/W7wUP+fHmhkIgtwyeNpGXb9uWMyy7dOH4s6FD2bKlax8WzRirqzlu7umngS+/5FiyujoWkQYdOnCB5ttuA7p3d7x7yD/Djz97FqJqrzLs587H2teLcOaZwA/tg+O5q18Rxv/Vh9at2Rr34oscm9m2rfPtpCOSYCAIgiCkFYlqsdXQ48nLyUOr7FYJSRyIVxD6l/otsWiRlu/dG/j1V7aMXXghx4PVl2gSaYyANYmi+y4fXnmFBeChhwKHHcav++xT7+5ot33Zv0ehhkLixmpcyM4mVNWFZ9r+zVOMRy/ifR4+nDtpNHbSRqwR0WkAJgLIBPCSUuoRzTznAbgfgALwvVLqwpDPWgNYAeA9pdT1kbYlYk0QBCF9SVYf2HjHYyYea1u8AjXa5YcN4/ZJ113HVjBdrJjj0hs5eaisqWxQy2O0NeyG/q8EkyZxwsG55yZkCCklLXqDElEmgGcBnA7gMAAjiOgw0zzdANwJ4Dil1OEATK2I8QCA/zbUGAVBEITkkKw+sE5xut142kjF2/Ir2uXHjuWsyWeesRdqo6aPCutpqhNqAFBeWZ7w3rJmosnoLdtahieeAKZMAc4+O2FDaDQ0ZILB0QB+UUr9ppSqAjAVwHDTPFcBeFYptRkAlFJ7usgRUV8AHQCYOr0JgiAIjY1k9oGNdTx2xNpPNZJAdZLcEK3APeEELm5rVyS2cE6hRYBFS7y9ZUOJRqjn5+YjJ4eD/XVFkps6DSnWOgFYHfJ+TWBaKN0BdCeiL4joq4DbFESUAeDvAG5twPEJgiAIScIuQzRZ7b2cjCcvJ087b6zWPzuBOqTbEIuFa9T0URbBFmn5WLJYnQott8ud8GOhQ7d/rgwXsjPDqyU31tIriaQhi+LqtL05QCALQDcAAwF0BjCPiHoAuAjADKXUaorQR4KIRgEYBQD56VC1ThAEQbDFrrhsqjCPxy7YPlahYKzbHKSvs3AZLsbQ8eiWH9JtCF77/rU9yxtCL3R+O+wK2OqSKgAk9FjoMMZ71+xCrN6W3O4QjY0GSzAgov4A7ldKnRp4fycAKKUeDpnneQBfKaVeDbyfA+AOcOza8QDqALQCkA1gklLqDrvtSYKBIAiCEC/xltpwQjzJFvEkLUSbnZqMY+GUZI0lmfucFtmgRJQFYCWAQQB+B7AQwIVKqeUh85wGYIRS6lIiagdgMYDeSqnykHkuA1Ag2aCCIAhCUyAewRVvVm06CTCnJLMmXjK2Y5AW2aBKqRoA1wOYCS6/8ZZSajkRjSeiYYHZZgIoJ6IfAcwFcGuoUBMEQRCEpkY8yRbxZtX6eoZX7U+mUIu1Y0Qkt3Eqt5NMpCiuIAiCICSZWC1cybb+JIp4xh2NNTFZ20kEaeEGTTYi1gRBEITmQGN0Zcbj+o1m2WRtJxGkhRtUEARBEITEk0pXZqzEUyA4GrdxsraTbESsCYIgCILQoMQTaxdNjb5kbSfZiBtUEARBEIQGpalmdMaDuEEFQRAEQUgbkmW1SmfrWDyIZU0QBEEQBCHJiGVNEARBEAShiSBiTRAEQRAEIY0RsSYIgiAIgpDGiFgTBEEQBEFIY0SsCYIgCIIgpDEi1gRBEARBENIYEWuCIAiCIAhpjIg1QRAEQRCENKbJFMUlog0AShO82nYANiZ4nUL8yHlJX+TcpCdyXtIXOTfpSTLOi0cp1d7JjE1GrDUERLTIaXVhIXnIeUlf5NykJ3Je0hc5N+lJup0XcYMKgiAIgiCkMSLWBEEQBEEQ0hgRa5EpTvUABC1yXtIXOTfpiZyX9EXOTXqSVudFYtYEQRAEQRDSGLGsCYIgCIIgpDEi1jQQ0WlE9DMR/UJEd6R6PM0ZIupCRHOJaAURLSeiGwPT2xLRJ0T0v8DrPqkea3OEiDKJaDERfRh4fwARfR04L28SUXaqx9gcIaI2RPQOEf0UuHb6yzWTeojopsDv2DIieoOI9pJrJjUQ0WQi+pOIloVM014jxDwd0AQ/EFGfZI9XxJoJIsoE8CyA0wEcBmAEER2W2lE1a2oA3KKUOhRAPwDXBc7HHQDmKKW6AZgTeC8knxsBrAh5/yiACYHzshnAFSkZlTARwMdKqUMA9AKfI7lmUggRdQJwA4ACpVQPAJkALoBcM6niVQCnmabZXSOnA+gW+BsF4LkkjXEPItasHA3gF6XUb0qpKgBTAQxP8ZiaLUqptUqp7wL/bwffdDqBz8lrgdleA/CX1Iyw+UJEnQEMBfBS4D0BOBnAO4FZ5LykACJqDeAEAC8DgFKqSim1BXLNpANZAHKIKAuAG8BayDWTEpRSnwPYZJpsd40MB/BPxXwFoA0RdUzOSBkRa1Y6AVgd8n5NYJqQYojIC+BIAF8D6KCUWguwoAOwb+pG1mx5CsBtAOoC7/MAbFFK1QTey7WTGg4EsAHAKwEX9UtE1BJyzaQUpdTvAJ4AUAYWaVsBfAu5ZtIJu2sk5bpAxJoV0kyTlNkUQ0StAPwbwBil1LZUj6e5Q0RnAPhTKfVt6GTNrHLtJJ8sAH0APKeUOhLATojLM+UE4p+GAzgAwP4AWoLda2bkmkk/Uv7bJmLNyhoAXULedwbwR4rGIgAgIhdYqPmVUu8GJq83zNCB1z9TNb5mynEAhhFRCThU4GSwpa1NwMUDyLWTKtYAWKOU+jrw/h2weJNrJrUMBrBKKbVBKVUN4F0Ax0KumXTC7hpJuS4QsWZlIYBugQydbHAA6LQUj6nZEoiDehnACqXUkyEfTQNwaeD/SwF8kOyxNWeUUncqpTorpbzga+RTpZQPwFwAfw3MJuclBSil1gFYTUQHByYNAvAj5JpJNWUA+hGRO/C7ZpwXuWbSB7trZBqASwJZof0AbDXcpclCiuJqIKIhYCtBJoDJSqmiFA+p2UJEAwDMA7AUwdiou8Bxa28ByAf/CJ6rlDIHiwpJgIgGAhirlDqDiA4EW9raAlgM4CKl1O5Ujq85QkS9wYkf2QB+A3A5+OFcrpkUQkTjAJwPznJfDOBKcOyTXDNJhojeADAQQDsA6wHcB+B9aK6RgLj+Bzh7tALA5UqpRUkdr4g1QRAEQRCE9EXcoIIgCIIgCGmMiDVBEARBEIQ0RsSaIAiCIAhCGiNiTRAEQRAEIY0RsSYIgiAIgpDGiFgTBKFJQ0S1RLQk5C9h1fyJyEtEyxK1PkEQBB1Z9c8iCILQqKlUSvVO9SAEQRBiRSxrgiA0S4iohIgeJaJvAn9dA9M9RDSHiH4IvOYHpncgoveI6PvA37GBVWUS0YtEtJyIZhFRTmD+G4jox8B6pqZoNwVBaAKIWBMEoamTY3KDnh/y2Tal1NHg6uRPBab9A8A/lVJHAPADeDow/WkA/1VK9QL32lwemN4NwLNKqcMBbAFwTmD6HQCODKxndEPtnCAITR/pYCAIQpOGiHYopVppppcAOFkp9RsRuQCsU0rlEdFGAB2VUtWB6WuVUu2IaAOAzqGtgIjIC+ATpVS3wPvbAbiUUg8S0ccAdoBb2LyvlNrRwLsqCEITRSxrgiA0Z5TN/3bz6Ajt41iLYCzwUADPAugL4FsikhhhQRBiQsSaIAjNmfNDXr8M/L8AwAWB/30A5gf+nwPgGgAgokwiam23UiLKANBFKTUXwG0A2gCwWPcEQRCcIE96giA0dXKIaEnI+4+VUkb5jhZE9DX4wXVEYNoNACYT0a0ANgC4PDD9RgDFRHQF2IJ2DYC1NtvMBDCFiHIBEIAJSqktCdsjQRCaFRKzJghCsyQQs1aglNqY6rEIgiBEQtyggiAIgiAIaYxY1gRBEARBENIYsawJgiAIgiCkMSLWBEEQBEEQ0hgRa4IgCIIgCGmMiDVBEARBEIQ0RsSaIAiCIAhCGiNiTRAEQRAEIY35f8AN2vk9OjlFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "history_dict1 = history1.history\n",
    "val_loss_values_1 = history_dict1['val_loss']\n",
    "val_loss_values_2 = history_dict2['val_loss']\n",
    "val_loss_values_3 = history_dict3['val_loss']\n",
    "\n",
    "epochs = range(1, len(history_dict1['acc']) + 1 )\n",
    "\n",
    "plt.plot(epochs, val_loss_values_1, 'bo', label='Validation loss Model 1')\n",
    "plt.plot(epochs, val_loss_values_2, 'b', label='Validation loss Model 2')\n",
    "plt.plot(epochs, val_loss_values_3, 'go', label='Validation loss Model 3')\n",
    "plt.title('Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6400/6400 [==============================] - 1s 172us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 2/30\n",
      "6400/6400 [==============================] - 0s 55us/step - loss: 0.6912 - acc: 0.5494\n",
      "Epoch 3/30\n",
      "6400/6400 [==============================] - 0s 51us/step - loss: 0.6841 - acc: 0.5858\n",
      "Epoch 4/30\n",
      "6400/6400 [==============================] - 0s 51us/step - loss: 0.6705 - acc: 0.5995\n",
      "Epoch 5/30\n",
      "6400/6400 [==============================] - 0s 67us/step - loss: 0.6599 - acc: 0.6078\n",
      "Epoch 6/30\n",
      "6400/6400 [==============================] - 1s 79us/step - loss: 0.6530 - acc: 0.6147\n",
      "Epoch 7/30\n",
      "6400/6400 [==============================] - 0s 64us/step - loss: 0.6498 - acc: 0.6214\n",
      "Epoch 8/30\n",
      "6400/6400 [==============================] - 0s 65us/step - loss: 0.6476 - acc: 0.6209\n",
      "Epoch 9/30\n",
      "6400/6400 [==============================] - 0s 51us/step - loss: 0.6444 - acc: 0.6206\n",
      "Epoch 10/30\n",
      "6400/6400 [==============================] - 1s 80us/step - loss: 0.6427 - acc: 0.6228\n",
      "Epoch 11/30\n",
      "6400/6400 [==============================] - 0s 66us/step - loss: 0.6417 - acc: 0.6239\n",
      "Epoch 12/30\n",
      "6400/6400 [==============================] - 0s 55us/step - loss: 0.6416 - acc: 0.6267\n",
      "Epoch 13/30\n",
      "6400/6400 [==============================] - 0s 68us/step - loss: 0.6402 - acc: 0.6250\n",
      "Epoch 14/30\n",
      "6400/6400 [==============================] - 0s 62us/step - loss: 0.6402 - acc: 0.6275\n",
      "Epoch 15/30\n",
      "6400/6400 [==============================] - 0s 55us/step - loss: 0.6380 - acc: 0.6269\n",
      "Epoch 16/30\n",
      "6400/6400 [==============================] - 0s 60us/step - loss: 0.6378 - acc: 0.6241\n",
      "Epoch 17/30\n",
      "6400/6400 [==============================] - 0s 60us/step - loss: 0.6364 - acc: 0.6303\n",
      "Epoch 18/30\n",
      "6400/6400 [==============================] - 1s 81us/step - loss: 0.6361 - acc: 0.6281\n",
      "Epoch 19/30\n",
      "6400/6400 [==============================] - 0s 67us/step - loss: 0.6352 - acc: 0.6344\n",
      "Epoch 20/30\n",
      "6400/6400 [==============================] - 0s 64us/step - loss: 0.6334 - acc: 0.6334\n",
      "Epoch 21/30\n",
      "6400/6400 [==============================] - 0s 57us/step - loss: 0.6336 - acc: 0.6342\n",
      "Epoch 22/30\n",
      "6400/6400 [==============================] - 0s 61us/step - loss: 0.6317 - acc: 0.6359\n",
      "Epoch 23/30\n",
      "6400/6400 [==============================] - 0s 61us/step - loss: 0.6324 - acc: 0.6377\n",
      "Epoch 24/30\n",
      "6400/6400 [==============================] - 0s 56us/step - loss: 0.6310 - acc: 0.6356\n",
      "Epoch 25/30\n",
      "6400/6400 [==============================] - 0s 65us/step - loss: 0.6298 - acc: 0.6441\n",
      "Epoch 26/30\n",
      "6400/6400 [==============================] - 0s 67us/step - loss: 0.6301 - acc: 0.6428\n",
      "Epoch 27/30\n",
      "6400/6400 [==============================] - 0s 70us/step - loss: 0.6291 - acc: 0.6427\n",
      "Epoch 28/30\n",
      "6400/6400 [==============================] - 0s 57us/step - loss: 0.6286 - acc: 0.6448\n",
      "Epoch 29/30\n",
      "6400/6400 [==============================] - 0s 54us/step - loss: 0.6289 - acc: 0.6398\n",
      "Epoch 30/30\n",
      "6400/6400 [==============================] - 0s 56us/step - loss: 0.6280 - acc: 0.6452\n",
      "1600/1600 [==============================] - 0s 190us/step\n"
     ]
    }
   ],
   "source": [
    "# NN Model 2 Training again with epochs = 15\n",
    "# output = activation(dot(input, kernel) + bias)\n",
    "classifier = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier.add(layers.Dense(16, activation='relu', kernel_initializer='random_normal', input_dim=13))  \n",
    "#Second  Hidden Layer\n",
    "classifier.add(layers.Dense(32, activation='relu', kernel_initializer='random_normal'))\n",
    "#Third Hidden Layer\n",
    "classifier.add(layers.Dense(32, activation='relu', kernel_initializer='random_normal'))\n",
    "#Output Layer\n",
    "classifier.add(layers.Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='rmsprop',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "\n",
    "classifier.fit(X_train, y_train, epochs=30, batch_size=128)\n",
    "results = classifier.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.650266797542572, 0.6125]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
