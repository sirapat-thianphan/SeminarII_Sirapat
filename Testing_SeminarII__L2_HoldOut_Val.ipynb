{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/sirapat-thianphan/SeminarII_Sirapat/master/events_bs2_2.csv'\n",
    "loaded_data = pd.read_csv(url, sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tactic0_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>NEAR_CCTV_</th>\n",
       "      <th>NEAR_MOOBA</th>\n",
       "      <th>MOOBAN_EST</th>\n",
       "      <th>MOOBAN_LEV</th>\n",
       "      <th>NEAR_UNITS</th>\n",
       "      <th>UNIT_TYPE</th>\n",
       "      <th>NEAR_VEHIC</th>\n",
       "      <th>VEHICLES_T</th>\n",
       "      <th>NEAR_NAIS_</th>\n",
       "      <th>NAIS_TYPE</th>\n",
       "      <th>NEAR_DIST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>101.19182</td>\n",
       "      <td>6.13009</td>\n",
       "      <td>3467.485002</td>\n",
       "      <td>85.604275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>927.963005</td>\n",
       "      <td>5</td>\n",
       "      <td>1308.145156</td>\n",
       "      <td>2</td>\n",
       "      <td>284.929088</td>\n",
       "      <td>3</td>\n",
       "      <td>27.677967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>101.26577</td>\n",
       "      <td>6.41964</td>\n",
       "      <td>972.895329</td>\n",
       "      <td>1515.131446</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1855.001821</td>\n",
       "      <td>4</td>\n",
       "      <td>2805.680397</td>\n",
       "      <td>2</td>\n",
       "      <td>1321.192664</td>\n",
       "      <td>1</td>\n",
       "      <td>1077.837387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>101.14605</td>\n",
       "      <td>6.68195</td>\n",
       "      <td>4535.321847</td>\n",
       "      <td>372.279866</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>294.153727</td>\n",
       "      <td>7</td>\n",
       "      <td>212.795421</td>\n",
       "      <td>2</td>\n",
       "      <td>323.187802</td>\n",
       "      <td>10</td>\n",
       "      <td>97.315259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>101.22266</td>\n",
       "      <td>6.85446</td>\n",
       "      <td>240.146910</td>\n",
       "      <td>333.135614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1591.508482</td>\n",
       "      <td>3</td>\n",
       "      <td>407.629181</td>\n",
       "      <td>1</td>\n",
       "      <td>155.356802</td>\n",
       "      <td>3</td>\n",
       "      <td>6.634046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>101.34695</td>\n",
       "      <td>6.45786</td>\n",
       "      <td>242.448908</td>\n",
       "      <td>1172.773291</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>558.423389</td>\n",
       "      <td>5</td>\n",
       "      <td>701.641769</td>\n",
       "      <td>2</td>\n",
       "      <td>620.660475</td>\n",
       "      <td>5</td>\n",
       "      <td>31.915022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>100.97757</td>\n",
       "      <td>6.65426</td>\n",
       "      <td>4096.016638</td>\n",
       "      <td>1315.821482</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1716.603590</td>\n",
       "      <td>5</td>\n",
       "      <td>6956.354136</td>\n",
       "      <td>1</td>\n",
       "      <td>14218.082300</td>\n",
       "      <td>5</td>\n",
       "      <td>1124.033888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>101.74995</td>\n",
       "      <td>6.27591</td>\n",
       "      <td>2686.242719</td>\n",
       "      <td>932.762119</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1707.460629</td>\n",
       "      <td>4</td>\n",
       "      <td>3448.168296</td>\n",
       "      <td>2</td>\n",
       "      <td>69.781556</td>\n",
       "      <td>6</td>\n",
       "      <td>71.977883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>101.62470</td>\n",
       "      <td>6.71488</td>\n",
       "      <td>580.185597</td>\n",
       "      <td>403.194092</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>567.060214</td>\n",
       "      <td>4</td>\n",
       "      <td>1545.663021</td>\n",
       "      <td>2</td>\n",
       "      <td>80.889155</td>\n",
       "      <td>4</td>\n",
       "      <td>35.425075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>101.28660</td>\n",
       "      <td>6.72085</td>\n",
       "      <td>302.995168</td>\n",
       "      <td>143.336508</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1104.123671</td>\n",
       "      <td>4</td>\n",
       "      <td>363.863675</td>\n",
       "      <td>2</td>\n",
       "      <td>1144.968962</td>\n",
       "      <td>3</td>\n",
       "      <td>25.827262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>101.45094</td>\n",
       "      <td>6.49835</td>\n",
       "      <td>2562.292453</td>\n",
       "      <td>250.031476</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3504.811321</td>\n",
       "      <td>4</td>\n",
       "      <td>7015.471466</td>\n",
       "      <td>2</td>\n",
       "      <td>2175.258547</td>\n",
       "      <td>6</td>\n",
       "      <td>14.428984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tactic0_id  longitude  latitude   NEAR_CCTV_   NEAR_MOOBA  MOOBAN_EST  \\\n",
       "0           1  101.19182   6.13009  3467.485002    85.604275           0   \n",
       "1           0  101.26577   6.41964   972.895329  1515.131446           0   \n",
       "2           1  101.14605   6.68195  4535.321847   372.279866           1   \n",
       "3           1  101.22266   6.85446   240.146910   333.135614           0   \n",
       "4           0  101.34695   6.45786   242.448908  1172.773291           0   \n",
       "5           0  100.97757   6.65426  4096.016638  1315.821482           0   \n",
       "6           0  101.74995   6.27591  2686.242719   932.762119           1   \n",
       "7           0  101.62470   6.71488   580.185597   403.194092           0   \n",
       "8           1  101.28660   6.72085   302.995168   143.336508           1   \n",
       "9           0  101.45094   6.49835  2562.292453   250.031476           0   \n",
       "\n",
       "   MOOBAN_LEV   NEAR_UNITS  UNIT_TYPE   NEAR_VEHIC  VEHICLES_T    NEAR_NAIS_  \\\n",
       "0           0   927.963005          5  1308.145156           2    284.929088   \n",
       "1           0  1855.001821          4  2805.680397           2   1321.192664   \n",
       "2           3   294.153727          7   212.795421           2    323.187802   \n",
       "3           0  1591.508482          3   407.629181           1    155.356802   \n",
       "4           0   558.423389          5   701.641769           2    620.660475   \n",
       "5           0  1716.603590          5  6956.354136           1  14218.082300   \n",
       "6           3  1707.460629          4  3448.168296           2     69.781556   \n",
       "7           0   567.060214          4  1545.663021           2     80.889155   \n",
       "8           3  1104.123671          4   363.863675           2   1144.968962   \n",
       "9           0  3504.811321          4  7015.471466           2   2175.258547   \n",
       "\n",
       "   NAIS_TYPE    NEAR_DIST  \n",
       "0          3    27.677967  \n",
       "1          1  1077.837387  \n",
       "2         10    97.315259  \n",
       "3          3     6.634046  \n",
       "4          5    31.915022  \n",
       "5          5  1124.033888  \n",
       "6          6    71.977883  \n",
       "7          4    35.425075  \n",
       "8          3    25.827262  \n",
       "9          6    14.428984  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = loaded_data.iloc[:,1:]\n",
    "y = loaded_data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>NEAR_CCTV_</th>\n",
       "      <th>NEAR_MOOBA</th>\n",
       "      <th>MOOBAN_EST</th>\n",
       "      <th>MOOBAN_LEV</th>\n",
       "      <th>NEAR_UNITS</th>\n",
       "      <th>UNIT_TYPE</th>\n",
       "      <th>NEAR_VEHIC</th>\n",
       "      <th>VEHICLES_T</th>\n",
       "      <th>NEAR_NAIS_</th>\n",
       "      <th>NAIS_TYPE</th>\n",
       "      <th>NEAR_DIST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.19182</td>\n",
       "      <td>6.13009</td>\n",
       "      <td>3467.485002</td>\n",
       "      <td>85.604275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>927.963005</td>\n",
       "      <td>5</td>\n",
       "      <td>1308.145156</td>\n",
       "      <td>2</td>\n",
       "      <td>284.929088</td>\n",
       "      <td>3</td>\n",
       "      <td>27.677967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.26577</td>\n",
       "      <td>6.41964</td>\n",
       "      <td>972.895329</td>\n",
       "      <td>1515.131446</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1855.001821</td>\n",
       "      <td>4</td>\n",
       "      <td>2805.680397</td>\n",
       "      <td>2</td>\n",
       "      <td>1321.192664</td>\n",
       "      <td>1</td>\n",
       "      <td>1077.837387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101.14605</td>\n",
       "      <td>6.68195</td>\n",
       "      <td>4535.321847</td>\n",
       "      <td>372.279866</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>294.153727</td>\n",
       "      <td>7</td>\n",
       "      <td>212.795421</td>\n",
       "      <td>2</td>\n",
       "      <td>323.187802</td>\n",
       "      <td>10</td>\n",
       "      <td>97.315259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.22266</td>\n",
       "      <td>6.85446</td>\n",
       "      <td>240.146910</td>\n",
       "      <td>333.135614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1591.508482</td>\n",
       "      <td>3</td>\n",
       "      <td>407.629181</td>\n",
       "      <td>1</td>\n",
       "      <td>155.356802</td>\n",
       "      <td>3</td>\n",
       "      <td>6.634046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101.34695</td>\n",
       "      <td>6.45786</td>\n",
       "      <td>242.448908</td>\n",
       "      <td>1172.773291</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>558.423389</td>\n",
       "      <td>5</td>\n",
       "      <td>701.641769</td>\n",
       "      <td>2</td>\n",
       "      <td>620.660475</td>\n",
       "      <td>5</td>\n",
       "      <td>31.915022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude   NEAR_CCTV_   NEAR_MOOBA  MOOBAN_EST  MOOBAN_LEV  \\\n",
       "0  101.19182   6.13009  3467.485002    85.604275           0           0   \n",
       "1  101.26577   6.41964   972.895329  1515.131446           0           0   \n",
       "2  101.14605   6.68195  4535.321847   372.279866           1           3   \n",
       "3  101.22266   6.85446   240.146910   333.135614           0           0   \n",
       "4  101.34695   6.45786   242.448908  1172.773291           0           0   \n",
       "\n",
       "    NEAR_UNITS  UNIT_TYPE   NEAR_VEHIC  VEHICLES_T   NEAR_NAIS_  NAIS_TYPE  \\\n",
       "0   927.963005          5  1308.145156           2   284.929088          3   \n",
       "1  1855.001821          4  2805.680397           2  1321.192664          1   \n",
       "2   294.153727          7   212.795421           2   323.187802         10   \n",
       "3  1591.508482          3   407.629181           1   155.356802          3   \n",
       "4   558.423389          5   701.641769           2   620.660475          5   \n",
       "\n",
       "     NEAR_DIST  \n",
       "0    27.677967  \n",
       "1  1077.837387  \n",
       "2    97.315259  \n",
       "3     6.634046  \n",
       "4    31.915022  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kratung/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/kratung/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "#standardizing the input feature\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.93840786, -1.40305775,  0.60341523,  0.48251584, -0.62225642,\n",
       "       -0.56807385, -0.32173501,  0.69453424, -0.33334833,  0.44593843,\n",
       "       -0.06509256, -0.35881874,  0.88035142])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NN Model 1 ( 8, 16 , 16, 1 )\n",
    "# output = activation(dot(input, kernel) + bias)\n",
    "classifier1 = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier1.add(layers.Dense(8, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_dim=13))  \n",
    "#classifier1.add(layers.Dropout(0.3))\n",
    "#Second  Hidden Layer\n",
    "classifier1.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "#classifier1.add(layers.Dropout(0.3))\n",
    "#Third Hidden Layer\n",
    "classifier1.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "#classifier1.add(layers.Dropout(0.3))\n",
    "#Output Layer\n",
    "classifier1.add(layers.Dense(1, activation='sigmoid'))\n",
    "#Compiling the neural network\n",
    "classifier1.compile(optimizer ='rmsprop',loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NN Model 2 ( 16, 32 , 32, 1 )\n",
    "# output = activation(dot(input, kernel) + bias)\n",
    "classifier2 = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier2.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_dim=13))  \n",
    "#classifier2.add(layers.Dropout(0.3))\n",
    "#Second  Hidden Layer\n",
    "classifier2.add(layers.Dense(32, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "#classifier2.add(layers.Dropout(0.3))\n",
    "#Third Hidden Layer\n",
    "classifier2.add(layers.Dense(32, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "#classifier2.add(layers.Dropout(0.3))\n",
    "#Output Layer\n",
    "classifier2.add(layers.Dense(1, activation='sigmoid'))\n",
    "#Compiling the neural network\n",
    "classifier2.compile(optimizer ='rmsprop',loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NN Model 3 ( 32, 64 , 64, 1 )\n",
    "# output = activation(dot(input, kernel) + bias)\n",
    "classifier3 = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier3.add(layers.Dense(32, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_dim=13))  \n",
    "#classifier3.add(layers.Dropout(0.3))\n",
    "#Second  Hidden Layer\n",
    "classifier3.add(layers.Dense(128, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "#classifier3.add(layers.Dropout(0.3))\n",
    "#Third Hidden Layer\n",
    "classifier3.add(layers.Dense(128, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "#classifier3.add(layers.Dropout(0.3))\n",
    "#Output Layer\n",
    "classifier3.add(layers.Dense(1, activation='sigmoid'))\n",
    "#Compiling the neural network\n",
    "classifier3.compile(optimizer ='rmsprop',loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Approach\n",
    "x_val = X_train[:1000]\n",
    "partial_x_train = X_train[1000:]\n",
    "\n",
    "y_val = y_train[:1000]\n",
    "partial_y_train = y_train[1000:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5400 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "5400/5400 [==============================] - 2s 314us/step - loss: 0.7182 - acc: 0.5457 - val_loss: 0.7148 - val_acc: 0.5600\n",
      "Epoch 2/100\n",
      "5400/5400 [==============================] - 0s 67us/step - loss: 0.7069 - acc: 0.5724 - val_loss: 0.7054 - val_acc: 0.5730\n",
      "Epoch 3/100\n",
      "5400/5400 [==============================] - 0s 67us/step - loss: 0.6978 - acc: 0.5772 - val_loss: 0.6975 - val_acc: 0.5760\n",
      "Epoch 4/100\n",
      "5400/5400 [==============================] - 0s 50us/step - loss: 0.6900 - acc: 0.5846 - val_loss: 0.6908 - val_acc: 0.5990\n",
      "Epoch 5/100\n",
      "5400/5400 [==============================] - 0s 63us/step - loss: 0.6839 - acc: 0.5928 - val_loss: 0.6859 - val_acc: 0.5990\n",
      "Epoch 6/100\n",
      "5400/5400 [==============================] - 0s 54us/step - loss: 0.6792 - acc: 0.5985 - val_loss: 0.6808 - val_acc: 0.6090\n",
      "Epoch 7/100\n",
      "5400/5400 [==============================] - 0s 48us/step - loss: 0.6757 - acc: 0.6007 - val_loss: 0.6778 - val_acc: 0.6210\n",
      "Epoch 8/100\n",
      "5400/5400 [==============================] - 0s 50us/step - loss: 0.6731 - acc: 0.6044 - val_loss: 0.6745 - val_acc: 0.6230\n",
      "Epoch 9/100\n",
      "5400/5400 [==============================] - 0s 63us/step - loss: 0.6706 - acc: 0.6044 - val_loss: 0.6722 - val_acc: 0.6240\n",
      "Epoch 10/100\n",
      "5400/5400 [==============================] - 0s 45us/step - loss: 0.6687 - acc: 0.6050 - val_loss: 0.6707 - val_acc: 0.6210\n",
      "Epoch 11/100\n",
      "5400/5400 [==============================] - 0s 44us/step - loss: 0.6668 - acc: 0.6083 - val_loss: 0.6686 - val_acc: 0.6220\n",
      "Epoch 12/100\n",
      "5400/5400 [==============================] - 0s 65us/step - loss: 0.6652 - acc: 0.6107 - val_loss: 0.6687 - val_acc: 0.6250\n",
      "Epoch 13/100\n",
      "5400/5400 [==============================] - 0s 43us/step - loss: 0.6639 - acc: 0.6131 - val_loss: 0.6655 - val_acc: 0.6190\n",
      "Epoch 14/100\n",
      "5400/5400 [==============================] - 0s 58us/step - loss: 0.6625 - acc: 0.6144 - val_loss: 0.6644 - val_acc: 0.6310\n",
      "Epoch 15/100\n",
      "5400/5400 [==============================] - 0s 62us/step - loss: 0.6607 - acc: 0.6198 - val_loss: 0.6638 - val_acc: 0.6350\n",
      "Epoch 16/100\n",
      "5400/5400 [==============================] - 0s 57us/step - loss: 0.6597 - acc: 0.6220 - val_loss: 0.6623 - val_acc: 0.6290\n",
      "Epoch 17/100\n",
      "5400/5400 [==============================] - 0s 60us/step - loss: 0.6587 - acc: 0.6235 - val_loss: 0.6615 - val_acc: 0.6380\n",
      "Epoch 18/100\n",
      "5400/5400 [==============================] - 0s 54us/step - loss: 0.6571 - acc: 0.6259 - val_loss: 0.6596 - val_acc: 0.6370\n",
      "Epoch 19/100\n",
      "5400/5400 [==============================] - 0s 59us/step - loss: 0.6562 - acc: 0.6250 - val_loss: 0.6594 - val_acc: 0.6300\n",
      "Epoch 20/100\n",
      "5400/5400 [==============================] - 0s 53us/step - loss: 0.6550 - acc: 0.6263 - val_loss: 0.6581 - val_acc: 0.6310\n",
      "Epoch 21/100\n",
      "5400/5400 [==============================] - 0s 53us/step - loss: 0.6541 - acc: 0.6272 - val_loss: 0.6577 - val_acc: 0.6290\n",
      "Epoch 22/100\n",
      "5400/5400 [==============================] - 0s 81us/step - loss: 0.6534 - acc: 0.6309 - val_loss: 0.6570 - val_acc: 0.6320\n",
      "Epoch 23/100\n",
      "5400/5400 [==============================] - 0s 54us/step - loss: 0.6528 - acc: 0.6280 - val_loss: 0.6559 - val_acc: 0.6310\n",
      "Epoch 24/100\n",
      "5400/5400 [==============================] - 0s 63us/step - loss: 0.6517 - acc: 0.6306 - val_loss: 0.6557 - val_acc: 0.6310\n",
      "Epoch 25/100\n",
      "5400/5400 [==============================] - 0s 47us/step - loss: 0.6504 - acc: 0.6306 - val_loss: 0.6559 - val_acc: 0.6260\n",
      "Epoch 26/100\n",
      "5400/5400 [==============================] - 0s 64us/step - loss: 0.6500 - acc: 0.6280 - val_loss: 0.6547 - val_acc: 0.6270\n",
      "Epoch 27/100\n",
      "5400/5400 [==============================] - 0s 57us/step - loss: 0.6487 - acc: 0.6319 - val_loss: 0.6533 - val_acc: 0.6330\n",
      "Epoch 28/100\n",
      "5400/5400 [==============================] - 0s 54us/step - loss: 0.6482 - acc: 0.6322 - val_loss: 0.6540 - val_acc: 0.6280\n",
      "Epoch 29/100\n",
      "5400/5400 [==============================] - 0s 59us/step - loss: 0.6470 - acc: 0.6326 - val_loss: 0.6538 - val_acc: 0.6390\n",
      "Epoch 30/100\n",
      "5400/5400 [==============================] - 0s 62us/step - loss: 0.6466 - acc: 0.6350 - val_loss: 0.6533 - val_acc: 0.6270\n",
      "Epoch 31/100\n",
      "5400/5400 [==============================] - 0s 68us/step - loss: 0.6459 - acc: 0.6359 - val_loss: 0.6521 - val_acc: 0.6380\n",
      "Epoch 32/100\n",
      "5400/5400 [==============================] - 0s 59us/step - loss: 0.6454 - acc: 0.6365 - val_loss: 0.6518 - val_acc: 0.6420\n",
      "Epoch 33/100\n",
      "5400/5400 [==============================] - 0s 53us/step - loss: 0.6447 - acc: 0.6387 - val_loss: 0.6512 - val_acc: 0.6460\n",
      "Epoch 34/100\n",
      "5400/5400 [==============================] - 0s 54us/step - loss: 0.6442 - acc: 0.6385 - val_loss: 0.6513 - val_acc: 0.6430\n",
      "Epoch 35/100\n",
      "5400/5400 [==============================] - 0s 65us/step - loss: 0.6436 - acc: 0.6393 - val_loss: 0.6517 - val_acc: 0.6390\n",
      "Epoch 36/100\n",
      "5400/5400 [==============================] - 0s 63us/step - loss: 0.6428 - acc: 0.6394 - val_loss: 0.6525 - val_acc: 0.6370\n",
      "Epoch 37/100\n",
      "5400/5400 [==============================] - 0s 62us/step - loss: 0.6427 - acc: 0.6380 - val_loss: 0.6487 - val_acc: 0.6470\n",
      "Epoch 38/100\n",
      "5400/5400 [==============================] - 0s 57us/step - loss: 0.6420 - acc: 0.6411 - val_loss: 0.6496 - val_acc: 0.6460\n",
      "Epoch 39/100\n",
      "5400/5400 [==============================] - 0s 44us/step - loss: 0.6413 - acc: 0.6394 - val_loss: 0.6489 - val_acc: 0.6430\n",
      "Epoch 40/100\n",
      "5400/5400 [==============================] - 0s 49us/step - loss: 0.6408 - acc: 0.6413 - val_loss: 0.6492 - val_acc: 0.6450\n",
      "Epoch 41/100\n",
      "5400/5400 [==============================] - 0s 45us/step - loss: 0.6402 - acc: 0.6417 - val_loss: 0.6494 - val_acc: 0.6440\n",
      "Epoch 42/100\n",
      "5400/5400 [==============================] - 0s 45us/step - loss: 0.6398 - acc: 0.6402 - val_loss: 0.6479 - val_acc: 0.6430\n",
      "Epoch 43/100\n",
      "5400/5400 [==============================] - 0s 45us/step - loss: 0.6390 - acc: 0.6448 - val_loss: 0.6483 - val_acc: 0.6390\n",
      "Epoch 44/100\n",
      "5400/5400 [==============================] - 0s 45us/step - loss: 0.6386 - acc: 0.6437 - val_loss: 0.6480 - val_acc: 0.6370\n",
      "Epoch 45/100\n",
      "5400/5400 [==============================] - 0s 42us/step - loss: 0.6383 - acc: 0.6467 - val_loss: 0.6478 - val_acc: 0.6360\n",
      "Epoch 46/100\n",
      "5400/5400 [==============================] - 0s 45us/step - loss: 0.6376 - acc: 0.6430 - val_loss: 0.6470 - val_acc: 0.6490\n",
      "Epoch 47/100\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.6372 - acc: 0.6467 - val_loss: 0.6467 - val_acc: 0.6450\n",
      "Epoch 48/100\n",
      "5400/5400 [==============================] - 0s 63us/step - loss: 0.6369 - acc: 0.6480 - val_loss: 0.6477 - val_acc: 0.6420\n",
      "Epoch 49/100\n",
      "5400/5400 [==============================] - 0s 46us/step - loss: 0.6370 - acc: 0.6491 - val_loss: 0.6465 - val_acc: 0.6500\n",
      "Epoch 50/100\n",
      "5400/5400 [==============================] - 0s 55us/step - loss: 0.6361 - acc: 0.6491 - val_loss: 0.6462 - val_acc: 0.6470\n",
      "Epoch 51/100\n",
      "5400/5400 [==============================] - 0s 70us/step - loss: 0.6357 - acc: 0.6511 - val_loss: 0.6473 - val_acc: 0.6410\n",
      "Epoch 52/100\n",
      "5400/5400 [==============================] - 0s 66us/step - loss: 0.6358 - acc: 0.6480 - val_loss: 0.6483 - val_acc: 0.6390\n",
      "Epoch 53/100\n",
      "5400/5400 [==============================] - 0s 50us/step - loss: 0.6356 - acc: 0.6480 - val_loss: 0.6460 - val_acc: 0.6490\n",
      "Epoch 54/100\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.6353 - acc: 0.6480 - val_loss: 0.6468 - val_acc: 0.6410\n",
      "Epoch 55/100\n",
      "5400/5400 [==============================] - 0s 45us/step - loss: 0.6349 - acc: 0.6472 - val_loss: 0.6459 - val_acc: 0.6490\n",
      "Epoch 56/100\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.6347 - acc: 0.6504 - val_loss: 0.6472 - val_acc: 0.6420\n",
      "Epoch 57/100\n",
      "5400/5400 [==============================] - 0s 42us/step - loss: 0.6343 - acc: 0.6511 - val_loss: 0.6472 - val_acc: 0.6460\n",
      "Epoch 58/100\n",
      "5400/5400 [==============================] - 0s 42us/step - loss: 0.6343 - acc: 0.6509 - val_loss: 0.6467 - val_acc: 0.6480\n",
      "Epoch 59/100\n",
      "5400/5400 [==============================] - 0s 44us/step - loss: 0.6340 - acc: 0.6489 - val_loss: 0.6475 - val_acc: 0.6500\n",
      "Epoch 60/100\n",
      "5400/5400 [==============================] - 0s 44us/step - loss: 0.6340 - acc: 0.6500 - val_loss: 0.6451 - val_acc: 0.6470\n",
      "Epoch 61/100\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.6335 - acc: 0.6502 - val_loss: 0.6456 - val_acc: 0.6480\n",
      "Epoch 62/100\n",
      "5400/5400 [==============================] - 0s 44us/step - loss: 0.6334 - acc: 0.6467 - val_loss: 0.6458 - val_acc: 0.6470\n",
      "Epoch 63/100\n",
      "5400/5400 [==============================] - 0s 45us/step - loss: 0.6331 - acc: 0.6496 - val_loss: 0.6462 - val_acc: 0.6480\n",
      "Epoch 64/100\n",
      "5400/5400 [==============================] - 0s 54us/step - loss: 0.6330 - acc: 0.6506 - val_loss: 0.6445 - val_acc: 0.6470\n",
      "Epoch 65/100\n",
      "5400/5400 [==============================] - 0s 42us/step - loss: 0.6328 - acc: 0.6524 - val_loss: 0.6453 - val_acc: 0.6490\n",
      "Epoch 66/100\n",
      "5400/5400 [==============================] - 0s 42us/step - loss: 0.6327 - acc: 0.6487 - val_loss: 0.6463 - val_acc: 0.6470\n",
      "Epoch 67/100\n",
      "5400/5400 [==============================] - 0s 42us/step - loss: 0.6324 - acc: 0.6507 - val_loss: 0.6456 - val_acc: 0.6460\n",
      "Epoch 68/100\n",
      "5400/5400 [==============================] - 0s 42us/step - loss: 0.6324 - acc: 0.6517 - val_loss: 0.6445 - val_acc: 0.6490\n",
      "Epoch 69/100\n",
      "5400/5400 [==============================] - 0s 49us/step - loss: 0.6319 - acc: 0.6506 - val_loss: 0.6465 - val_acc: 0.6450\n",
      "Epoch 70/100\n",
      "5400/5400 [==============================] - 0s 45us/step - loss: 0.6321 - acc: 0.6535 - val_loss: 0.6464 - val_acc: 0.6470\n",
      "Epoch 71/100\n",
      "5400/5400 [==============================] - 0s 44us/step - loss: 0.6321 - acc: 0.6520 - val_loss: 0.6448 - val_acc: 0.6480\n",
      "Epoch 72/100\n",
      "5400/5400 [==============================] - 0s 46us/step - loss: 0.6315 - acc: 0.6494 - val_loss: 0.6468 - val_acc: 0.6470\n",
      "Epoch 73/100\n",
      "5400/5400 [==============================] - 0s 46us/step - loss: 0.6312 - acc: 0.6507 - val_loss: 0.6446 - val_acc: 0.6460\n",
      "Epoch 74/100\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.6315 - acc: 0.6504 - val_loss: 0.6445 - val_acc: 0.6460\n",
      "Epoch 75/100\n",
      "5400/5400 [==============================] - 0s 49us/step - loss: 0.6312 - acc: 0.6520 - val_loss: 0.6475 - val_acc: 0.6440\n",
      "Epoch 76/100\n",
      "5400/5400 [==============================] - 0s 50us/step - loss: 0.6311 - acc: 0.6533 - val_loss: 0.6453 - val_acc: 0.6470\n",
      "Epoch 77/100\n",
      "5400/5400 [==============================] - 0s 56us/step - loss: 0.6310 - acc: 0.6509 - val_loss: 0.6450 - val_acc: 0.6440\n",
      "Epoch 78/100\n",
      "5400/5400 [==============================] - 0s 53us/step - loss: 0.6309 - acc: 0.6515 - val_loss: 0.6448 - val_acc: 0.6440\n",
      "Epoch 79/100\n",
      "5400/5400 [==============================] - 0s 47us/step - loss: 0.6305 - acc: 0.6533 - val_loss: 0.6456 - val_acc: 0.6510\n",
      "Epoch 80/100\n",
      "5400/5400 [==============================] - 0s 42us/step - loss: 0.6303 - acc: 0.6520 - val_loss: 0.6445 - val_acc: 0.6450\n",
      "Epoch 81/100\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.6305 - acc: 0.6520 - val_loss: 0.6445 - val_acc: 0.6510\n",
      "Epoch 82/100\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.6297 - acc: 0.6520 - val_loss: 0.6437 - val_acc: 0.6470\n",
      "Epoch 83/100\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.6299 - acc: 0.6517 - val_loss: 0.6489 - val_acc: 0.6450\n",
      "Epoch 84/100\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.6304 - acc: 0.6493 - val_loss: 0.6454 - val_acc: 0.6500\n",
      "Epoch 85/100\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.6298 - acc: 0.6537 - val_loss: 0.6440 - val_acc: 0.6450\n",
      "Epoch 86/100\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.6296 - acc: 0.6509 - val_loss: 0.6433 - val_acc: 0.6480\n",
      "Epoch 87/100\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.6296 - acc: 0.6478 - val_loss: 0.6454 - val_acc: 0.6420\n",
      "Epoch 88/100\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.6296 - acc: 0.6520 - val_loss: 0.6447 - val_acc: 0.6520\n",
      "Epoch 89/100\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.6295 - acc: 0.6500 - val_loss: 0.6443 - val_acc: 0.6550\n",
      "Epoch 90/100\n",
      "5400/5400 [==============================] - 0s 46us/step - loss: 0.6289 - acc: 0.6509 - val_loss: 0.6435 - val_acc: 0.6510\n",
      "Epoch 91/100\n",
      "5400/5400 [==============================] - 0s 46us/step - loss: 0.6290 - acc: 0.6506 - val_loss: 0.6435 - val_acc: 0.6500\n",
      "Epoch 92/100\n",
      "5400/5400 [==============================] - 0s 47us/step - loss: 0.6291 - acc: 0.6524 - val_loss: 0.6443 - val_acc: 0.6520\n",
      "Epoch 93/100\n",
      "5400/5400 [==============================] - 0s 56us/step - loss: 0.6287 - acc: 0.6528 - val_loss: 0.6470 - val_acc: 0.6440\n",
      "Epoch 94/100\n",
      "5400/5400 [==============================] - 0s 54us/step - loss: 0.6288 - acc: 0.6528 - val_loss: 0.6431 - val_acc: 0.6520\n",
      "Epoch 95/100\n",
      "5400/5400 [==============================] - 0s 57us/step - loss: 0.6287 - acc: 0.6511 - val_loss: 0.6429 - val_acc: 0.6540\n",
      "Epoch 96/100\n",
      "5400/5400 [==============================] - 0s 57us/step - loss: 0.6281 - acc: 0.6569 - val_loss: 0.6427 - val_acc: 0.6570\n",
      "Epoch 97/100\n",
      "5400/5400 [==============================] - 0s 71us/step - loss: 0.6278 - acc: 0.6513 - val_loss: 0.6442 - val_acc: 0.6520\n",
      "Epoch 98/100\n",
      "5400/5400 [==============================] - 0s 47us/step - loss: 0.6280 - acc: 0.6513 - val_loss: 0.6438 - val_acc: 0.6560\n",
      "Epoch 99/100\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.6279 - acc: 0.6522 - val_loss: 0.6420 - val_acc: 0.6510\n",
      "Epoch 100/100\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.6277 - acc: 0.6526 - val_loss: 0.6422 - val_acc: 0.6550\n"
     ]
    }
   ],
   "source": [
    "classifier1.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history1 = classifier1.fit(partial_x_train, partial_y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5400 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "5400/5400 [==============================] - 2s 290us/step - loss: 0.7470 - acc: 0.5622 - val_loss: 0.7317 - val_acc: 0.5760\n",
      "Epoch 2/100\n",
      "5400/5400 [==============================] - 0s 57us/step - loss: 0.7186 - acc: 0.6024 - val_loss: 0.7125 - val_acc: 0.6050\n",
      "Epoch 3/100\n",
      "5400/5400 [==============================] - 0s 54us/step - loss: 0.7036 - acc: 0.6078 - val_loss: 0.7016 - val_acc: 0.6300\n",
      "Epoch 4/100\n",
      "5400/5400 [==============================] - 0s 55us/step - loss: 0.6940 - acc: 0.6137 - val_loss: 0.6953 - val_acc: 0.6290\n",
      "Epoch 5/100\n",
      "5400/5400 [==============================] - 0s 60us/step - loss: 0.6873 - acc: 0.6233 - val_loss: 0.6882 - val_acc: 0.6240\n",
      "Epoch 6/100\n",
      "5400/5400 [==============================] - 0s 66us/step - loss: 0.6822 - acc: 0.6235 - val_loss: 0.6832 - val_acc: 0.6370\n",
      "Epoch 7/100\n",
      "5400/5400 [==============================] - 0s 66us/step - loss: 0.6783 - acc: 0.6254 - val_loss: 0.6798 - val_acc: 0.6400\n",
      "Epoch 8/100\n",
      "5400/5400 [==============================] - 0s 65us/step - loss: 0.6745 - acc: 0.6278 - val_loss: 0.6777 - val_acc: 0.6400\n",
      "Epoch 9/100\n",
      "5400/5400 [==============================] - 0s 63us/step - loss: 0.6713 - acc: 0.6361 - val_loss: 0.6751 - val_acc: 0.6400\n",
      "Epoch 10/100\n",
      "5400/5400 [==============================] - 0s 60us/step - loss: 0.6686 - acc: 0.6350 - val_loss: 0.6723 - val_acc: 0.6440\n",
      "Epoch 11/100\n",
      "5400/5400 [==============================] - 0s 57us/step - loss: 0.6658 - acc: 0.6430 - val_loss: 0.6734 - val_acc: 0.6260\n",
      "Epoch 12/100\n",
      "5400/5400 [==============================] - 0s 68us/step - loss: 0.6641 - acc: 0.6407 - val_loss: 0.6699 - val_acc: 0.6350\n",
      "Epoch 13/100\n",
      "5400/5400 [==============================] - 0s 67us/step - loss: 0.6615 - acc: 0.6448 - val_loss: 0.6727 - val_acc: 0.6260\n",
      "Epoch 14/100\n",
      "5400/5400 [==============================] - 0s 70us/step - loss: 0.6597 - acc: 0.6448 - val_loss: 0.6714 - val_acc: 0.6290\n",
      "Epoch 15/100\n",
      "5400/5400 [==============================] - 0s 62us/step - loss: 0.6581 - acc: 0.6478 - val_loss: 0.6653 - val_acc: 0.6340\n",
      "Epoch 16/100\n",
      "5400/5400 [==============================] - 0s 79us/step - loss: 0.6558 - acc: 0.6494 - val_loss: 0.6690 - val_acc: 0.6310\n",
      "Epoch 17/100\n",
      "5400/5400 [==============================] - 0s 73us/step - loss: 0.6544 - acc: 0.6467 - val_loss: 0.6660 - val_acc: 0.6340\n",
      "Epoch 18/100\n",
      "5400/5400 [==============================] - 0s 78us/step - loss: 0.6526 - acc: 0.6530 - val_loss: 0.6621 - val_acc: 0.6370\n",
      "Epoch 19/100\n",
      "5400/5400 [==============================] - 0s 74us/step - loss: 0.6519 - acc: 0.6519 - val_loss: 0.6615 - val_acc: 0.6270\n",
      "Epoch 20/100\n",
      "5400/5400 [==============================] - 0s 73us/step - loss: 0.6505 - acc: 0.6441 - val_loss: 0.6631 - val_acc: 0.6270\n",
      "Epoch 21/100\n",
      "5400/5400 [==============================] - 0s 75us/step - loss: 0.6488 - acc: 0.6483 - val_loss: 0.6638 - val_acc: 0.6320\n",
      "Epoch 22/100\n",
      "5400/5400 [==============================] - 0s 78us/step - loss: 0.6486 - acc: 0.6528 - val_loss: 0.6626 - val_acc: 0.6300\n",
      "Epoch 23/100\n",
      "5400/5400 [==============================] - 0s 73us/step - loss: 0.6472 - acc: 0.6507 - val_loss: 0.6613 - val_acc: 0.6340\n",
      "Epoch 24/100\n",
      "5400/5400 [==============================] - 0s 85us/step - loss: 0.6464 - acc: 0.6502 - val_loss: 0.6617 - val_acc: 0.6330\n",
      "Epoch 25/100\n",
      "5400/5400 [==============================] - 1s 93us/step - loss: 0.6450 - acc: 0.6515 - val_loss: 0.6582 - val_acc: 0.6380\n",
      "Epoch 26/100\n",
      "5400/5400 [==============================] - 0s 82us/step - loss: 0.6446 - acc: 0.6561 - val_loss: 0.6597 - val_acc: 0.6440\n",
      "Epoch 27/100\n",
      "5400/5400 [==============================] - 0s 88us/step - loss: 0.6436 - acc: 0.6533 - val_loss: 0.6598 - val_acc: 0.6390\n",
      "Epoch 28/100\n",
      "5400/5400 [==============================] - 0s 79us/step - loss: 0.6421 - acc: 0.6574 - val_loss: 0.6585 - val_acc: 0.6410\n",
      "Epoch 29/100\n",
      "5400/5400 [==============================] - 0s 71us/step - loss: 0.6420 - acc: 0.6546 - val_loss: 0.6579 - val_acc: 0.6450\n",
      "Epoch 30/100\n",
      "5400/5400 [==============================] - 0s 90us/step - loss: 0.6412 - acc: 0.6576 - val_loss: 0.6573 - val_acc: 0.6490\n",
      "Epoch 31/100\n",
      "5400/5400 [==============================] - 0s 80us/step - loss: 0.6404 - acc: 0.6552 - val_loss: 0.6579 - val_acc: 0.6440\n",
      "Epoch 32/100\n",
      "5400/5400 [==============================] - 0s 71us/step - loss: 0.6402 - acc: 0.6559 - val_loss: 0.6591 - val_acc: 0.6330\n",
      "Epoch 33/100\n",
      "5400/5400 [==============================] - 0s 79us/step - loss: 0.6389 - acc: 0.6598 - val_loss: 0.6582 - val_acc: 0.6510\n",
      "Epoch 34/100\n",
      "5400/5400 [==============================] - 0s 61us/step - loss: 0.6392 - acc: 0.6587 - val_loss: 0.6579 - val_acc: 0.6500\n",
      "Epoch 35/100\n",
      "5400/5400 [==============================] - 0s 86us/step - loss: 0.6378 - acc: 0.6606 - val_loss: 0.6614 - val_acc: 0.6240\n",
      "Epoch 36/100\n",
      "5400/5400 [==============================] - 0s 66us/step - loss: 0.6377 - acc: 0.6533 - val_loss: 0.6554 - val_acc: 0.6480\n",
      "Epoch 37/100\n",
      "5400/5400 [==============================] - 0s 85us/step - loss: 0.6371 - acc: 0.6587 - val_loss: 0.6560 - val_acc: 0.6430\n",
      "Epoch 38/100\n",
      "5400/5400 [==============================] - 0s 75us/step - loss: 0.6366 - acc: 0.6600 - val_loss: 0.6562 - val_acc: 0.6390\n",
      "Epoch 39/100\n",
      "5400/5400 [==============================] - 0s 71us/step - loss: 0.6364 - acc: 0.6635 - val_loss: 0.6560 - val_acc: 0.6430\n",
      "Epoch 40/100\n",
      "5400/5400 [==============================] - 0s 83us/step - loss: 0.6357 - acc: 0.6594 - val_loss: 0.6546 - val_acc: 0.6480\n",
      "Epoch 41/100\n",
      "5400/5400 [==============================] - 0s 84us/step - loss: 0.6347 - acc: 0.6630 - val_loss: 0.6576 - val_acc: 0.6450\n",
      "Epoch 42/100\n",
      "5400/5400 [==============================] - 0s 68us/step - loss: 0.6352 - acc: 0.6650 - val_loss: 0.6578 - val_acc: 0.6450\n",
      "Epoch 43/100\n",
      "5400/5400 [==============================] - 0s 84us/step - loss: 0.6343 - acc: 0.6617 - val_loss: 0.6567 - val_acc: 0.6340\n",
      "Epoch 44/100\n",
      "5400/5400 [==============================] - 0s 78us/step - loss: 0.6339 - acc: 0.6633 - val_loss: 0.6558 - val_acc: 0.6410\n",
      "Epoch 45/100\n",
      "5400/5400 [==============================] - 0s 73us/step - loss: 0.6333 - acc: 0.6630 - val_loss: 0.6619 - val_acc: 0.6270\n",
      "Epoch 46/100\n",
      "5400/5400 [==============================] - 0s 92us/step - loss: 0.6329 - acc: 0.6622 - val_loss: 0.6634 - val_acc: 0.6480\n",
      "Epoch 47/100\n",
      "5400/5400 [==============================] - 0s 82us/step - loss: 0.6323 - acc: 0.6637 - val_loss: 0.6549 - val_acc: 0.6460\n",
      "Epoch 48/100\n",
      "5400/5400 [==============================] - 0s 70us/step - loss: 0.6318 - acc: 0.6650 - val_loss: 0.6566 - val_acc: 0.6400\n",
      "Epoch 49/100\n",
      "5400/5400 [==============================] - 0s 76us/step - loss: 0.6312 - acc: 0.6613 - val_loss: 0.6628 - val_acc: 0.6160\n",
      "Epoch 50/100\n",
      "5400/5400 [==============================] - 0s 81us/step - loss: 0.6309 - acc: 0.6652 - val_loss: 0.6589 - val_acc: 0.6310\n",
      "Epoch 51/100\n",
      "5400/5400 [==============================] - 0s 83us/step - loss: 0.6307 - acc: 0.6646 - val_loss: 0.6562 - val_acc: 0.6570\n",
      "Epoch 52/100\n",
      "5400/5400 [==============================] - 0s 83us/step - loss: 0.6311 - acc: 0.6656 - val_loss: 0.6591 - val_acc: 0.6320\n",
      "Epoch 53/100\n",
      "5400/5400 [==============================] - 0s 85us/step - loss: 0.6300 - acc: 0.6691 - val_loss: 0.6559 - val_acc: 0.6330\n",
      "Epoch 54/100\n",
      "5400/5400 [==============================] - 0s 80us/step - loss: 0.6297 - acc: 0.6678 - val_loss: 0.6559 - val_acc: 0.6370\n",
      "Epoch 55/100\n",
      "5400/5400 [==============================] - 1s 100us/step - loss: 0.6291 - acc: 0.6676 - val_loss: 0.6611 - val_acc: 0.6370\n",
      "Epoch 56/100\n",
      "5400/5400 [==============================] - 0s 72us/step - loss: 0.6295 - acc: 0.6643 - val_loss: 0.6581 - val_acc: 0.6340\n",
      "Epoch 57/100\n",
      "5400/5400 [==============================] - 0s 84us/step - loss: 0.6289 - acc: 0.6685 - val_loss: 0.6556 - val_acc: 0.6340\n",
      "Epoch 58/100\n",
      "5400/5400 [==============================] - 0s 74us/step - loss: 0.6278 - acc: 0.6672 - val_loss: 0.6669 - val_acc: 0.6100\n",
      "Epoch 59/100\n",
      "5400/5400 [==============================] - 0s 70us/step - loss: 0.6279 - acc: 0.6685 - val_loss: 0.6584 - val_acc: 0.6310\n",
      "Epoch 60/100\n",
      "5400/5400 [==============================] - 0s 65us/step - loss: 0.6273 - acc: 0.6693 - val_loss: 0.6565 - val_acc: 0.6270\n",
      "Epoch 61/100\n",
      "5400/5400 [==============================] - 0s 60us/step - loss: 0.6275 - acc: 0.6685 - val_loss: 0.6602 - val_acc: 0.6390\n",
      "Epoch 62/100\n",
      "5400/5400 [==============================] - 0s 60us/step - loss: 0.6269 - acc: 0.6685 - val_loss: 0.6605 - val_acc: 0.6380\n",
      "Epoch 63/100\n",
      "5400/5400 [==============================] - 0s 61us/step - loss: 0.6261 - acc: 0.6681 - val_loss: 0.6584 - val_acc: 0.6280\n",
      "Epoch 64/100\n",
      "5400/5400 [==============================] - 0s 59us/step - loss: 0.6265 - acc: 0.6698 - val_loss: 0.6607 - val_acc: 0.6360\n",
      "Epoch 65/100\n",
      "5400/5400 [==============================] - 0s 61us/step - loss: 0.6260 - acc: 0.6661 - val_loss: 0.6695 - val_acc: 0.6140\n",
      "Epoch 66/100\n",
      "5400/5400 [==============================] - 0s 69us/step - loss: 0.6252 - acc: 0.6719 - val_loss: 0.6597 - val_acc: 0.6400\n",
      "Epoch 67/100\n",
      "5400/5400 [==============================] - 0s 91us/step - loss: 0.6248 - acc: 0.6722 - val_loss: 0.6596 - val_acc: 0.6270\n",
      "Epoch 68/100\n",
      "5400/5400 [==============================] - 0s 63us/step - loss: 0.6248 - acc: 0.6696 - val_loss: 0.6592 - val_acc: 0.6280\n",
      "Epoch 69/100\n",
      "5400/5400 [==============================] - 0s 82us/step - loss: 0.6250 - acc: 0.6709 - val_loss: 0.6655 - val_acc: 0.6400\n",
      "Epoch 70/100\n",
      "5400/5400 [==============================] - 0s 84us/step - loss: 0.6246 - acc: 0.6659 - val_loss: 0.6615 - val_acc: 0.6190\n",
      "Epoch 71/100\n",
      "5400/5400 [==============================] - 0s 91us/step - loss: 0.6245 - acc: 0.6715 - val_loss: 0.6616 - val_acc: 0.6300\n",
      "Epoch 72/100\n",
      "5400/5400 [==============================] - 0s 82us/step - loss: 0.6252 - acc: 0.6694 - val_loss: 0.6574 - val_acc: 0.6320\n",
      "Epoch 73/100\n",
      "5400/5400 [==============================] - 0s 61us/step - loss: 0.6235 - acc: 0.6676 - val_loss: 0.6648 - val_acc: 0.6190\n",
      "Epoch 74/100\n",
      "5400/5400 [==============================] - 0s 87us/step - loss: 0.6229 - acc: 0.6737 - val_loss: 0.6630 - val_acc: 0.6510\n",
      "Epoch 75/100\n",
      "5400/5400 [==============================] - 0s 74us/step - loss: 0.6217 - acc: 0.6700 - val_loss: 0.6591 - val_acc: 0.6450\n",
      "Epoch 76/100\n",
      "5400/5400 [==============================] - 0s 86us/step - loss: 0.6233 - acc: 0.6704 - val_loss: 0.6626 - val_acc: 0.6380\n",
      "Epoch 77/100\n",
      "5400/5400 [==============================] - 0s 64us/step - loss: 0.6219 - acc: 0.6711 - val_loss: 0.6649 - val_acc: 0.6120\n",
      "Epoch 78/100\n",
      "5400/5400 [==============================] - 0s 77us/step - loss: 0.6230 - acc: 0.6735 - val_loss: 0.6592 - val_acc: 0.6220\n",
      "Epoch 79/100\n",
      "5400/5400 [==============================] - 0s 62us/step - loss: 0.6220 - acc: 0.6746 - val_loss: 0.6607 - val_acc: 0.6370\n",
      "Epoch 80/100\n",
      "5400/5400 [==============================] - 0s 62us/step - loss: 0.6221 - acc: 0.6719 - val_loss: 0.6589 - val_acc: 0.6290\n",
      "Epoch 81/100\n",
      "5400/5400 [==============================] - 0s 61us/step - loss: 0.6216 - acc: 0.6709 - val_loss: 0.6606 - val_acc: 0.6320\n",
      "Epoch 82/100\n",
      "5400/5400 [==============================] - 0s 87us/step - loss: 0.6218 - acc: 0.6739 - val_loss: 0.6640 - val_acc: 0.6210\n",
      "Epoch 83/100\n",
      "5400/5400 [==============================] - 0s 73us/step - loss: 0.6217 - acc: 0.6737 - val_loss: 0.6641 - val_acc: 0.6100\n",
      "Epoch 84/100\n",
      "5400/5400 [==============================] - 0s 87us/step - loss: 0.6205 - acc: 0.6719 - val_loss: 0.6620 - val_acc: 0.6330\n",
      "Epoch 85/100\n",
      "5400/5400 [==============================] - 0s 92us/step - loss: 0.6209 - acc: 0.6733 - val_loss: 0.6638 - val_acc: 0.6210\n",
      "Epoch 86/100\n",
      "5400/5400 [==============================] - 0s 86us/step - loss: 0.6207 - acc: 0.6715 - val_loss: 0.6621 - val_acc: 0.6180\n",
      "Epoch 87/100\n",
      "5400/5400 [==============================] - 0s 65us/step - loss: 0.6196 - acc: 0.6761 - val_loss: 0.6639 - val_acc: 0.6410\n",
      "Epoch 88/100\n",
      "5400/5400 [==============================] - 0s 82us/step - loss: 0.6203 - acc: 0.6748 - val_loss: 0.6639 - val_acc: 0.6160\n",
      "Epoch 89/100\n",
      "5400/5400 [==============================] - 0s 70us/step - loss: 0.6195 - acc: 0.6748 - val_loss: 0.6627 - val_acc: 0.6370\n",
      "Epoch 90/100\n",
      "5400/5400 [==============================] - 0s 79us/step - loss: 0.6198 - acc: 0.6767 - val_loss: 0.6617 - val_acc: 0.6300\n",
      "Epoch 91/100\n",
      "5400/5400 [==============================] - 0s 88us/step - loss: 0.6191 - acc: 0.6748 - val_loss: 0.6638 - val_acc: 0.6170\n",
      "Epoch 92/100\n",
      "5400/5400 [==============================] - 0s 73us/step - loss: 0.6191 - acc: 0.6719 - val_loss: 0.6585 - val_acc: 0.6230\n",
      "Epoch 93/100\n",
      "5400/5400 [==============================] - 0s 84us/step - loss: 0.6185 - acc: 0.6737 - val_loss: 0.6652 - val_acc: 0.6310\n",
      "Epoch 94/100\n",
      "5400/5400 [==============================] - 0s 72us/step - loss: 0.6184 - acc: 0.6746 - val_loss: 0.6664 - val_acc: 0.6230\n",
      "Epoch 95/100\n",
      "5400/5400 [==============================] - 0s 58us/step - loss: 0.6182 - acc: 0.6759 - val_loss: 0.6639 - val_acc: 0.6310\n",
      "Epoch 96/100\n",
      "5400/5400 [==============================] - 0s 62us/step - loss: 0.6184 - acc: 0.6744 - val_loss: 0.6735 - val_acc: 0.6080\n",
      "Epoch 97/100\n",
      "5400/5400 [==============================] - 1s 93us/step - loss: 0.6187 - acc: 0.6739 - val_loss: 0.6715 - val_acc: 0.6060\n",
      "Epoch 98/100\n",
      "5400/5400 [==============================] - 0s 80us/step - loss: 0.6178 - acc: 0.6761 - val_loss: 0.6610 - val_acc: 0.6240\n",
      "Epoch 99/100\n",
      "5400/5400 [==============================] - 0s 72us/step - loss: 0.6179 - acc: 0.6752 - val_loss: 0.6615 - val_acc: 0.6270\n",
      "Epoch 100/100\n",
      "5400/5400 [==============================] - 0s 66us/step - loss: 0.6173 - acc: 0.6728 - val_loss: 0.6610 - val_acc: 0.6240\n"
     ]
    }
   ],
   "source": [
    "classifier2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history2 = classifier2.fit(partial_x_train, partial_y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5400 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "5400/5400 [==============================] - 5s 834us/step - loss: 0.9125 - acc: 0.5961 - val_loss: 0.8730 - val_acc: 0.5830\n",
      "Epoch 2/100\n",
      "5400/5400 [==============================] - 3s 484us/step - loss: 0.8184 - acc: 0.6219 - val_loss: 0.7940 - val_acc: 0.6310\n",
      "Epoch 3/100\n",
      "5400/5400 [==============================] - 2s 443us/step - loss: 0.7689 - acc: 0.6233 - val_loss: 0.7515 - val_acc: 0.6470\n",
      "Epoch 4/100\n",
      "5400/5400 [==============================] - 2s 429us/step - loss: 0.7358 - acc: 0.6350 - val_loss: 0.7544 - val_acc: 0.6140\n",
      "Epoch 5/100\n",
      "5400/5400 [==============================] - 2s 422us/step - loss: 0.7167 - acc: 0.6357 - val_loss: 0.7133 - val_acc: 0.6260\n",
      "Epoch 6/100\n",
      "5400/5400 [==============================] - 2s 400us/step - loss: 0.7022 - acc: 0.6424 - val_loss: 0.7069 - val_acc: 0.6280\n",
      "Epoch 7/100\n",
      "5400/5400 [==============================] - 2s 346us/step - loss: 0.6923 - acc: 0.6398 - val_loss: 0.6995 - val_acc: 0.6340\n",
      "Epoch 8/100\n",
      "5400/5400 [==============================] - 1s 257us/step - loss: 0.6818 - acc: 0.6463 - val_loss: 0.6892 - val_acc: 0.6250\n",
      "Epoch 9/100\n",
      "5400/5400 [==============================] - 1s 268us/step - loss: 0.6765 - acc: 0.6454 - val_loss: 0.6828 - val_acc: 0.6350\n",
      "Epoch 10/100\n",
      "5400/5400 [==============================] - 2s 311us/step - loss: 0.6709 - acc: 0.6456 - val_loss: 0.6965 - val_acc: 0.6380\n",
      "Epoch 11/100\n",
      "5400/5400 [==============================] - 2s 357us/step - loss: 0.6663 - acc: 0.6517 - val_loss: 0.6865 - val_acc: 0.6360\n",
      "Epoch 12/100\n",
      "5400/5400 [==============================] - 2s 404us/step - loss: 0.6617 - acc: 0.6513 - val_loss: 0.6793 - val_acc: 0.6240\n",
      "Epoch 13/100\n",
      "5400/5400 [==============================] - 2s 359us/step - loss: 0.6577 - acc: 0.6572 - val_loss: 0.6734 - val_acc: 0.6430\n",
      "Epoch 14/100\n",
      "5400/5400 [==============================] - 2s 362us/step - loss: 0.6551 - acc: 0.6543 - val_loss: 0.6752 - val_acc: 0.6400\n",
      "Epoch 15/100\n",
      "5400/5400 [==============================] - 2s 365us/step - loss: 0.6523 - acc: 0.6550 - val_loss: 0.6797 - val_acc: 0.6260\n",
      "Epoch 16/100\n",
      "5400/5400 [==============================] - 2s 359us/step - loss: 0.6512 - acc: 0.6520 - val_loss: 0.6806 - val_acc: 0.6230\n",
      "Epoch 17/100\n",
      "5400/5400 [==============================] - 2s 406us/step - loss: 0.6489 - acc: 0.6589 - val_loss: 0.6995 - val_acc: 0.6300\n",
      "Epoch 18/100\n",
      "5400/5400 [==============================] - 2s 367us/step - loss: 0.6475 - acc: 0.6607 - val_loss: 0.6670 - val_acc: 0.6340\n",
      "Epoch 19/100\n",
      "5400/5400 [==============================] - 2s 367us/step - loss: 0.6453 - acc: 0.6561 - val_loss: 0.6680 - val_acc: 0.6310\n",
      "Epoch 20/100\n",
      "5400/5400 [==============================] - 2s 419us/step - loss: 0.6444 - acc: 0.6576 - val_loss: 0.6625 - val_acc: 0.6330\n",
      "Epoch 21/100\n",
      "5400/5400 [==============================] - 2s 402us/step - loss: 0.6419 - acc: 0.6543 - val_loss: 0.6850 - val_acc: 0.6220\n",
      "Epoch 22/100\n",
      "5400/5400 [==============================] - 2s 449us/step - loss: 0.6397 - acc: 0.6591 - val_loss: 0.6739 - val_acc: 0.6210\n",
      "Epoch 23/100\n",
      "5400/5400 [==============================] - 2s 453us/step - loss: 0.6408 - acc: 0.6622 - val_loss: 0.6658 - val_acc: 0.6320\n",
      "Epoch 24/100\n",
      "5400/5400 [==============================] - 2s 427us/step - loss: 0.6395 - acc: 0.6606 - val_loss: 0.6622 - val_acc: 0.6360\n",
      "Epoch 25/100\n",
      "5400/5400 [==============================] - 2s 449us/step - loss: 0.6362 - acc: 0.6633 - val_loss: 0.6628 - val_acc: 0.6330\n",
      "Epoch 26/100\n",
      "5400/5400 [==============================] - 3s 481us/step - loss: 0.6371 - acc: 0.6657 - val_loss: 0.6682 - val_acc: 0.6220\n",
      "Epoch 27/100\n",
      "5400/5400 [==============================] - 2s 462us/step - loss: 0.6360 - acc: 0.6641 - val_loss: 0.6632 - val_acc: 0.6330\n",
      "Epoch 28/100\n",
      "5400/5400 [==============================] - 2s 379us/step - loss: 0.6330 - acc: 0.6707 - val_loss: 0.6647 - val_acc: 0.6320\n",
      "Epoch 29/100\n",
      "5400/5400 [==============================] - 2s 351us/step - loss: 0.6340 - acc: 0.6639 - val_loss: 0.6714 - val_acc: 0.6280\n",
      "Epoch 30/100\n",
      "5400/5400 [==============================] - 2s 343us/step - loss: 0.6332 - acc: 0.6650 - val_loss: 0.6746 - val_acc: 0.6270\n",
      "Epoch 31/100\n",
      "5400/5400 [==============================] - 2s 357us/step - loss: 0.6326 - acc: 0.6644 - val_loss: 0.6629 - val_acc: 0.6230\n",
      "Epoch 32/100\n",
      "5400/5400 [==============================] - 2s 356us/step - loss: 0.6321 - acc: 0.6665 - val_loss: 0.6746 - val_acc: 0.6300\n",
      "Epoch 33/100\n",
      "5400/5400 [==============================] - 2s 346us/step - loss: 0.6307 - acc: 0.6663 - val_loss: 0.6654 - val_acc: 0.6330\n",
      "Epoch 34/100\n",
      "5400/5400 [==============================] - 2s 353us/step - loss: 0.6287 - acc: 0.6722 - val_loss: 0.6764 - val_acc: 0.6270\n",
      "Epoch 35/100\n",
      "5400/5400 [==============================] - 2s 360us/step - loss: 0.6296 - acc: 0.6644 - val_loss: 0.6713 - val_acc: 0.6400\n",
      "Epoch 36/100\n",
      "5400/5400 [==============================] - 2s 351us/step - loss: 0.6281 - acc: 0.6700 - val_loss: 0.6677 - val_acc: 0.6320\n",
      "Epoch 37/100\n",
      "5400/5400 [==============================] - 2s 361us/step - loss: 0.6268 - acc: 0.6620 - val_loss: 0.6625 - val_acc: 0.6390\n",
      "Epoch 38/100\n",
      "5400/5400 [==============================] - 2s 366us/step - loss: 0.6267 - acc: 0.6674 - val_loss: 0.6671 - val_acc: 0.6390\n",
      "Epoch 39/100\n",
      "5400/5400 [==============================] - 2s 406us/step - loss: 0.6258 - acc: 0.6669 - val_loss: 0.6673 - val_acc: 0.6500\n",
      "Epoch 40/100\n",
      "5400/5400 [==============================] - 2s 366us/step - loss: 0.6254 - acc: 0.6739 - val_loss: 0.6894 - val_acc: 0.6250\n",
      "Epoch 41/100\n",
      "5400/5400 [==============================] - 2s 387us/step - loss: 0.6244 - acc: 0.6717 - val_loss: 0.6712 - val_acc: 0.6310\n",
      "Epoch 42/100\n",
      "5400/5400 [==============================] - 2s 423us/step - loss: 0.6236 - acc: 0.6743 - val_loss: 0.6698 - val_acc: 0.6430\n",
      "Epoch 43/100\n",
      "5400/5400 [==============================] - 2s 380us/step - loss: 0.6234 - acc: 0.6717 - val_loss: 0.6823 - val_acc: 0.6340\n",
      "Epoch 44/100\n",
      "5400/5400 [==============================] - 2s 400us/step - loss: 0.6239 - acc: 0.6744 - val_loss: 0.6653 - val_acc: 0.6350\n",
      "Epoch 45/100\n",
      "5400/5400 [==============================] - 2s 369us/step - loss: 0.6203 - acc: 0.6741 - val_loss: 0.6657 - val_acc: 0.6250\n",
      "Epoch 46/100\n",
      "5400/5400 [==============================] - 2s 372us/step - loss: 0.6197 - acc: 0.6741 - val_loss: 0.6842 - val_acc: 0.6320\n",
      "Epoch 47/100\n",
      "5400/5400 [==============================] - 2s 360us/step - loss: 0.6208 - acc: 0.6750 - val_loss: 0.6806 - val_acc: 0.6340\n",
      "Epoch 48/100\n",
      "5400/5400 [==============================] - 2s 398us/step - loss: 0.6186 - acc: 0.6774 - val_loss: 0.6871 - val_acc: 0.6300\n",
      "Epoch 49/100\n",
      "5400/5400 [==============================] - 2s 391us/step - loss: 0.6190 - acc: 0.6759 - val_loss: 0.6669 - val_acc: 0.6490\n",
      "Epoch 50/100\n",
      "5400/5400 [==============================] - 2s 433us/step - loss: 0.6190 - acc: 0.6739 - val_loss: 0.6789 - val_acc: 0.6220\n",
      "Epoch 51/100\n",
      "5400/5400 [==============================] - 2s 405us/step - loss: 0.6162 - acc: 0.6759 - val_loss: 0.6764 - val_acc: 0.6320\n",
      "Epoch 52/100\n",
      "5400/5400 [==============================] - 2s 399us/step - loss: 0.6176 - acc: 0.6750 - val_loss: 0.6962 - val_acc: 0.6150\n",
      "Epoch 53/100\n",
      "5400/5400 [==============================] - 2s 392us/step - loss: 0.6162 - acc: 0.6759 - val_loss: 0.6686 - val_acc: 0.6470\n",
      "Epoch 54/100\n",
      "5400/5400 [==============================] - 2s 396us/step - loss: 0.6141 - acc: 0.6769 - val_loss: 0.6667 - val_acc: 0.6430\n",
      "Epoch 55/100\n",
      "5400/5400 [==============================] - 2s 378us/step - loss: 0.6155 - acc: 0.6770 - val_loss: 0.6687 - val_acc: 0.6320\n",
      "Epoch 56/100\n",
      "5400/5400 [==============================] - 2s 458us/step - loss: 0.6137 - acc: 0.6785 - val_loss: 0.6802 - val_acc: 0.6320\n",
      "Epoch 57/100\n",
      "5400/5400 [==============================] - 2s 411us/step - loss: 0.6144 - acc: 0.6796 - val_loss: 0.6842 - val_acc: 0.6350\n",
      "Epoch 58/100\n",
      "5400/5400 [==============================] - 2s 396us/step - loss: 0.6132 - acc: 0.6800 - val_loss: 0.6732 - val_acc: 0.6440\n",
      "Epoch 59/100\n",
      "5400/5400 [==============================] - 2s 346us/step - loss: 0.6126 - acc: 0.6778 - val_loss: 0.6762 - val_acc: 0.6320\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400/5400 [==============================] - 2s 332us/step - loss: 0.6129 - acc: 0.6781 - val_loss: 0.6718 - val_acc: 0.6290\n",
      "Epoch 61/100\n",
      "5400/5400 [==============================] - 2s 338us/step - loss: 0.6108 - acc: 0.6846 - val_loss: 0.6784 - val_acc: 0.6320\n",
      "Epoch 62/100\n",
      "5400/5400 [==============================] - 2s 333us/step - loss: 0.6101 - acc: 0.6837 - val_loss: 0.6717 - val_acc: 0.6370\n",
      "Epoch 63/100\n",
      "5400/5400 [==============================] - 2s 328us/step - loss: 0.6092 - acc: 0.6878 - val_loss: 0.6671 - val_acc: 0.6430\n",
      "Epoch 64/100\n",
      "5400/5400 [==============================] - 2s 331us/step - loss: 0.6083 - acc: 0.6850 - val_loss: 0.7103 - val_acc: 0.6180\n",
      "Epoch 65/100\n",
      "5400/5400 [==============================] - 2s 333us/step - loss: 0.6098 - acc: 0.6859 - val_loss: 0.6712 - val_acc: 0.6280\n",
      "Epoch 66/100\n",
      "5400/5400 [==============================] - 2s 340us/step - loss: 0.6101 - acc: 0.6831 - val_loss: 0.6721 - val_acc: 0.6290\n",
      "Epoch 67/100\n",
      "5400/5400 [==============================] - 2s 334us/step - loss: 0.6084 - acc: 0.6815 - val_loss: 0.6967 - val_acc: 0.6260\n",
      "Epoch 68/100\n",
      "5400/5400 [==============================] - 2s 369us/step - loss: 0.6051 - acc: 0.6846 - val_loss: 0.6927 - val_acc: 0.6040\n",
      "Epoch 69/100\n",
      "5400/5400 [==============================] - 2s 369us/step - loss: 0.6082 - acc: 0.6804 - val_loss: 0.6724 - val_acc: 0.6400\n",
      "Epoch 70/100\n",
      "5400/5400 [==============================] - 2s 357us/step - loss: 0.6043 - acc: 0.6904 - val_loss: 0.6736 - val_acc: 0.6390\n",
      "Epoch 71/100\n",
      "5400/5400 [==============================] - 2s 445us/step - loss: 0.6047 - acc: 0.6848 - val_loss: 0.6845 - val_acc: 0.6480\n",
      "Epoch 72/100\n",
      "5400/5400 [==============================] - 2s 449us/step - loss: 0.6032 - acc: 0.6889 - val_loss: 0.6857 - val_acc: 0.6190\n",
      "Epoch 73/100\n",
      "5400/5400 [==============================] - 2s 417us/step - loss: 0.6042 - acc: 0.6896 - val_loss: 0.6740 - val_acc: 0.6310\n",
      "Epoch 74/100\n",
      "5400/5400 [==============================] - 2s 407us/step - loss: 0.6026 - acc: 0.6917 - val_loss: 0.7071 - val_acc: 0.5580\n",
      "Epoch 75/100\n",
      "5400/5400 [==============================] - 2s 416us/step - loss: 0.6027 - acc: 0.6906 - val_loss: 0.6893 - val_acc: 0.6520\n",
      "Epoch 76/100\n",
      "5400/5400 [==============================] - 2s 447us/step - loss: 0.6042 - acc: 0.6883 - val_loss: 0.6938 - val_acc: 0.6260\n",
      "Epoch 77/100\n",
      "5400/5400 [==============================] - 2s 396us/step - loss: 0.6014 - acc: 0.6863 - val_loss: 0.6862 - val_acc: 0.6280\n",
      "Epoch 78/100\n",
      "5400/5400 [==============================] - 2s 404us/step - loss: 0.6014 - acc: 0.6957 - val_loss: 0.7004 - val_acc: 0.5910\n",
      "Epoch 79/100\n",
      "5400/5400 [==============================] - 2s 378us/step - loss: 0.6028 - acc: 0.6883 - val_loss: 0.7464 - val_acc: 0.5810\n",
      "Epoch 80/100\n",
      "5400/5400 [==============================] - 2s 369us/step - loss: 0.6013 - acc: 0.6954 - val_loss: 0.7075 - val_acc: 0.6360\n",
      "Epoch 81/100\n",
      "5400/5400 [==============================] - 2s 368us/step - loss: 0.6015 - acc: 0.6893 - val_loss: 0.6780 - val_acc: 0.6100\n",
      "Epoch 82/100\n",
      "5400/5400 [==============================] - 3s 517us/step - loss: 0.5996 - acc: 0.6950 - val_loss: 0.7148 - val_acc: 0.6280\n",
      "Epoch 83/100\n",
      "5400/5400 [==============================] - 2s 388us/step - loss: 0.5965 - acc: 0.6954 - val_loss: 0.6930 - val_acc: 0.6340\n",
      "Epoch 84/100\n",
      "5400/5400 [==============================] - 2s 444us/step - loss: 0.5968 - acc: 0.6976 - val_loss: 0.6853 - val_acc: 0.6360\n",
      "Epoch 85/100\n",
      "5400/5400 [==============================] - 2s 437us/step - loss: 0.5972 - acc: 0.6926 - val_loss: 0.7063 - val_acc: 0.6320\n",
      "Epoch 86/100\n",
      "5400/5400 [==============================] - 2s 402us/step - loss: 0.5970 - acc: 0.6920 - val_loss: 0.7035 - val_acc: 0.6240\n",
      "Epoch 87/100\n",
      "5400/5400 [==============================] - 2s 387us/step - loss: 0.5978 - acc: 0.6935 - val_loss: 0.6846 - val_acc: 0.6190\n",
      "Epoch 88/100\n",
      "5400/5400 [==============================] - 2s 387us/step - loss: 0.5981 - acc: 0.6935 - val_loss: 0.6810 - val_acc: 0.6060\n",
      "Epoch 89/100\n",
      "5400/5400 [==============================] - 3s 480us/step - loss: 0.5979 - acc: 0.6963 - val_loss: 0.6880 - val_acc: 0.6450\n",
      "Epoch 90/100\n",
      "5400/5400 [==============================] - 3s 643us/step - loss: 0.5940 - acc: 0.6980 - val_loss: 0.7020 - val_acc: 0.6170\n",
      "Epoch 91/100\n",
      "5400/5400 [==============================] - 3s 463us/step - loss: 0.5969 - acc: 0.6965 - val_loss: 0.7188 - val_acc: 0.5980\n",
      "Epoch 92/100\n",
      "5400/5400 [==============================] - 2s 412us/step - loss: 0.5956 - acc: 0.7007 - val_loss: 0.7308 - val_acc: 0.6260\n",
      "Epoch 93/100\n",
      "5400/5400 [==============================] - 3s 504us/step - loss: 0.5935 - acc: 0.6954 - val_loss: 0.7164 - val_acc: 0.6380\n",
      "Epoch 94/100\n",
      "5400/5400 [==============================] - 3s 528us/step - loss: 0.5922 - acc: 0.7019 - val_loss: 0.6935 - val_acc: 0.6090\n",
      "Epoch 95/100\n",
      "5400/5400 [==============================] - 3s 484us/step - loss: 0.5952 - acc: 0.7020 - val_loss: 0.7019 - val_acc: 0.6070\n",
      "Epoch 96/100\n",
      "5400/5400 [==============================] - 2s 434us/step - loss: 0.5915 - acc: 0.7059 - val_loss: 0.7161 - val_acc: 0.6200\n",
      "Epoch 97/100\n",
      "5400/5400 [==============================] - 3s 546us/step - loss: 0.5910 - acc: 0.6998 - val_loss: 0.7133 - val_acc: 0.5950\n",
      "Epoch 98/100\n",
      "5400/5400 [==============================] - 3s 548us/step - loss: 0.5928 - acc: 0.6961 - val_loss: 0.7062 - val_acc: 0.6260\n",
      "Epoch 99/100\n",
      "5400/5400 [==============================] - 3s 490us/step - loss: 0.5887 - acc: 0.7046 - val_loss: 0.7226 - val_acc: 0.5770\n",
      "Epoch 100/100\n",
      "5400/5400 [==============================] - 3s 543us/step - loss: 0.5908 - acc: 0.7059 - val_loss: 0.7407 - val_acc: 0.5700\n"
     ]
    }
   ],
   "source": [
    "classifier3.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history3 = classifier3.fit(partial_x_train, partial_y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['acc', 'val_loss', 'loss', 'val_acc'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict1 = history1.history\n",
    "history_dict2 = history2.history\n",
    "history_dict3 = history3.history\n",
    "\n",
    "history_dict1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAFNCAYAAABfUShSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzs3Xt8VNW9///XIkYwQQJFVBRJwKOVS0ICkdJqBUSpXMVbhcYWoYriDbX+Wo+IoC21Fy8Uv/5Oy7G1FCIeivVSga/1pCDaeloBARG1p0q4iNUYJIIJkJDP94+VhFxmkplMJtkT3s/HYx7J7Nl77TV79uz9mXV1ZoaIiIiIBFOHts6AiIiIiISnYE1EREQkwBSsiYiIiASYgjURERGRAFOwJiIiIhJgCtZEREREAkzBmogkHOdchnPOnHPHVT1f7ZybGsm6zdjXPc65J2LJb5h0r3XOvdbS6YpI+6NgTURanXPuJefcAyGWX+qc+1e0gZWZjTGzxS2QrxHOud310v6xmV0Xa9oiIs2lYE1E2sJvgW8751y95d8G8s2sovWzJCISTArWRKQtPAd8Cfh69QLnXDdgPPC7qufjnHNvOuc+d87tcs7NC5eYc26tc+66qv+TnHMPOec+dc59AIyrt+4059w7zrn9zrkPnHM3VC1PBVYDpznnDlQ9TnPOzXPOLa21/UTn3NvOuX1V++1X67VC59xdzrktzrkS59x/Oec6RXJAnHNfc869UbXdG865r9V67dqqvO53zm13zuVVLf8359wrVdt86pz7r0j2JSKJRcGaiLQ6MysDlgPfqbX4m8C7Zra56vkXVa93xQdcM51zkyJI/np80JcD5AJX1nv9k6rXuwDTgEedc4PN7AtgDLDHzDpXPfbU3tA5dzawDLgd6AGsAv7onDu+3vu4BOgDZAHXNpVh59yXgJXAQqA78Aiw0jnXvSqIXAiMMbMTga8Bm6o2/SHwJ6Ab0At4rKl9iUjiUbAmIm1lMXCVc+6EquffqVoGgJmtNbO3zKzSzLbgg6ThEaT7TWCBme0ys73Ag7VfNLOVZva+ea/gg52vh0oohKuBlWb2spmVAw8BJ+ADqGoLzWxP1b7/CGRHkO444H/NbImZVZjZMuBdYELV65XAQOfcCWb2kZm9XbW8HEgHTjOzg2amDgsi7ZCCNRFpE1WBRRFwqXOuL3Au8FT16865rzjn1jjnipxzJcCNwEkRJH0asKvW8x21X3TOjXHO/Y9zbq9zbh8wNsJ0q9OuSc/MKqv2dXqtdf5V6/9SoHO06dbK9+lVJX5X49//R865lc65c6rW+T7ggL9XVc1Oj/B9iEgCUbAmIm3pd/gStW8DfzKzj2u99hTwAnCGmaUBv8QHJk35CDij1vPe1f845zoCz+BLxE4xs674qszqdK2JtPfgS7Kq03NV+/owgnxFnG6V3tXpmtlLZnYx0BNf4vafVcv/ZWbXm9lpwA3A/++c+7cY8yIiAaNgTUTa0u+Ai/DtzOoPvXEisNfMDjrnhgLfijDN5cBtzrleVZ0W7q712vFAR3yJXoVzbgwwutbrHwPdnXNpjaQ9zjk3yjmXDHwPOAT8NcK8hbMKONs59y3n3HHOuauB/sCLzrlTqjo1pFbt6wBwBMA5d5VzrldVGp/hg80jMeZFRAJGwZqItBkzK8QHOqn4UrTabgIecM7tB+7DB0qR+E/gJWAzsBH4Q6397Qduq0rrM3wA+EKt19/Ft437oKq352n18vsecA2+If+n+DZlE8zscIR5C8nMivGdHr4HFOOrN8eb2af46/T38KVve/Ht9m6q2vRc4G/OuQNV72OWmW2PJS8iEjzOrKlSfxERERFpKypZExEREQkwBWsiIiIiAaZgTURERCTAFKyJiIiIBJiCNREREZEAO66tM9BSTjrpJMvIyGjrbIiIiIg0acOGDZ+aWY9I1m03wVpGRgbr169v62yIiIiINMk5V3+KubBUDSoiIiISYArWRERERAJMwZqIiIhIgLWbNmsiIiKxKC8vZ/fu3Rw8eLCtsyLtSKdOnejVqxfJycnNTkPBmoiICLB7925OPPFEMjIycM61dXakHTAziouL2b17N3369Gl2OqoGFRERAQ4ePEj37t0VqEmLcc7RvXv3mEtrFayJiIhUUaAmLa0lzikFaxHKfyufjAUZdLi/AxkLMsh/K7+tsyQiIu3IiBEjeOmll+osW7BgATfddFOj23Xu3BmAPXv2cOWVV4ZNu6mxSBcsWEBpaWnN87Fjx7Jv375Ist6oefPm8dBDD8WcTijOOb797W/XPK+oqKBHjx6MHz8+qnQyMjL49NNPm7XO7NmzOeOMM2o+h3hQsBaB/LfymfHHGewo2YFh7CjZwYw/zlDAJiIiLWbKlCk8/fTTdZY9/fTTTJkyJaLtTzvtNFasWNHs/dcP1latWkXXrl2bnV5rSE1NZevWrZSVlQHw8ssvc/rpp7dqHiZMmMDf//73uO5DwVoEZhfMprS8tM6y0vJSZhfMbqMciYhIW8vPh4wM6NDB/82P8ff7lVdeyYsvvsihQ4cAKCwsZM+ePZx//vkcOHCAUaNGMXjwYDIzM3n++ecbbF9YWMjAgQMBKCsrY/LkyWRlZXH11VfXBDMAM2fOJDc3lwEDBjB37lwAFi5cyJ49exg5ciQjR44E6pYkPfLIIwwcOJCBAweyYMGCmv3169eP66+/ngEDBjB69Og6+wll06ZNDBs2jKysLC677DI+++yzmv3379+frKwsJk+eDMArr7xCdnY22dnZ5OTksH///pBpjhkzhpUrVwKwbNmyOsHt3r17mTRpEllZWQwbNowtW7YAUFxczOjRo8nJyeGGG27AzGq2Wbp0KUOHDiU7O5sbbriBI0eONPqehg0bRs+ePRtdJ2Zm1i4eQ4YMsXhx85wxjwYPN8/FbZ8iItK6tm3bFvG6S5eapaSYwdFHSopfHouxY8fac889Z2ZmDz74oN11111mZlZeXm4lJSVmZlZUVGRnnnmmVVZWmplZamqqmZlt377dBgwYYGZmDz/8sE2bNs3MzDZv3mxJSUn2xhtvmJlZcXGxmZlVVFTY8OHDbfPmzWZmlp6ebkVFRTV5qX6+fv16GzhwoB04cMD2799v/fv3t40bN9r27dstKSnJ3nzzTTMzu+qqq2zJkiUN3tPcuXPt5z//uZmZZWZm2tq1a83MbM6cOTZr1iwzM+vZs6cdPHjQzMw+++wzMzMbP368vfbaa2Zmtn//fisvL2+Qdmpqqm3evNmuuOIKKysrs0GDBtmaNWts3LhxZmZ2yy232Lx588zMrKCgwAYNGmRmZrfeeqvdf//9Zmb24osvGmBFRUW2bds2Gz9+vB0+fNjMzGbOnGmLFy8OeXxC5SWcUOcWsN4ijHFUshaB3mm9o1ouIiLt2+zZUFq3woXSUr88FrWrQmtXgZoZ99xzD1lZWVx00UV8+OGHfPzxx2HTWbduHddccw0AWVlZZGVl1by2fPlyBg8eTE5ODm+//Tbbtm1rNE+vvfYal112GampqXTu3JnLL7+cV199FYA+ffqQnZ0NwJAhQygsLAybTklJCfv27WP48OEATJ06lXXr1tXkMS8vj6VLl3LccX5UsfPOO48777yThQsXsm/fvprl9WVlZVFYWMiyZcsYO3Zsg7xXt2m78MILKS4upqSkpM7xGTduHN26dQOgoKCADRs2cO6555KdnU1BQQEffPBBo8enNShYi8D8UfNJSU6psywlOYX5o+a3UY5ERKQt7dwZ3fJITZo0iYKCAjZu3EhZWRmDBw8GID8/n6KiIjZs2MCmTZs45ZRTmhwOIlQvxO3bt/PQQw9RUFDAli1bGDduXJPpWK0qwvo6duxY839SUhIVFRWNphXOypUrufnmm9mwYQNDhgyhoqKCu+++myeeeIKysjKGDRvGu+++G3b7iRMnctdddzVo3xcq79XHJdTxMTOmTp3Kpk2b2LRpE++99x7z5s1r1ntqSQrWIpCXmceiCYtIT0vH4UhPS2fRhEXkZea1ddZERKQN9A5TsRJueaQ6d+7MiBEjmD59ep3Ao6SkhJNPPpnk5GTWrFnDjh07Gk3nggsuIL+qEd3WrVtr2mp9/vnnpKamkpaWxscff8zq1atrtjnxxBNDtgu74IILeO655ygtLeWLL77g2Wef5etf/3rU7y0tLY1u3brVlMotWbKE4cOHU1lZya5duxg5ciQ/+9nP2LdvHwcOHOD9998nMzOTH/zgB+Tm5jYarE2fPp377ruPzMzMsMdh7dq1nHTSSXTp0qXO8tWrV9e0nRs1ahQrVqzgk08+AXybt6aOdWvQDAYRysvMU3AmIiIAzJ8PM2bUrQpNSfHLYzVlyhQuv/zyOj1D8/LymDBhArm5uWRnZ3POOec0msbMmTOZNm0aWVlZZGdnM3ToUAAGDRpETk4OAwYMoG/fvpx33nk128yYMYMxY8bQs2dP1qxZU7N88ODBXHvttTVpXHfddeTk5DRa5RnO4sWLufHGGyktLaVv3748+eSTHDlyhGuuuYaSkhLMjDvuuIOuXbsyZ84c1qxZQ1JSEv3792fMmDFh0+3VqxezZs1qsHzevHk1xyElJYXFixcDMHfuXKZMmcLgwYMZPnw4vaui7P79+/OjH/2I0aNHU1lZSXJyMo8//jjp6elh9/3973+fp556itLSUnr16sV1113X4qVxrrHizUSSm5trTY0hIyIiEs4777xDv379Il4/P9+3Udu505eozZ8PefpNLyGEOreccxvMLDeS7VWyJiIi0gx5eQrOpHWozZqIiIhIgClYExEREQkwBWsiIiIiAaZgTURERCTAFKyJiIiIBJiCNRERkQAYMWIEL730Up1lCxYs4Kabbmp0u86dOwOwZ88errzyyrBpNzW81YIFCyitNXDc2LFj2bdvXyRZb9S8efN46KGHYk4nFOdczXRSABUVFfTo0YPx48dHlU7tSeujWae0tJRx48ZxzjnnMGDAAO6+++6o9hspBWsiIiIBUHte0Gq15wdtymmnncaKFSuavf/6wdqqVavo2rVrs9NrDampqWzdupWysjIAXn75ZU4//fRWzcNdd93Fu+++y5tvvslf/vKXOrNCtBQFayIiIgFw5ZVX8uKLL3Lo0CEACgsL2bNnD+effz4HDhxg1KhRDB48mMzMTJ5//vkG2xcWFjJw4EAAysrKmDx5MllZWVx99dU1wQz42Q1yc3MZMGAAc+fOBWDhwoXs2bOHkSNHMnLkSKBuSdIjjzzCwIEDGThwIAsWLKjZX79+/bj++usZMGAAo0ePrrOfUDZt2sSwYcPIysrisssuq5nmaeHChfTv35+srCwmT54MwCuvvEJ2djbZ2dnk5OSEnAoLYMyYMaxcuRKAZcuW1Qlu9+7dy6RJk8jKymLYsGE1024VFxczevRocnJyuOGGG+rMIbp06VKGDh1KdnY2N9xwA0eOHAn7flJSUmqO1/HHH8/gwYPZvXt3o8egWcysXTyGDBliIiIizbVt27a2zoKNHTvWnnvuOTMze/DBB+2uu+4yM7Py8nIrKSkxM7OioiI788wzrbKy0szMUlNTzcxs+/btNmDAADMze/jhh23atGlmZrZ582ZLSkqyN954w8zMiouLzcysoqLChg8fbps3bzYzs/T0dCsqKqrJS/Xz9evX28CBA+3AgQO2f/9+69+/v23cuNG2b99uSUlJ9uabb5qZ2VVXXWVLlixp8J7mzp1rP//5z83MLDMz09auXWtmZnPmzLFZs2aZmVnPnj3t4MGDZmb22WefmZnZ+PHj7bXXXjMzs/3791t5eXmDtFNTU23z5s12xRVXWFlZmQ0aNMjWrFlj48aNMzOzW265xebNm2dmZgUFBTZo0CAzM7v11lvt/vvvNzOzF1980QArKiqybdu22fjx4+3w4cNmZjZz5kxbvHhxyONT32effWZ9+vSx999/v8Froc4tYL1FGONoBgMREZF6br8dNm1q2TSzs6GqUCqs6qrQSy+9lKeffprf/OY3gC9Yueeee1i3bh0dOnTgww8/5OOPP+bUU08Nmc66deu47bbbAMjKyiIrK6vmteXLl7No0SIqKir46KOP2LZtW53X63vttde47LLLSE1NBeDyyy/n1VdfZeLEifTp04fs7GwAhgwZ0uh8oSUlJezbt4/hw4cDMHXqVK666qqaPObl5TFp0iQmTZoEwHnnncedd95JXl4el19+Ob169QqZblZWFoWFhSxbtoyxY8c2yPszzzwDwIUXXkhxcTElJSWsW7eOP/zhDwCMGzeObt26AVBQUMCGDRs499xzAV9CefLJJ4d9T9UqKiqYMmUKt912G3379m1y/WipGlRERCQgJk2aREFBARs3bqSsrIzBgwcDkJ+fT1FRERs2bGDTpk2ccsopHDx4sNG0nHMNlm3fvp2HHnqIgoICtmzZwrhx45pMxxqZQ7xjx441/yclJVFRUdFoWuGsXLmSm2++mQ0bNjBkyBAqKiq4++67eeKJJygrK2PYsGG8++67YbefOHEid911V4P2faHyXn1cQh0fM2Pq1Kls2rSJTZs28d5770U0KfuMGTM466yzuP3225tctzlUsiYiIlJPUyVg8dK5c2dGjBjB9OnT6wQeJSUlnHzyySQnJ7NmzRp27NjRaDoXXHAB+fn5jBw5kq1bt9a01fr8889JTU0lLS2Njz/+mNWrVzNixAgATjzxRPbv389JJ53UIK1rr72Wu+++GzPj2WefZcmSJVG/t7S0NLp168arr77K17/+dZYsWcLw4cOprKxk165djBw5kvPPP5+nnnqKAwcOUFxcTGZmJpmZmbz++uu8++67nHPOOSHTnj59OmlpaWRmZrJ27doGx2HOnDmsXbuWk046iS5dutQsv/fee1m9enVN27lRo0Zx6aWXcscdd3DyySezd+9e9u/fT3p6etj3de+991JSUsITTzwR9TGJlII1ERGRAJkyZQqXX355nZ6heXl5TJgwgdzcXLKzs8MGLdVmzpzJtGnTyMrKIjs7m6FDhwIwaNAgcnJyGDBgAH379uW8886r2WbGjBmMGTOGnj17smbNmprlgwcP5tprr61J47rrriMnJ6fRKs9wFi9ezI033khpaSl9+/blySef5MiRI1xzzTWUlJRgZtxxxx107dqVOXPmsGbNGpKSkujfvz9jxowJm26vXr2YNWtWg+Xz5s2rOQ4pKSksXrwYgLlz5zJlyhQGDx7M8OHD6d27NwD9+/fnRz/6EaNHj6ayspLk5GQef/zxsMHa7t27mT9/Puecc05NKegtt9zCddddF/WxaYxrrHgzkeTm5lpTY8iIiIiE884779CvX7+2zoa0Q6HOLefcBjPLjWT7uLZZc85d4px7zzn3T+dcg5HinHO9nXNrnHNvOue2OOfGVi3PcM6VOec2VT1+Gc98ioiIiARV3KpBnXNJwOPAxcBu4A3n3Atmtq3WavcCy83sP5xz/YFVQEbVa++bWXa88iciIiKSCOJZsjYU+KeZfWBmh4GngUvrrWNAl6r/04A9ccyPiIiISMKJZ7B2OrCr1vPdVctqmwdc45zbjS9Vu7XWa32qqkdfcc59PY75FBEREQmseAZrDQcw8SVptU0BfmtmvYCxwBLnXAfgI6C3meUAdwJPOee61NsW59wM59x659z6oqKiFs6+iIiISNuLZ7C2Gzij1vNeNKzm/C6wHMDMXgc6ASeZ2SEzK65avgF4Hzi7/g7MbJGZ5ZpZbo8ePeLwFkRERETaVjyDtTeAs5xzfZxzxwOTgRfqrbMTGAXgnOuHD9aKnHM9qjoo4JzrC5wFfBDHvIqIiLSpESNG8NJLL9VZtmDBAm666aZGt+vcuTMAe/bs4corrwybdlPDWy1YsIDS0tKa52PHjmXfvn2RZL1R8+bN46GHHoo5nVCcc3z729+ueV5RUUGPHj0YP358VOnUnrQ+2nUuueQSBg0axIABA7jxxhsbnfi9ueIWrJlZBXAL8BLwDr7X59vOuQeccxOrVvsecL1zbjOwDLi2anLTC4AtVctXADea2d545VVERKStVc8LWtvTTz/dYAqlcE477TRWrFjR7P3XD9ZWrVpF165dm51ea0hNTWXr1q2UlZUB8PLLL3P66fWbx8fX8uXL2bx5M1u3bqWoqIjf//73Lb6PuI6zZmarzOxsMzvTzOZXLbvPzF6o+n+bmZ1nZoPMLNvM/lS1/BkzG1C1fLCZ/TGe+RQREYlW/lv5ZCzIoMP9HchYkEH+W/kxpXfllVfy4osvcujQIQAKCwvZs2cP559/PgcOHGDUqFEMHjyYzMxMnn/++QbbFxYWMnDgQMBPQD558mSysrK4+uqra4IZ8LMb5ObmMmDAAObOnQvAwoUL2bNnDyNHjmTkyJFA3ZKkRx55hIEDBzJw4EAWVM3FVVhYSL9+/bj++usZMGAAo0ePrrOfUDZt2sSwYcPIysrisssuq5nmaeHChfTv35+srCwmT54MwCuvvEJ2djbZ2dnk5OSwf//+kGmOGTOGlStXArBs2bI6we3evXuZNGkSWVlZDBs2rGbareLiYkaPHk1OTg433HBDnTlEly5dytChQ8nOzuaGG25osqSsSxffpL6iooLDhw+HnHM0ZmbWLh5DhgwxERGR5tq2bVvE6y7dstRS5qcY86h5pMxPsaVblsaUh7Fjx9pzzz1nZmYPPvig3XXXXWZmVl5ebiUlJWZmVlRUZGeeeaZVVlaamVlqaqqZmW3fvt0GDBhgZmYPP/ywTZs2zczMNm/ebElJSfbGG2+YmVlxcbGZmVVUVNjw4cNt8+bNZmaWnp5uRUVFNXmpfr5+/XobOHCgHThwwPbv32/9+/e3jRs32vbt2y0pKcnefPNNMzO76qqrbMmSJQ3e09y5c+3nP/+5mZllZmba2rVrzcxszpw5NmvWLDMz69mzpx08eNDMzD777DMzMxs/fry99tprZma2f/9+Ky8vb5B2amqqbd682a644gorKyuzQYMG2Zo1a2zcuHFmZnbLLbfYvHnzzMysoKDABg0aZGZmt956q91///1mZvbiiy8aYEVFRbZt2zYbP368HT582MzMZs6caYsXLw55fGobPXq0de3a1aZMmWIVFRUNXg91bgHrLcIYJ64layIiIu3R7ILZlJaX1llWWl7K7ILZMaVbuyq0dhWomXHPPfeQlZXFRRddxIcffsjHH38cNp1169ZxzTXXAJCVlUVWVlbNa8uXL2fw4MHk5OTw9ttvs23btnDJAPDaa69x2WWXkZqaSufOnbn88st59dVXAejTpw/Z2X78+iFDhjQ6X2hJSQn79u1j+PDhAEydOpV169bV5DEvL4+lS5dy3HF+vP7zzjuPO++8k4ULF7Jv376a5fVlZWVRWFjIsmXLGDt2bIO8V7dpu/DCCykuLqakpKTO8Rk3bhzdunUDoKCggA0bNnDuueeSnZ1NQUEBH3zQdJP5l156iY8++ohDhw7x5z//ucn1o6VgTUREJEo7S3ZGtTxSkyZNoqCggI0bN1JWVlYzOXh+fj5FRUVs2LCBTZs2ccopp3Dw4MFG0wpVHbd9+3YeeughCgoK2LJlC+PGjWsyHWtkDvGOHTvW/J+UlERFRUWjaYWzcuVKbr75ZjZs2MCQIUOoqKjg7rvv5oknnqCsrIxhw4bx7rvvht1+4sSJ3HXXXQ3a94XKe/VxCXV8zIypU6eyadMmNm3axHvvvce8efMieg+dOnVi4sSJIauoY6VgTUREJEq903pHtTxSnTt3ZsSIEUyfPr1O4FFSUsLJJ59McnIya9asYceOHY2mc8EFF5Cf79vQbd26taat1ueff05qaippaWl8/PHHrF69umabE088MWS7sAsuuIDnnnuO0tJSvvjiC5599lm+/vXox6pPS0ujW7duNaVyS5YsYfjw4VRWVrJr1y5GjhzJz372M/bt28eBAwd4//33yczM5Ac/+AG5ubmNBmvTp0/nvvvuIzMzM+xxWLt2LSeddBJdunSps3z16tU1bedGjRrFihUr+OSTTwDf5q2xY33gwAE++ugjwLdZW7VqFeecc07Ux6YpcZsbVEREpL2aP2o+M/44o05VaEpyCvNHzY857SlTpnD55ZfX6Rmal5fHhAkTyM3NJTs7u8mAYObMmUybNo2srCyys7MZOnQoAIMGDSInJ4cBAwbQt29fzjvvvJptZsyYwZgxY+jZsydr1qypWT548GCuvfbamjSuu+46cnJyGq3yDGfx4sXceOONlJaW0rdvX5588kmOHDnCNddcQ0lJCWbGHXfcQdeuXZkzZw5r1qwhKSmJ/v37M2bMmLDp9urVi1mzZjVYPm/evJrjkJKSwuLFiwGYO3cuU6ZMYfDgwQwfPpzevX2Q3b9/f370ox8xevRoKisrSU5O5vHHHyc9PT3kfr/44gsmTpzIoUOHOHLkCBdeeCE33nhj1MelKa6x4s1Ekpuba02NISMiIhLOO++8Q79+/SJeP/+tfGYXzGZnyU56p/Vm/qj55GXmxTGHkqhCnVvOuQ1mlhvJ9ipZExERaYa8zDwFZ9Iq1GZNREREJMAUrImIiIgEmII1ERGRKu2lHbcER0ucUwrWRERE8ONkFRcXK2CTFmNmFBcX06lTp5jSUQcDERER/PAPu3fvpqioqK2zIu1Ip06d6NWrV0xpKFgTEREBkpOT6dOnT1tnQ6QBVYOKiIiIBJiCNREREZEAU7AmIiIiEmAK1kREREQCTMGaiIiISIApWBMREREJMAVrIiIiIgGmYE1EREQkwBSsiYiIiASYgjURERGRAFOwJiIiIhJgCtZEREREAkzBmoiIiEiAKVgTERERCTAFayIiIiIBpmBNREREJMAUrImIiIgEmII1ERERkQBTsCYiIiISYArWRERERAJMwZqIiIhIgClYExEREQkwBWsiIiIiAaZgTURERCTAFKyJiIiIBJiCNREREZEAU7AmIiIiEmAK1kREREQCTMGaiIiISIApWBMREREJMAVrIiIiIgGmYE1EREQkwOIarDnnLnHOveec+6dz7u4Qr/d2zq1xzr3pnNvinBtb67V/r9ruPefcN+KZTxEREZGgOi6ZNyLHAAAgAElEQVReCTvnkoDHgYuB3cAbzrkXzGxbrdXuBZab2X845/oDq4CMqv8nAwOA04D/ds6dbWZH4pVfERERkSCKZ8naUOCfZvaBmR0GngYurbeOAV2q/k8D9lT9fynwtJkdMrPtwD+r0hMRERE5psQzWDsd2FXr+e6qZbXNA65xzu3Gl6rdGsW2OOdmOOfWO+fWFxUVtVS+RURERAIjnsGaC7HM6j2fAvzWzHoBY4ElzrkOEW6LmS0ys1wzy+3Ro0fMGRYREREJmri1WcOXhp1R63kvjlZzVvsucAmAmb3unOsEnBThtiIiIiLtXjxL1t4AznLO9XHOHY/vMPBCvXV2AqMAnHP9gE5AUdV6k51zHZ1zfYCzgL/HMa8iIiIigRS3YM3MKoBbgJeAd/C9Pt92zj3gnJtYtdr3gOudc5uBZcC15r0NLAe2Af8XuDmIPUHz38onY0EGHe7vQMaCDPLfym/rLImIiEg748waNAVLSLm5ubZ+/fpW21/+W/nM+OMMSstLa5alJKewaMIi8jLzWi0fIiIikniccxvMLDeSdTWDQTPNLphdJ1ADKC0vZXbB7DbKkYiIiLRHCtaaaWfJzqiWi4iIiDSHgrVm6p3WO6rlIiIiIs2hYK2Z5o+aT0pySp1lKckpzB81v41yJCIiIu1Rk8Gac+5nzrkuzrlk51yBc+5T59w1rZG5IMvLzGPRhEWkp6XjcKSnpatzgYiIiLS4JnuDOuc2mVm2c+4yYBJwB7DGzAa1RgYj1dq9QUVERESaq6V7gyZX/R0LLDOzvc3OmYiIiIhEJZLppv7onHsXKANucs71AA7GN1siIiIiAhGUrJnZ3cBXgVwzKwe+AC6Nd8ZEREREJLIOBlcBFWZ2xDl3L7AUOC3uORMRERGRiNqszTGz/c6584FvAIuB/4hvtkREREQEIgvWqidQHwf8h5k9DxwfvyyJiIiISLVIgrUPnXO/Ar4JrHLOdYxwOxERERGJUSRB1zeBl4BLzGwf8CXg/4trrkREREQEiKw3aCnwPvAN59wtwMlm9qe450xEREREIuoNOgvIB06ueix1zt0a74yJiIiISGSD4n4X+IqZfQHgnPsp8DrwWDwzJiIiIiKRtVlzHO0RStX/Lj7ZEREREZHaIilZexL4m3Pu2arnk4DfxC9LIiIiIlKtyWDNzB5xzq0FzseXqE0zszfjnTERERERiaxkDTPbCGysfu6c22lmveOWKxEREREBmj+4rdqsiYiIiLSC5gZr1qK5EBEREZGQwlaDOufuDPcS0Dk+2RERERGR2hprs3ZiI6/9oqUzIiIiIiINhQ3WzOz+1syIiIiIiDTU3DZrIiIiItIKFKyJiIiIBJiCNREREZEAa3JQXOdcR+AKIKP2+mb2QPyyJSIiIiIQ2QwGzwMlwAbgUHyzIyIiIiK1RRKs9TKzS+KeExERERFpIJI2a391zmXGPSciIiIi0kAkJWvnA9c657bjq0EdYGaWFdeciYiIiEhEwdqYuOdCREREREJqshrUzHYAXYEJVY+uVctEREREJM6aDNacc7OAfODkqsdS59yt8c6YiIiIiERWDfpd4Ctm9gWAc+6nwOvAY/HMmIiIiIhE1hvUAUdqPT9StUxERERE4iySkrUngb85556tej4J+HX8siQiIiIi1SLpYPAIMA3YC3wGTDOzBfHOWHuS/1Y+GQsy6HB/BzIWZJD/Vn5bZ0lEREQSRNiSNedcFzP73Dn3JaCw6lH92pfMbG/8s5f48t/KZ8YfZ1BaXgrAjpIdzPjjDADyMvPaMmsiIiKSABorWXuq6u8GYH2tR/VzicDsgtk1gVq10vJSZhfMbqMciYiISCIJW7JmZuOr/vZpvewkvvy38pldMJudJTvpndabHSWhh6TbWbKzlXMmIiIiiSiScdYKIlkWZttLnHPvOef+6Zy7O8TrjzrnNlU9/uGc21frtSO1Xnshkv21teoqzx0lOzCMHSU7cGE6zvZO693KuRMREZFE1FibtU5ACnCSc64bR4fr6AKc1lTCzrkk4HHgYmA38IZz7gUz21a9jpndUWv9W4GcWkmUmVl2FO+lzYWq8jQMh8OwmmUpySnMHzW/tbMnIiIiCaixkrUb8O3Tzqn6W/14Hh+ENWUo8E8z+8DMDgNPA5c2sv4UYFkkmQ6qcFWbhpGelo7DkZ6WzqIJi9S5QERERCLSWJu1XwC/cM7dambNma3gdGBXree7ga+EWtE5lw70Af5ca3En59x6oAL4iZk914w8tKpwbdTS09IpvL2w9TMkIiIiCa/JQXHN7DHn3ECgP9Cp1vLfNbFpqMZaFmIZwGRghZnVnimht5ntcc71Bf7snHvLzN6vswPnZgAzAHr3bvs2YPNHza8zTAeoylNERERiE0kHg7n4eUAfA0YCPwMmRpD2buCMWs97AXvCrDuZelWgZran6u8HwFrqtmerXmeRmeWaWW6PHj0iyFJ85WXmsWjCIlV5iogIoEHRpWU4s3CFXVUrOPcWMAh408wGOedOAZ4wswlNbHcc8A9gFPAh8AbwLTN7u956XwZeAvpYVWaqOjSUmtkh59xJ+InjL63dOaG+3NxcW79ew7+JiEgw1B8UHXxti37EC4BzboOZ5UaybiQTuZeZWSVQ4ZzrAnwC9G1qIzOrAG7BB2LvAMvN7G3n3APOudolc1OAp61u1NgPWO+c2wyswbdZCxuoiYiIBI0GRZeWEslE7uudc12B/8T3Bj0A/D2SxM1sFbCq3rL76j2fF2K7vwKZkexDREQkiMKNEKBB0SVakXQwuKnq31865/4v0MXMtsQ3WyIiIokt3AgBGhRdohW2GtQ5N7j+A/gScFzV/yIiIhLG/FHzSUlOqbNMIwRIczRWsvZw1d9OQC6wGT8cRxbwN+D8+GZNREQkcVV3Iqg9X/T8UfPVuSDA6s/vHZTPK5LeoE8D883srarnA4G7zOza+GcvcuoNKiIiIs3V2r13W7o36DnVgRqAmW0FEmrOThEREZHGBLn3biS9Qd9xzj0BLMXPQHANfigOERERkXYhyL13IylZmwa8DcwCbge2VS0TERERaRfC9dINQu/dJoM1MztoZo+a2WVVj0fN7GBrZE5ERESkNQS5927YalDn3HIz+2bVdFMNeiGYWVZccyYiIiLSSoLcezdsb1DnXE8z+8g5lx7qdTNrONJfG1JvUBEREUkU0fQGDVuyZmYfVf0NVFAmIiIicixprBp0PyGqP/ED45qZdYlbrkREREQEaKSDgZmdaGZdQjxOVKAmIiIi0ch/K5+MBRl0uL8DGQsyyH8rv62zlDAiGWcNAOfcyfippwAws7YfeKQVVVbC3/8OXbpA//5tnRsREZHEUX92gB0lO5jxxxkAgWjAH3RNDt3hnJvonPtfYDvwClAIrI5zvgKnshK+8Q147LG2zomIiEhiCfLsAIkgkkFxfwgMA/5hZn2AUcBf4pqrADruODj/fFi7tq1zIiIikliCPDtAIogkWCs3s2Kgg3Oug5mt4RidG3TECHj3XfjXv9o6JyIiIokjyLMDJIJIgrV9zrnOwDog3zn3C6AivtkKphEj/N9169o0GyIiIgklyLMDJIJIgrVLgTLgDuD/Au8DE+KZqaDKyYETT1RVqIiISDTyMvNYNGER6WnpOBzpaeksmrBInQsi1NgMBv8HeMrM/tq6WWqe1prBYOxYKCyEbdvivisRERFpp6KZwaCxkrX/BR52zhU6537qnDsm26nVN2IEvPMOfPJJW+dEREREjgWNDYr7CzP7KjAc2As86Zx7xzl3n3Pu7FbLYcBUt1t75ZU2zYaIiIjEIJEG6W2yzZqZ7TCzn5pZDvAt4DLgnbjnLKAGD4bOndVuTUREJFFVD9K7o2QHhtUM0hvUgC2SQXGTnXMTnHP5+MFw/wFcEfecBVT1eGsqWRMREUlMiTZIb9hgzTl3sXPuN8BuYAawCjjTzK42s+daK4NBNGIEvP222q2JiIgkokQbpLexkrV7gNeBfmY2wczyzeyLVspXoGm8NRERkfCC3h4s0QbpbayDwUgz+08z29uaGUoEgwdDaqrarYmIiNSXCO3BEm2Q3kgGxZV6kpPVbk1ERCSURGgPlmiD9CpYa6YRI2DrVigqauuciIiIBEc07cFirS6NZfu8zDwKby+kcm4lhbcXBjZQAwVrzTZ8uP+rdmsiIiJHRdoeLNbq0kSobm0pCtYilJ8PGRnQoYP/+49/QEqKqkJFRCR+gt5QP5RI24PFWl2aCNWtLUXBWgTy82HGDNixA8z835tugjPPbH4ng0T8AoqISOtJ1JKjSNuDxTp8Rrj1dpTsaHf317ATuSeaeE7knpHhA7T6unaFfft8u7WTToo8veovYO1fBCnJKYFu3CgiIq0rY0EGO0oa3nzS09IpvL2w9TPUwmJ9f+G2dziMo7FNUO+vLTWRu1TZGSbI37fP/4223dqxVHQrIiLNk2gDt0Yr1uEzQm1fP1CD9nF/VbAWgd5hxsjr3du3W1uzJrr02vsXUETaLzXhaD2JNnBrtGIdPiPU9vUDtWqJfn9VNWgEqtusldYqDEtJgUWLYMUKeO012LULOnWKLL32XrQtIu2TmnC0Lh3v6CXS/VXVoC0sL88HZunp4Jz/u2iRX37bbfDppz6gi1SijZwsIgJqwtHaEm3g1iBor/dXlazFyAxycuDIEdiyxQdzkch/K5/ZBbPZWbKT3mm9mT9qvr6AIhJoHe7vELKayeGonFvZBjlKXLoHxE+iHNtoStYUrLWA3/4Wpk2Dl1+Giy5qfjqJcoKJyLEpkaqYItFW11xVbwqoGrTVTZkCJ58MCxY0P41EHU9HRI4d7amKqS2vua1VnazOIEcl+rFQsBaD6lkNTjgBDh2ClSvhvfeal5bagohI0LWnNlRtec1tjREBVABwVHs4FqoGbaZQPUTBV4O+/HL06aktiIhI62nLa25rVCe3tyrrWAT1WKgatBXMnt0wUAMoKIC9e6NPr72PpyMiEiRtec1tjerkY2kqpqa0h7FNFaw1U7hZDczgiSeiT689tQUREQm6trzmtkZ1crig0+FavDqwNdqDxbKP9lAYomrQZgo3X2inTn6e0A8+gOTk6NJUb1ARkdbTnq+5oXqchpqKCWKrDmyNnq2x7iOovW8DM3SHc+4S4BdAEvCEmf2k3uuPAiOrnqYAJ5tZ16rXpgL3Vr32IzNb3Ni+gtBmLSUFZs6Ehx+Gp5+Gq69uteyIiEgbC1rwVz8/odptQWzt9BKl/V3QPhsISLDmnEsC/gFcDOwG3gCmmNm2MOvfCuSY2XTn3JeA9UAuYMAGYIiZfRZuf20xzlp+vm+7tnOnnyd0/nw/jMc550DHjvDGG5FPQdXofgJ4kjVXe3ovIiLVglp6U1s8AqvW6KjRXjvgBaWDwVDgn2b2gZkdBp4GLm1k/SnAsqr/vwG8bGZ7qwK0l4FL4pjXZsnLg8JCqKz0f/PyoEMHePRR2LoVZs2KfR/toctxtfb0XkREakuE4Zfi0U6vNdqDtYc2Z7GKZ7B2OrCr1vPdVcsacM6lA32AP0ezrXNuhnNuvXNufVFRUYtkOlb5+XDzzf7/RYvgxhtjSy8RLgCRak/vRUSktkTocRiPjg2t0VFDHfDiG6yFmiUzXJ3rZGCFmR2JZlszW2RmuWaW26NHj2Zms+VUt2Or3fHgV7+Cn/wk/DZNifUCEKRRmxPhYiYSqSB9txJFez5miVL6k5eZR+HthVTOraTw9sKYq2hbo2drexqMubmOi2Pau4Ezaj3vBewJs+5k4OZ6246ot+3aFsxbXIQbe23OHF/aduKJ0acZrlFoJBeA+m0oqqsdgTY5yWN5LyJBErTvViJo78ds/qj5IdusHQulP3mZeXH/DFtjH0EWz5K1N4CznHN9nHPH4wOyF+qv5Jz7MtANeL3W4peA0c65bs65bsDoqmWBFm7stYoKuO46PwZbtGIp/g1ataOKsqW9CNp3KxG092Om0h+Jp7gFa2ZWAdyCD7LeAZab2dvOuQeccxNrrToFeNpqdUs1s73AD/EB3xvAA1XLAq13mAKirl1h+XJ47LHo04zlAhC0akddzKS9CNp3KxEk8jGLtPq2pasYj1Xtubq8uTQobgsKN/bar34Fv/89rF4NGzZAZmbr5Ceo86GJJDp9t6IX7ph1P6E7nY/vHNjhfII4JEd7HgIpiMc7XoIydMcxJy/P9wBNTwfn/N9Fi+Caa+DXv4Zu3WDqVCgvb538qNpRJD703YpeqGOW3CGZ/Yf3B3o4n6BV37b3IZCCdryDQsFaCws19lp+PuTmwiefwJtvwuTJrZQXVTuKxIW+W9ELdcy6dOzC4SOH66wXtBtz0Kpv23swE7TjHRSqBo2zUFWjAD/8Idx7b+htRESOBYkwMn3QqrwT4ZjFImjHO55UDRog4YbzeOABOHSo+emqAaYEic5HaY4gjk1W/1wee9bYQFV5B/GYtSQ1MQhNwVqchRvOo7wc7r+/eWm29zYLklh0PkpzBe3GHOpcXrx5MVMHTQ1MlXdbH7N4/zBTE4PQVA0aZxkZdWc0qJaaCmVl8PrrMHRolGkeQ8XEEnyJcj625x50iSxIn4vO5ab3e6z01GwN0VSDKliLs3DDeSxY4NutpaTA//yPH4stUrG2WQjSxVESXyK0odFNRiIRzbl8LF5HEyWYTRRqsxYg4YbzSEmBw4fhvffg1FP90B6RiqXNgqqspKUlQhua9t6DTupqblVdpOdyEK+jrdFuVD01246CtVZQfzgP8KVtH3/s/z90yD//7W8jS689TUEVKzVsb3tt2YYm0s8/kW8yOsfDC3VsYgmkIj2Xg3YdjTV4jPQcS4QfZu2VqkHbQLh2bCecAJ9/Dscd13QazS2CT4Qqq0ipais42qJKKJrPP1Grb3SOhxfu2Jxw3AkUlxU3WD/SzzqSczlo19FYzu9ozjGdjy1LbdYCrkOH8JO6f+c78OSTfp1oRXKRSdSbVijt6b0cy5ob6EXz+SfqTUbneHjhjk04LRlIBe1ziSV4jPa9HItt9eJFbdYCLtyE72lp8LvfwW23+SrTaERaDN7W3b5bUiJXbYkXS/VNNJ9/og4HoHM8vGiPQUtW1QXtOhpL9WS055gmq28bCtbawPz5voNBbSkpMGUKdOkCjz/uh/b4P/8n8jQjbUPRmjeteLe1UfuJxBdL25/GPv9Q514i3mR0jocX7hh0P6F73AOpoAX/sQSP0X6PpG2oGrSN5Of72Q127vQlbWPHwuLFDWc7mDXLD/PRlLZuQ1G/aHzsWWNZvHlxXKudErVqS46K5bwN9/lPHTQ17udevLTF9yhRNfb9B465qrrmVk+2x+9RolCbtQQUrtMBwHe/6wO2zp0b2T7GNhSxtEMI9WV3uJA34ZZu06H2E4ktHuft7ILZbfZdiEVjN81V/7tK53gI+v63jHh8j6RpCtYSUGOdDpyDpCSoqPClcD/+sR8OpLZYSpliLaGKpqFvIvY6lfiJR+loPErrWqM0obUarSvACa4gfTZtXVtzLFAHgwQUrtNB9+5w/PE+UANfbTptmh9Yt7ZY2lDEOmZQNA191dZGaotH259Y2nm15fhZrdGZIIiDuYoXtM9G7SWDRcFaQITrdAB+0Nzaysvhxhvh9tth9+6jy5vbgDrWm0S4L6/D1XmeqL1OE0WiNgZu6Yb/sTS2DnfO7yjZEfdjG+vNMZLPP2iDucpRQftsgtbj9VinYC0gwk1LtXdv6PXNfK/Rs86Cu++Gzz5r/r6juUmEuiGE+1LfmHtjYHpLtXdB+1XelmIprWvsh0e8j20sN8dIP38NBRJcQftsgtbj9VinNmsBF67jQffu0KkTfPihf56aCnPnwi23+JkQohFpO51E6X0VpHYf4USTx2NtsOO21JadZar3H88Bgo/l8yTo14Vj+bM5VqmDQTuSn+/nDa09pEdysi99O3z46LIOHfxAur16He2AEM0sCKEuZFA3ADtw+EBM07i0hkQYziMe07uoMXDLqf9dCNd5pi2PbXPzmAjfj3Bausd60N53IuRRWpaCtXam/phsBw5AccOYiS5d4OBBH8R17Oi3mTOnmfsMceEIJ0gBQSL8Oo0mjyoxaXtBO7axlv61VglTrMFVS443F7TPMJygl/5Jy1Kw1s41NsxHfSNGwH/9F5x8MuzfD//zP/CXv/jHaafBI4/4KtX6ohmOI0gXvCCWMMVSUhPp+wniGF3t5cYTtBKPcN/N+gFbNJ9/rJ9VSwZX8aiKDuJ1QVpGYSFcdBEMHeo73n39677mKRFo6I52LtwwH6GsXQunnupP3i5dYPRo+OEP4ZNP4OmnYdAgeOWVhttF2qg1aL2DgtbdPFTD7/q9ZKuFymOk7ydUY+DqEcjbotNBe+rwELSG1uG+m4Y16/OP9bMKtf0v1/+y2T0bQ/WKDBVoQew91jUMReKbPx927YJVq2D4cMjM9FM1lpS0dc5aloK1BBRqmI/G1C6F69gRfvlL2LwZXn/dp3Phhb5zQvVYbkVFkFIR5iL2RXfYlw7mOL1z8HoHBa27ebgbT6TDmkTzfuoPgbHqf1e12VAA4YYhmLV6loYXiVG4AKO6lCnazz/WISNaOriKx7iNQbsuSMvYvh1++1u44QbYswd+/Wt/T7v1Vl9ztGpVW+ew5ShYS0ChhvkIVZUZyqFD8O//7nuZ5ub6Nm7nnQcPPOCns3LOl8SVvjCf46zexe24FGbn/oLZqYWk/LySvs8X8s1zghOoQfxKQZo7hlmkpSDh8hjL+2nLoQDC7aO4rLhdlLaFE8150txzKtLAI9LPP9bzpKWDq3iM2xi00lFpGT/+sZ/d5wc/8EHa9Onw97/D+vW+s92//3vkTYaCTm3W2olQvUYjlZzse5IeOXJ0WadOMO2RfFYdCt2OJT8frrkGvvc9eOih8Gl//jmceGL0bQiC1N4pljZLbdmwOdy+u5/Qnc7Hd26x9knRDCUSSpDaPMYiHr18G9tXSw3nEus5Gk0bulimv9McqVLb9u1w9tkwcyYsXNjw9d/+1s/286c/wcUXt3r2IqIOBseoSHuNRio93TfeDOeWW/zAvL//PVx5Zd3XqgftvfNOX3L3y1/Cl78cJt8t3POrpcVyM2vLxumh9p3cIRnnHIePHB33pbGAItRwLs0dky+cIHX+iCUAiCY4bo1JsmMdPzGazgnTn53BYWu54CpIP9YkmK6/HpYsgfffh9NPb/j6oUPQp49vw/bSS62fv0goWBMgttK2aunpR4O/+fPrTiB/6JBv0LltG7zxxtFg7Isv/H6fesr3zNmyBcrKfCD5gx/4dnM1eWzFQUibewOItSdZPG48kaZZf71Ix8oLdwM/4bgTIh5rr7n7jvU9R6qlA+lw50l9KckpYYPYlg5cm3ueRPOD6dAh6DU2n+JBs7EuOzm5Y28eGa/gSuKnqVK1aj/5ia8K3bTJd6YLGgVrUiOW0jbn6tb3p6T4tnK1A7Zdu2DwYD80yN/+5ht5Xn45vPOO73V6992+5+kdd/jep1/+MvzqVz7Ig+iqy2K5kbVWVWZrlAjE8l4iDTyj+VxCbR9rvlujtLWlq6ijOWZJLokjdqTB8mj2fd11vtRg1qxochmZaI7NL37h5yl+/nm4+WbfHnbdusQZPkGC5/Bh3/Zszx6YONE3y6mtqVK1ap99Bmec4e9Jv/tdfPPcHBq6Q2rk5fmqzMpK//cXv2jYkzQ5GY4/vu6y+oEa+BK6WbP8xbhDh6MX5aef9sHZSSf5YOydd+D734d77vHrnXoqLFsGq1f7L+GIEf7iXl4en55focTS4y3SBt2tNVxFLO8l0iEMou2EEMlnE2kj75YeCiKclu6AEeo8CeeIHYmpd+LGjb7n2w9+EHo6ulhFemxKSvyPsosuggkTfH5ee81fF2L14Yfwhz+0nwbiEp6ZD85+8hP4xjegWzdfK3P11b4E7Te/OTpaQXUP0BkzGg/UwKdz3XX+/rN7d9zfRlwpWDvGhOpJ+uST/stQe1m4C2Rxsb85mPm/M2bAM8/Accf56hDwgeHChb5Ur7ZLLoGtW+G223zQePHFcHrnlu/5FUo0N+b6vfSAkEEGUGe9WatnxRxQRNJDMJYgI9LAM1zw1f2E7jEFGZEMgRGPcbZCaemxt0IFo91PCN1Nu/ocam7vxMce8/MBd+jgS69bWqTH5qc/9deEn/3MXzu++13/4+yHP4xt/6Wl/npxxRW+h1/tqfWaq7LSD1H0H/8Be/fGnt6//uV/lH7zm77phzTfzJnwla/4KssPP/Tn0R/+4H/g9+zpnw8cCCtW+OY41T1AI3H77UfvSYlM1aASUrgJ5ENJSqrbk7Ra9+5+OJBQbd6WLvVF2Slfyaf0ohkcPNJ042Q4Olfp6Sf25rvp80n/PI/33vO9Ti+4AEaNgh49QryfCBt/R1rdFo8G9JFWE8ZafRfJPLCNHYf667Z0VW+kbb/Av+f3by2kuNhXxUejNTp/xGMfRUW+amf6dH+uP/CAn5Hka19rkSwDkeV792446yzfuWjJkqPbPvww3HUX/PWv8NWvNm//06f70pNvfcv/6LvgAn/zjnSIolAef9x3igJfkzBhAnznOzBmjK9diNSuXT44feIJH0Sa+Wq25cujm485Unv2+I5a27b50qXy8qN/+/f3tR1jxoTe94EDfgabDz6ASZP8cE2hqqdLSvx6q1f7a3lS0tFHx46+vdcFF0BOjv9hHomiIl/627evD2jDefZZf/xuugnuuw9OOaXu62a+in32bH8MwI+jFk3wNXmyf2+7dvnB4YNCbdYkZi3ROaG+lBSYOtUPVLhzp/9SlpdDSe980q6Yzd6K8Df/37yRz8zVdXuccTgF/riI5Hfz6NTJT6cF/oJy8cX+cd55cMIJkfeMjLRzQzyGpog0CGvpACBoQyVEOhRER5fCVz5ZxDvL8yWb6EoAABnrSURBVNi71w/yfO650e0rf0s+s16Yzd4j8W1j2JLB7YMP+iYGb7/tS8HPPtuPKfX66y0bLDSV7+nT/XXivff8j7tqX3zh8/WVr8DKldHv98knfdr33utL6JYt80MwnHEGvPhi+F7ljdmxw5fMfPWrvjTwd7/zeS8q8s037r3Xl/g31s5u506fn8WLfQAxdaov1XzhBT+E0Zw5PnBuSc8846/DZWV+9pnjj/fB0nHH+UDq5Zd9SdSXv+xLkL7zHX+9e/11Hyj913/5z6O6WcvZZ/sA+Fvf8kHUf/+3fz/PPuvH3OzTB9LSfMBW/Sgt9UEO+B/fX/uar6L86ld98JeWVjfP774Ljz7qj/HBg37fK1b4gKy+PXt8u8uMDJ/n+s1xajtyxP/If+45Xzp66qmRH8f16/214eGHfeAbFArWpEVE2jkhXMlaKPXbwp1wgv+ivvMOnH++v+iceebRx86d/oKz/LQMLK3hDfy0lHR23FGIc7Bhg794vfyy/1VfXu5/FX7ta75NTXm/fH5TOJtdn/uSuQOHDrDvcGS9LeqXjkXT8y/SICqaXqetMeREkCYqrw4en9u2io++2In7vDf23/NJ25nH2LFQUOBvRNE2bF+0yI9+npLib1r1h6AJmooKf5M9+2x/owWf72uv9TeyvPjH0gC89ZYvbbnzztDjLP74x/7asWGD74AUTbpf+QoMG+a/x0lJfvlf/+pLhsrLfSne2Wf7Uq1Dh/zfjh39j7RQn72Zr1L9y198M4zqwLK83A/p8Nhjfiyua6/1QwzV7q1e7ZlnfFXcwYO+DdT3v3902j8zv+w3v/GB5eTJkb/fcD7/3AePixf7gGjp0tBBanm5D4QeecQHJF/6ki9hfvddX00+ebLPd79+/j3k5/spCM2ga1fYt8+365oyxb//cCVvH30Er77qv1/r1vnPqdqXv+wDoZwc+POffYDesaMPHG+4wZeCbdzoz9fzzz+6XWWlb5/2l7/Am282LwiPxsiRvkPC++/XLUn94gv/I+eEE+K7/1CiCdYws3bxGDJkiEl8LV1qlpJi5r/q/pGSYjZzZsPl0Ty+9CWztDT/f4cODV/v0MGMuc6YR4OHm+dC5nX/frOVK83uvNNs0KCjaXXqVGsfYdIM9Uh/NL1O+umPpodcr/tPu1v6o+nm5jlLfzTdlm5ZGvHxDZdm/X1HY9cus9GjzSZMMDt8OPQ6bl50x7Y1LN2ytMFx/PRTs4wMf77cfLPZn/5kduiQX/9Xv/Kf6YoVke9j/Xqz4483u/BCs69+1W9/331mR47E5z3V98EHZt/+ttm6dZFv88wzPp/PPXd02ZEjZkOGmPXqZfbFF83LS2Wl33b//qbXPXLE7JJLzLp2NSsuDr1OSYl//bLLIs/D55+bffnLZqeeavbRRw1f377dbMCA8NeR6dNDn+NPPulff+yx8O9n3jy/zle/WnffZWX+XAOzoUP9ZxbKwYNm55/vry9/+1vD10tK/OdcVtbUUTBbu9af5x06mM2ZE/57W1tlpdmrr5pdeaXZiBFmv/51+M9y926zhx7y597vf+/zHq3iYrOXXjL70Y/MLr3UrGdPf4x69PDH8uOPj6776af+c+3a1eztt48uf+QRv80vfxn9/pvjxRf9/i6+2GzkSJ+nLl2Onj/dupkNHGj2jW+YTZtm9rOfxT9PwHqLMMZRyZpEpX5pW3U7tJYckLe6TUR17x8Ad0fokrVIS38++QTWrPHDi6Sm+qqPHx7IoLgi8pHXR3wpj127/K/Z1R/m88j/zuBQZcu1RWrp6s3nnvO/qktLfYlAdceO+oJWshbKkSMwbpz/DF99FYYOrft6RYX/ZV9a6tu1hCodqW3vXhgyxKe7caOfZePGG307qcsu81U4nTvH7e3w8ce+iv799/3zGTN89VzXro1vN3Kk7w33/vtHS53AH5MLLoD77/ftfhpj5ttb/epXfmiDkhL/qKjwaV5+uR9qp357s4oK3/P7wQf9MW6qSmnuXF8tWFAA//Zv/6+9uw+Soj7zAP59XJaXFTlcNAoCg5xUlIi8uBJRY1nEpDZKNJZ4ysGJFp4JXEXhfDmQpCKWm0AkSDyIisKJtagxiPgSEV/O8s7jUBEREThABQQXWFGC4AvrznN/PD3OMNs92z09M93sfD9VXTvT09vz6+7p6Wee30tbNiM1HX304W2fVK1q7vHHbfkLLnBf5/79wDPP2OP27e04t29v2aIZM6zpw+LF6XZJDQ3Wruv004FXX81dTbx4sWWDunWzqs3Ona2t1Zo1Vs3529/mrqZrbLTP5ddf27iTHTvaepYssczdoUN2fMeMsfNy0KD0/+7ebeNSLlxo923u29eyafm2+YvC7t22fW7n3tatti2VlVbduXevZeNqa+17qhTDvCST9n5btth9Q7t3T/9NJq06OTV9/LHNL3ZIwcwaRc4tCyeSf/YNA+oVt1Udnv2ZWqU/nFSviYStO5Gw962v1xbzXMu4tl6r6rLWeVuV9vrFeO0507I63X+f0JHT6vXMMz3KNDGh+I3oUf+a0KHj6vWBB1S3bQux37IySvevqNelS1UnT1a95x7V115TPXAg9zq++MKynYBlXDZtUp040Z4/9JC//VBVVxUoK1hsv/61lf/++72XWb7clvnDH3Kvq7lZ9eKLVSsrVVeuTM9PJlXvvtsyGgMGqG7enHs9yaRl8mbNSmf4/Ni3T3XQIDs/XnpJ9aab7D1PPNEyHcmk+/+tXWvbN2OG++sjR9o6d+zwfu+DB1WvvtrWU1OjOnq06oQJqlOmqE6frjppUjrL/f3vqz76qH3e7r9ftW9fm3/66aqPPOJdzpS9e1WPOcb7nO7cWbVXL9UzzrCsFaBaV+dvH7qZP1+1XTs7dtu3W/kuu0y1QwfVjRv9rWP1aitTp05Wvupq1Wee8V+Gd9+1/zv+eNWKCtumRML262OPqY4aZeUBVIcMUf3d71RHjEgvW1NjGUA/Gc4jzerV9nkYMMAypCeeqLpnT9Sl8tba57sQECCzFnmQVaiJwVr8ZAdNYatLM4MjTEwoBtS3CAArK61qK3NeVVXugC0VHPW+O6FX31WvHTrYF8kpp6TXMWyYXSSfe84usK++qrpiheqbb9oF7dprVU86Kb18r16qP/iB6pgxqrfdZqn+ZctUN2ywYMrN/v32Zf/EExZcDRqUDnAzq4dFVE87zS60kyfbRfa+++xi8MQT6aqiW25JBxFNTVbd16GD6htv5N4PQatvW9PcbEFCY6MFshs2WMDi19NP67fVXK19gdbWWrDR2Oi9zJ132vrmzHF/fflyq7Jp31715ptVP/205TIbN1p1SuqYDByoumZN69vyxReq559vQcWyZen5q1apDh5s6/rpT1W3bGn5v9dfb9Vsn3zivu7337cyDxtmAUZT0+Gvb9pkF0oR1WnTvKt7P//c9k2/flaeVCBx1llW/Rqkmnj1atWHH1Z98EHVe++1HxwzZ9r7T5yoOnas6iWX2Llyww3hq6BfeMECgh497D0AOz+C2LXLqsmGD7egL6jnnrPgc8oUO67Zn9m9e20/pJpn9Oiheuuth1cRtlUvvmiffeDwz3+5YrBGsZUdwHXrFiJ4CzClMmx+snB1delfv9XV3m1dsiWT9oU7a5YFaeefb21PUl9OmdMJJ1jmYsQI+4VdXX346x072sXijjusLcpXX6nu3GmBy+232wWuVy8LTt3WvXx5y/I1Nto29uxpF6Rie+qpdDYmexJR7d9f9brrLCOyfr37hXrzZgu+hgzxDnIzrVtnge0vf+n++ksv2eujRuUO/D76SPWaa6yc1dWqs2db4HvwoOrUqbbfu3Sxi+6SJbbP27WzY+PVxqipyY6biGWm3F6fOdN+XLRrp/rzn1s5VC1grKpSHTcu9/bPn29lAezHw69+ZW29li618lZX+79INjdb0Dd+vAVBpcg0FMLatfYZT2WWs4PWuEgmLRj85puoS1Jay5apLlgQdSniIUiwxjZrFCm3IUIqK60NQ+ZAmG53VAiqqqr193Gblz3kiNt9UnNpbra2M9u2WduNzGnPHhuFu08fG+6gTx/rPj9wYOvtrgDbJ19+ab26UlP//t5tn95+29pK1dRY76xUG5yvv7byffyxDYFy4ED671dfWfudY46xqUsX63U2cKD7+FS7dln7uL/8xbrlX3aZtVGqqrIeVx07WrurFSuAlSut3RRg6x48OD0NGGA91HbutF6FmcND5DJ+vLXJWrcu3cNs40b7rM2da13+33jDX5u0NWtszLBUu6umJttPY8YAd92VHj5g717b5kcesbZIs2fbGGgi6Wn6dGsTN2eO3ZbJS0ODfb7mzbM2VhMm2L6rq7Pjl9nWyU1Tkw1x8cADwPPP2zxVO+aLF9vnrK3budPay02aBJx6atSlIXLHNmt0RPGT8XKrQg3SBi5VlZPvlP1eqV6wfjJ1fueVyqJF+m3V7rnnWjVMPvukSxfVK65QXbjQ2p4kk5bZ6drVMpN1da33ZGtutmrRBQus7dSwYYcfZxH3LGEuu3dbVVhtrWXEamr026rkH//YqgODSCatamvwYJteecV72SefTGe23Kbbb/f/vh9+aNm9VBX4eecFK7eqVTtPm2YZWj89EYmodMDMGrVF2T1OL7rIek+1li3LzqgVSna2z2+mzquM8+aVZpysRYtsJPd9+yx7N3So3fnh5JNtcNUuXdKZtM6dbZmDBy3T9vnn1iOvocHGqPrrX+2xiB2TbdusV+K8efmPm9TcDGzaZFmkY4+10dmDmj7dbl0D2DhfY8bYmFPdu+dXpiA+/dTGm2puTn8+VK0H8oUXBu/5tnGjjdY+dqyNQUZEbQMHxaWy4TaUCNBy3tSpxbnhdSElEumytrY9foM6PwFumEAxmbSg6tlnrVrz8sttgNBi3HYniEOHbPDUYcOsWpiIKG5iE6yJSC2APwKoAPCgqk53WeYfANwOQAG8o6r/6MxvBpAaJ3m7ql6S670YrFEuftvGFau9nF9+2tV5taEDWg/MvLYlkbA2dEREVBqxCNZEpALAJgA/ArADwJsARqnq+oxl+gF4HMBwVf1MRL6jqnuc1w6oqu9hKRmsUWv8ZuGy5wUJesIIc9uusEGmiGXJMnkNgExEROEFCdaKWVkxFMAWVf1AVQ8BeAzApVnL/DOAuar6GQCkAjWiYhg92rJHyaT9HT3a37w//cmqCRMJC2oSCRvtvqrq8PVXVrYc4dzvvKoq/4Ea0DIIa2o6PFBzWyaX6mrrbXnUUfZ3wgTLRG7bZuvZts2eL1pkU+ayQeYRUXg8t8qQ354IQScAI2FVn6nn/wRgTtYySwH8HsD/AFgJoDbjtW8ArHLm/6y192NvUCq1MD0/3eYlEuF6rObbs9VtIGGvnrbdurXslev2/16DE0fZg7bQPXCj7NFL5cvrHs38/B15EIdBcQFc4RKs/XvWMs8CeBJAJYCTYdWlXZ3Xejh/+wLYCuDvXd7jeiegW9W7d+8i7U6i0nD7Eg4SSOU75EipBib2GyiGDf5S+7K1oV+CXODCrC9IUFfoHwDlKsy+iPt+9PpRl0hEXbL8xH1/F1NcgrVhAJZnPJ8CYErWMvcBuCbj+csAznJZ10MARuZ6P2bWqC3Id8y5oMFMplD3bI148gpG/Y7J161bYcf4y15frqAu3+MaJJjNNxiNOpMZpjxhMk9HQtbK67MnEnXJgjsS9ncxxSVYawfgAydj1h7AOwC+l7VMLYCFzuPjAHwEoBuAYwF0yJi/GUD/XO/HYI3KSSEvrl6/1N0CoVJm4fKdwgyAHDaT2do+zAzqwgzy7HfKNxgNfI9dn5lHPz8e/GaYvcoTJvPk9b9+9qPffRM2EAlSRr+iym61tSxhULEI1qwcuAjWI/R9AFOdeXcAuMR5LABmAVgPG6bjKmf+Oc7zd5y/41p7LwZrRPnx+nXr1b4s3+zPkZzBaytT2OPido/dIJnHQlfLuwUoubantYArzH5025YgmVW/AWCQYDbf4DhsGXN91/jZ32GzhEdK1WpsgrVSTgzWiPJXinZVha7m87ooe2XWCh0slmvwWeiMYCH3Y67sb5iONfluS9iOOn475fjd5iDBcaHLGLZ5QpDvsnyzuqXGYI2IYqmQDehzVbX5+bIOksEJc9ELUp1cyA4YxZjC3mO3FFPYKua4BeFun5/sQCPq7QsTCPv53yCdicIErqXuqMNgjYjKgtcXa5yqk/xWJxd6aJMwwajXfghzAQ8TJAQJRkXyr95MTfnux1JN2W268tnGOE1hgq2gn8tc6wzbUScoBmtERD4Uu01O0OrkQgobjLqVzyso8JO1KHQvXa+Lulvj9CDBTPb/+92PQdrphQ0As9t0uZUxTHBcys5E2fs7SLlLlektVocHBmtERFSUYDRMeyC/VdmFHmYjbA/TsNXyfjKrQQJAt+Ch0G3EwpbRbfJTpVuMLGEh2iIWA4M1IiIqikJnBKPMZEa5LWECQL/lDLu+QnYcCtOcIGhnIj/jHQbtBV0MDNaIiIjagDgFx0HWWcggPGhnIj/Z0UKMLxhWkGBNbPkjX01Nja5atSrqYhAREVGBLVoETJ0KbN8O9O4N1NUBo0d7z893nUD+6wtKRN5S1RpfyzJYIyIiIiqtIMHaUcUuDBERERHlj8EaERERUYwxWCMiIiKKMQZrRERERDHGYI2IiIgoxhisEREREcUYgzUiIiKiGGOwRkRERBRjbWZQXBFpBLCtwKs9DsAnBV4nhcfjEl88NvHE4xJfPDbxVIrjklDV4/0s2GaCtWIQkVV+Rxem0uFxiS8em3jicYkvHpt4ittxYTUoERERUYwxWCMiIiKKMQZruc2LugDkisclvnhs4onHJb54bOIpVseFbdaIiIiIYoyZNSIiIqIYY7DmQkRqReT/RGSLiEyOujzlTER6icgrIrJBRN4TkRud+dUi8qKIbHb+Hht1WcuRiFSIyNsi8qzz/GQRed05Ln8WkfZRl7EciUhXEVksIhudc2cYz5noicgk53tsnYg8KiIdec5EQ0QWiMgeEVmXMc/1HBFzjxMTrBWRIaUuL4O1LCJSAWAugJ8A6A9glIj0j7ZUZe0bADep6mkAzgbwL87xmAzgZVXtB+Bl5zmV3o0ANmQ8nwHgbue4fAZgXCSloj8CeF5VTwUwEHaMeM5ESEROAnADgBpVPR1ABYCrwHMmKg8BqM2a53WO/ARAP2e6HsC9JSrjtxistTQUwBZV/UBVDwF4DMClEZepbKlqg6qudh5/DrvonAQ7JgudxRYC+Fk0JSxfItITwMUAHnSeC4DhABY7i/C4REBEugA4H8B8AFDVQ6q6Dzxn4qAdgE4i0g5AFYAG8JyJhKr+F4BPs2Z7nSOXAnhYzUoAXUWke2lKahistXQSgI8ynu9w5lHERKQPgMEAXgdwgqo2ABbQAfhOdCUrW7MB3Aog6TzvBmCfqn7jPOe5E42+ABoB/IdTRf2giBwNnjORUtWdAGYC2A4L0v4G4C3wnIkTr3Mk8riAwVpL4jKPXWYjJiKdATwBYKKq7o+6POVOREYA2KOqb2XOdlmU507ptQMwBMC9qjoYwEGwyjNyTvunSwGcDKAHgKNh1WvZeM7ET+TfbQzWWtoBoFfG854APo6oLARARCphgdoiVV3izN6dSkM7f/dEVb4ydS6AS0RkK6ypwHBYpq2rU8UD8NyJyg4AO1T1def5YljwxnMmWhcC+FBVG1W1CcASAOeA50yceJ0jkccFDNZaehNAP6eHTntYA9CnIy5T2XLaQc0HsEFVZ2W89DSAsc7jsQCeKnXZypmqTlHVnqraB3aO/KeqjgbwCoCRzmI8LhFQ1V0APhKR7zqzfghgPXjORG07gLNFpMr5XksdF54z8eF1jjwN4GqnV+jZAP6Wqi4tFQ6K60JELoJlCSoALFDVuoiLVLZE5DwA/w3gXaTbRt0Ga7f2OIDesC/BK1Q1u7EolYCIXADgZlUdISJ9YZm2agBvAxijql9HWb5yJCKDYB0/2gP4AMC1sB/nPGciJCLTAFwJ6+X+NoDrYG2feM6UmIg8CuACAMcB2A3gNwCWwuUccYLrObDeo18AuFZVV5W0vAzWiIiIiOKL1aBEREREMcZgjYiIiCjGGKwRERERxRiDNSIiIqIYY7BGREREFGMM1oioTRORZhFZkzEVbDR/EekjIusKtT4iIjftWl+EiOiI9qWqDoq6EERE+WJmjYjKkohsFZEZIvKGM53izE+IyMsistb529uZf4KIPCki7zjTOc6qKkTkARF5T0ReEJFOzvI3iMh6Zz2PRbSZRNQGMFgjorauU1Y16JUZr+1X1aGw0clnO/PmAHhYVc8AsAjAPc78ewC8qqoDYffafM+Z3w/AXFX9HoB9AC535k8GMNhZzy+KtXFE1PbxDgZE1KaJyAFV7ewyfyuA4ar6gYhUAtilqt1E5BMA3VW1yZnfoKrHiUgjgJ6ZtwISkT4AXlTVfs7zfwNQqap3isjzAA7AbmGzVFUPFHlTiaiNYmaNiMqZejz2WsZN5n0cm5FuC3wxgLkAzgTwloiwjTAR5YXBGhGVsysz/v6v83gFgKucx6MBvOY8fhnAeAAQkQoR6eK1UhE5CkAvVX0FwK0AugJokd0jIvKDv/SIqK3rJCJrMp4/r6qp4Ts6iMjrsB+uo5x5NwBYICK3AGgEcK0z/0YA80RkHCyDNh5Ag8d7VgCoF5G/AyAA7lbVfQXbIiIqK2yzRkRlyWmzVqOqn0RdFiKiXFgNSkRERBRjzKwRERERxRgza0REREQxxmCNiIiIKMYYrBERERHFGIM1IiIiohhjsEZEREQUYwzWiIiIiGLs/wGn/V3K0DfquQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "history_dict1 = history1.history\n",
    "val_loss_values_1 = history_dict1['val_loss']\n",
    "val_loss_values_2 = history_dict2['val_loss']\n",
    "val_loss_values_3 = history_dict3['val_loss']\n",
    "\n",
    "epochs = range(1, len(history_dict1['acc']) + 1 )\n",
    "\n",
    "plt.plot(epochs, val_loss_values_1, 'bo', label='Validation loss Model 1')\n",
    "plt.plot(epochs, val_loss_values_2, 'b', label='Validation loss Model 2')\n",
    "plt.plot(epochs, val_loss_values_3, 'go', label='Validation loss Model 3')\n",
    "plt.title('Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "6400/6400 [==============================] - 1s 173us/step - loss: 0.6886 - acc: 0.5692\n",
      "Epoch 2/25\n",
      "6400/6400 [==============================] - 0s 58us/step - loss: 0.6611 - acc: 0.6075\n",
      "Epoch 3/25\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.6469 - acc: 0.6164\n",
      "Epoch 4/25\n",
      "6400/6400 [==============================] - 0s 45us/step - loss: 0.6416 - acc: 0.6255\n",
      "Epoch 5/25\n",
      "6400/6400 [==============================] - 0s 41us/step - loss: 0.6383 - acc: 0.6270\n",
      "Epoch 6/25\n",
      "6400/6400 [==============================] - 0s 42us/step - loss: 0.6356 - acc: 0.6350\n",
      "Epoch 7/25\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.6329 - acc: 0.6384\n",
      "Epoch 8/25\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.6313 - acc: 0.6417\n",
      "Epoch 9/25\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.6303 - acc: 0.6430\n",
      "Epoch 10/25\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.6292 - acc: 0.6466\n",
      "Epoch 11/25\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.6287 - acc: 0.6452\n",
      "Epoch 12/25\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.6272 - acc: 0.6467\n",
      "Epoch 13/25\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.6266 - acc: 0.6447\n",
      "Epoch 14/25\n",
      "6400/6400 [==============================] - 0s 56us/step - loss: 0.6258 - acc: 0.6477\n",
      "Epoch 15/25\n",
      "6400/6400 [==============================] - 0s 50us/step - loss: 0.6249 - acc: 0.6489\n",
      "Epoch 16/25\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.6245 - acc: 0.6511\n",
      "Epoch 17/25\n",
      "6400/6400 [==============================] - 0s 47us/step - loss: 0.6239 - acc: 0.6505\n",
      "Epoch 18/25\n",
      "6400/6400 [==============================] - 0s 46us/step - loss: 0.6235 - acc: 0.6483\n",
      "Epoch 19/25\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.6224 - acc: 0.6505\n",
      "Epoch 20/25\n",
      "6400/6400 [==============================] - 0s 46us/step - loss: 0.6225 - acc: 0.6506\n",
      "Epoch 21/25\n",
      "6400/6400 [==============================] - 0s 39us/step - loss: 0.6218 - acc: 0.6483\n",
      "Epoch 22/25\n",
      "6400/6400 [==============================] - 0s 37us/step - loss: 0.6214 - acc: 0.6522\n",
      "Epoch 23/25\n",
      "6400/6400 [==============================] - 0s 43us/step - loss: 0.6212 - acc: 0.6528\n",
      "Epoch 24/25\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.6204 - acc: 0.6509\n",
      "Epoch 25/25\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.6203 - acc: 0.6508\n",
      "1600/1600 [==============================] - 0s 142us/step\n"
     ]
    }
   ],
   "source": [
    "# NN Model 2 Training again with epochs = 15\n",
    "# output = activation(dot(input, kernel) + bias)\n",
    "classifier = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier.add(layers.Dense(16, activation='relu', kernel_initializer='random_normal', input_dim=13))  \n",
    "#Second  Hidden Layer\n",
    "classifier.add(layers.Dense(32, activation='relu', kernel_initializer='random_normal'))\n",
    "#Third Hidden Layer\n",
    "classifier.add(layers.Dense(32, activation='relu', kernel_initializer='random_normal'))\n",
    "#Output Layer\n",
    "classifier.add(layers.Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='rmsprop',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "\n",
    "classifier.fit(X_train, y_train, epochs=25, batch_size=128)\n",
    "results = classifier.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.627038300037384, 0.64125]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
